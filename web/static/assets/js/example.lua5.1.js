// Generated by lua5.1.js-file-packer
(function(Lua5_1) {
Lua5_1.provide_file("/", "alt_getopt.lua",
 "-- Copyright (c) 2009 Aleksey Cheusov <vle@gmx.net>\n"
+"--\n"
+"-- Permission is hereby granted, free of charge, to any person obtaining\n"
+"-- a copy of this software and associated documentation files (the\n"
+"-- \"Software\"), to deal in the Software without restriction, including\n"
+"-- without limitation the rights to use, copy, modify, merge, publish,\n"
+"-- distribute, sublicense, and/or sell copies of the Software, and to\n"
+"-- permit persons to whom the Software is furnished to do so, subject to\n"
+"-- the following conditions:\n"
+"--\n"
+"-- The above copyright notice and this permission notice shall be\n"
+"-- included in all copies or substantial portions of the Software.\n"
+"--\n"
+"-- THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n"
+"-- EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n"
+"-- MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n"
+"-- NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n"
+"-- LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n"
+"-- OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n"
+"-- WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
+"\nlocal type, pairs, ipairs, io, os = type, pairs, ipairs, io, os\n"
+"\nmodule (\"alt_getopt\")\n"
+"\nlocal function convert_short2long (opts)\n"
+"   local i = 1\n"
+"   local len = #opts\n"
+"   local ret = {}\n"
+"\n   for short_opt, accept_arg in opts:gmatch(\"(%w)(:?)\") do\n"
+"      ret[short_opt]=#accept_arg\n"
+"   end\n"
+"\n   return ret\n"
+"end\n"
+"\nlocal function exit_with_error (msg, exit_status)\n"
+"   io.stderr:write (msg)\n"
+"   os.exit (exit_status)\n"
+"end\n"
+"\nlocal function err_unknown_opt (opt)\n"
+"   exit_with_error (\"Unknown option `-\" ..\n"
+"\t\t    (#opt > 1 and \"-\" or \"\") .. opt .. \"'\\n"
+"\", 1)\n"
+"end\n"
+"\nlocal function canonize (options, opt)\n"
+"   if not options [opt] then\n"
+"      err_unknown_opt (opt)\n"
+"   end\n"
+"\n   while type (options [opt]) == \"string\" do\n"
+"      opt = options [opt]\n"
+"\n      if not options [opt] then\n"
+"\t err_unknown_opt (opt)\n"
+"      end\n"
+"   end\n"
+"\n   return opt\n"
+"end\n"
+"\nfunction get_ordered_opts (arg, sh_opts, long_opts)\n"
+"   local i      = 1\n"
+"   local count  = 1\n"
+"   local opts   = {}\n"
+"   local optarg = {}\n"
+"\n   local options = convert_short2long (sh_opts)\n"
+"   for k,v in pairs (long_opts) do\n"
+"      options [k] = v\n"
+"   end\n"
+"\n   while i <= #arg do\n"
+"      local a = arg [i]\n"
+"\n      if a == \"--\" then\n"
+"\t i = i + 1\n"
+"\t break\n"
+"\n      elseif a == \"-\" then\n"
+"\t break\n"
+"\n      elseif a:sub (1, 2) == \"--\" then\n"
+"\t local pos = a:find (\"=\", 1, true)\n"
+"\n\t if pos then\n"
+"\t    local opt = a:sub (3, pos-1)\n"
+"\n\t    opt = canonize (options, opt)\n"
+"\n\t    if options [opt] == 0 then\n"
+"\t       exit_with_error (\"Bad usage of option `\" .. a .. \"'\\n"
+"\", 1)\n"
+"\t    end\n"
+"\n\t    optarg [count] = a:sub (pos+1)\n"
+"\t    opts [count] = opt\n"
+"\t else\n"
+"\t    local opt = a:sub (3)\n"
+"\n\t    opt = canonize (options, opt)\n"
+"\n\t    if options [opt] == 0 then\n"
+"\t       opts [count] = opt\n"
+"\t    else\n"
+"\t       if i == #arg then\n"
+"\t\t  exit_with_error (\"Missed value for option `\" .. a .. \"'\\n"
+"\", 1)\n"
+"\t       end\n"
+"\n\t       optarg [count] = arg [i+1]\n"
+"\t       opts [count] = opt\n"
+"\t       i = i + 1\n"
+"\t    end\n"
+"\t end\n"
+"\t count = count + 1\n"
+"\n      elseif a:sub (1, 1) == \"-\" then\n"
+"\t local j\n"
+"\t for j=2,a:len () do\n"
+"\t    local opt = canonize (options, a:sub (j, j))\n"
+"\n\t    if options [opt] == 0 then\n"
+"\t       opts [count] = opt\n"
+"\t       count = count + 1\n"
+"\t    elseif a:len () == j then\n"
+"\t       if i == #arg then\n"
+"\t\t  exit_with_error (\"Missed value for option `-\" .. opt .. \"'\\n"
+"\", 1)\n"
+"\t       end\n"
+"\n\t       optarg [count] = arg [i+1]\n"
+"\t       opts [count] = opt\n"
+"\t       i = i + 1\n"
+"\t       count = count + 1\n"
+"\t       break\n"
+"\t    else\n"
+"\t       optarg [count] = a:sub (j+1)\n"
+"\t       opts [count] = opt\n"
+"\t       count = count + 1\n"
+"\t       break\n"
+"\t    end\n"
+"\t end\n"
+"      else\n"
+"\t break\n"
+"      end\n"
+"\n      i = i + 1\n"
+"   end\n"
+"\n   return opts,i,optarg\n"
+"end\n"
+"\nfunction get_opts (arg, sh_opts, long_opts)\n"
+"   local ret = {}\n"
+"\n   local opts,optind,optarg = get_ordered_opts (arg, sh_opts, long_opts)\n"
+"   for i,v in ipairs (opts) do\n"
+"      if optarg [i] then\n"
+"\t ret [v] = optarg [i]\n"
+"      else\n"
+"\t ret [v] = 1\n"
+"      end\n"
+"   end\n"
+"\n   return ret,optind\n"
+"end\n",
true, false);
// End of /alt_getopt.lua
Lua5_1.provide_file("/", "main.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2011, 2014 Sierra Wireless and others.\n"
+"-- All rights reserved. This program and the accompanying materials\n"
+"-- are made available under the terms of the Eclipse Public License v1.0\n"
+"-- which accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Sierra Wireless - initial API and implementation\n"
+"--------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Uses Metalua capabilities to indent code and provide source code offset\n"
+"-- semantic depth.\n"
+"--\n"
+"-- @module formatter\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n M = {}\n"
+"require 'metalua.loader'\n"
+"local math = require 'math'\n"
+"local mlc  = require 'metalua.compiler'.new()\n"
+"local Q    = require 'metalua.treequery'\n"
+"\nlocal COMMENT = '--'\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Format utilities\n"
+"--------------------------------------------------------------------------------\n"
+"\n---\n"
+"-- Comment adjusted first line and first offset of a node.\n"
+"--\n"
+"-- @return #number, #number\n"
+"local function getfirstline(node, ignorecomments)\n"
+"    -- Consider preceding comments as part of current chunk\n"
+"    -- WARNING: This is NOT the default in Metalua\n"
+"    local first, offset\n"
+"    local offsets = node.lineinfo\n"
+"    if offsets.first.comments and not ignorecomments then\n"
+"        first = offsets.first.comments.lineinfo.first.line\n"
+"        offset = offsets.first.comments.lineinfo.first.offset\n"
+"    else\n"
+"        -- Regular node\n"
+"        first = offsets.first.line\n"
+"        offset = offsets.first.offset\n"
+"    end\n"
+"    return first, offset\n"
+"end\n"
+"\n---\n"
+"-- Last line of a node.\n"
+"--\n"
+"-- @return #number\n"
+"local function getlastline(node)\n"
+"    return node.lineinfo.last.line , node.lineinfo.last.offset\n"
+"end\n"
+"\nlocal function indent(cfg, st, startline, startindex, endline, parent)\n"
+"\n    -- Indent following lines when current one does not start with first statement\n"
+"    -- of current block.\n"
+"    if not cfg.source:sub(1,startindex-1):find(\"[\\r\\n"
+"]%s*$\") then\n"
+"        startline = startline + 1\n"
+"    end\n"
+"\n    -- Nothing interesting to do\n"
+"    if endline < startline then\n"
+"        return\n"
+"    end\n"
+"\n    -- Indent block first line\n"
+"    st.indentation[startline] = true\n"
+"\n    -- Restore indentation\n"
+"    if not st.unindentation[endline+1] then\n"
+"        -- Only when not performed by a higher node\n"
+"        st.unindentation[endline+1] = getfirstline(parent)\n"
+"    end\n"
+"end\n"
+"\n---\n"
+"-- Indent all lines of an expression list.\n"
+"local function indentexprlist(cfg, st, node, parent, ignorecomments)\n"
+"    local endline = getlastline(node)\n"
+"    local startline, startindex = getfirstline(node, ignorecomments)\n"
+"    indent(cfg, st, startline, startindex, endline, parent)\n"
+"end\n"
+"\n---\n"
+"-- Indents `Local and `Set\n"
+"local function assignments(cfg, st, node)\n"
+"\n    -- Indent only when node spreads across several lines\n"
+"    local nodestart = getfirstline(node, true)\n"
+"    local nodeend = getlastline(node)\n"
+"    if nodestart >= nodeend then\n"
+"        return\n"
+"    end\n"
+"\n    -- Format it\n"
+"    local lhs, exprs = unpack(node)\n"
+"    if #exprs == 0 then\n"
+"        -- Regular `Local handling\n"
+"        indentexprlist(cfg, st, lhs, node)\n"
+"        -- Avoid problems and format functions later.\n"
+"    elseif not (#exprs == 1 and exprs[1].tag == 'Function') then\n"
+"\n        -- for local, indent lhs\n"
+"        if node.tag == 'Local' then\n"
+"\n            -- Else way, indent LHS and expressions like a single chunk.\n"
+"            local endline = getlastline(exprs)\n"
+"            local startline, startindex = getfirstline(lhs, true)\n"
+"            indent(cfg, st, startline, startindex, endline, node)\n"
+"\n        end\n"
+"\n        -- In this chunk indent expressions one more.\n"
+"        indentexprlist(cfg, st, exprs, node)\n"
+"    end\n"
+"end\n"
+"\n---\n"
+"-- Indents parameters\n"
+"--\n"
+"-- @param callable  Node containing the params\n"
+"-- @param firstparam first parameter of the given callable\n"
+"local function indentparams(cfg, st, firstparam, lastparam, parent)\n"
+"\n    -- Determine parameters first line\n"
+"    local paramstartline,paramstartindex = getfirstline(firstparam)\n"
+"\n    -- Determine parameters last line\n"
+"    local paramlastline = getlastline(lastparam)\n"
+"\n    -- indent\n"
+"    indent(cfg, st, paramstartline, paramstartindex, paramlastline, parent)\n"
+"end\n"
+"\n---\n"
+"-- Indent all lines of a chunk.\n"
+"local function indentchunk(cfg, st, node, parent)\n"
+"\n    -- Get regular start\n"
+"    local startline, startindex = getfirstline(node[1])\n"
+"\n    -- Handle trailing comments as they were statements\n"
+"    local endline\n"
+"    local lastnode = node[#node]\n"
+"    if lastnode.lineinfo.last.comments then\n"
+"        endline = lastnode.lineinfo.last.comments.lineinfo.last.line\n"
+"    else\n"
+"        endline = lastnode.lineinfo.last.line\n"
+"    end\n"
+"\n    indent(cfg, st, startline, startindex, endline, parent)\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Expressions formatters\n"
+"--------------------------------------------------------------------------------\n"
+"local case = { }\n"
+"\nfunction case.String(cfg, st, node)\n"
+"    local firstline, _ = getfirstline(node,true)\n"
+"    local lastline = getlastline(node)\n"
+"    for line=firstline+1, lastline do\n"
+"        st.indentation[line]=false\n"
+"    end\n"
+"end\n"
+"\nfunction case.Table(cfg, st, node)\n"
+"\n    if not cfg.indenttable then\n"
+"        return\n"
+"    end\n"
+"\n    -- Format only inner values across several lines\n"
+"    local firstline, firstindex = getfirstline(node,true)\n"
+"    local lastline = getlastline(node)\n"
+"    if #node > 0 and firstline < lastline then\n"
+"\n        -- Determine first line to format\n"
+"        local firstnode = unpack(node)\n"
+"        local childfirstline, childfirstindex = getfirstline(firstnode)\n"
+"\n        -- Determine last line to format\n"
+"        local lastnode = #node == 1 and firstnode or node[ #node ]\n"
+"        local childlastline = getlastline(lastnode)\n"
+"\n        -- Actual formating\n"
+"        indent(cfg, st, childfirstline, childfirstindex, childlastline, node)\n"
+"    end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Statements formatters\n"
+"--------------------------------------------------------------------------------\n"
+"function case.Call(cfg, st, node)\n"
+"    local expr, firstparam = unpack(node)\n"
+"    if firstparam then\n"
+"        indentparams(cfg, st, firstparam, node[#node], node)\n"
+"    end\n"
+"end\n"
+"\nfunction case.Do(cfg, st, node, parent)\n"
+"    -- Ignore empty node\n"
+"    if #node == 0 or not parent then\n"
+"        return\n"
+"    end\n"
+"    indentchunk(cfg, st, node, parent)\n"
+"end\n"
+"\nfunction case.Forin(cfg, st, node)\n"
+"    local ids, iterator, _ = unpack(node)\n"
+"    indentexprlist(cfg, st, ids, node)\n"
+"    indentexprlist(cfg, st, iterator, node)\n"
+"end\n"
+"\nfunction case.Fornum(cfg, st, node)\n"
+"    -- Format from variable name to last expressions\n"
+"    local var, init, limit, range = unpack(node)\n"
+"    local startline, startindex   = getfirstline(var)\n"
+"\n    -- Take range as last expression, when not available limit will do\n"
+"    local lastexpr = range.tag and range or limit\n"
+"    indent(cfg, st, startline, startindex, getlastline(lastexpr), node)\n"
+"end\n"
+"\nfunction case.Function(cfg, st, node)\n"
+"    local params, chunk = unpack(node)\n"
+"    indentexprlist(cfg, st, params, node)\n"
+"end\n"
+"\nfunction case.Index(cfg, st, node, parent)\n"
+"\n    -- Bug 422778 - [ast] Missing a lineinfo attribute on one Index\n"
+"    -- the following if is a workaround avoid a nil exception but the formatting\n"
+"    -- of the current node is avoided.\n"
+"    if not node.lineinfo then\n"
+"        return\n"
+"    end\n"
+"    -- avoid indent if the index is on one line\n"
+"    local nodestartline = node.lineinfo.first.line\n"
+"    local nodeendline = node.lineinfo.last.line\n"
+"    if nodeendline == nodestartline then\n"
+"        return\n"
+"    end\n"
+"\n    local left, right = unpack(node)\n"
+"    -- Bug 422778 [ast] Missing a lineinfo attribute on one Index\n"
+"    -- the following line is a workaround avoid a nil exception but the\n"
+"    -- formatting of the current node is avoided.\n"
+"    if left.lineinfo then\n"
+"        local leftendline, leftendoffset = getlastline(left)\n"
+"        -- For Call,Set and Local nodes we want to indent to end of the parent node\n"
+"        -- not only the index itself\n"
+"        local parentisassignment = parent.tag == 'Set' or parent.tag == 'Local'\n"
+"        local parenthaschild = parent[1] and #parent[1] ==  1\n"
+"        if (parent[1] == node and parent.tag == 'Call') or\n"
+"            (parentisassignment and parenthaschild and parent[1][1] == node)\n"
+"        then\n"
+"            local parentendline = getlastline(parent)\n"
+"            indent(cfg, st, leftendline, leftendoffset+1, parentendline, parent)\n"
+"        else\n"
+"            local rightendline = getlastline(right)\n"
+"            indent(cfg, st, leftendline, leftendoffset+1, rightendline, node)\n"
+"        end\n"
+"    end\n"
+"\nend\n"
+"\nfunction case.If(cfg, st, node)\n"
+"    -- Indent only conditions, chunks are already taken care of.\n"
+"    local nodesize = #node\n"
+"    for conditionposition=1, nodesize-(nodesize%2), 2 do\n"
+"        indentexprlist(cfg, st, node[conditionposition], node)\n"
+"    end\n"
+"end\n"
+"\nfunction case.Invoke(cfg, st, node)\n"
+"    local expr, str, firstparam = unpack(node)\n"
+"\n    --indent str\n"
+"    local exprendline, exprendoffset = getlastline(expr)\n"
+"    local nodeendline = getlastline(node)\n"
+"    indent(cfg, st, exprendline, exprendoffset+1, nodeendline, node)\n"
+"\n    --indent parameters\n"
+"    if firstparam then\n"
+"        indentparams(cfg, st, firstparam, node[#node], str)\n"
+"    end\n"
+"\nend\n"
+"\nfunction case.Repeat(cfg, st, node)\n"
+"    local _, expr = unpack(node)\n"
+"    indentexprlist(cfg, st, expr, node)\n"
+"end\n"
+"\nfunction case.Return(cfg, st, node, parent)\n"
+"    if #node > 0 then\n"
+"        indentchunk(cfg, st, node, parent)\n"
+"    end\n"
+"end\n"
+"\ncase.Local = assignments\n"
+"case.Set   = assignments\n"
+"\nfunction case.While(cfg, st, node)\n"
+"    local expr, _ = unpack(node)\n"
+"    indentexprlist(cfg, st, expr, node)\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Calculate all indent level\n"
+"-- @param Source code to analyze\n"
+"-- @return #table {linenumber = indentationlevel}\n"
+"-- @usage local depth = format.indentLevel(\"local var\")\n"
+"--------------------------------------------------------------------------------\n"
+"local function getindentlevel(source, indenttable)\n"
+"\n    if not loadstring(source, 'CheckingFormatterSource') then\n"
+"        return\n"
+"    end\n"
+"\n    -----------------------------------------------------------------------------\n"
+"    -- Walk through AST\n"
+"    --\n"
+"    -- Walking the AST, we store which lines deserve one and always one\n"
+"    -- indentation.\n"
+"    --\n"
+"    -- We will not indent back. To obtain a smaller indentation, we will refer to\n"
+"    -- a less indented preceding line.\n"
+"    --\n"
+"    -- Why so complicated?\n"
+"    -- We use two tables as `state` simply for handling the case of one line\n"
+"    -- indentation.\n"
+"    -- We choose to use reference to a preceding line to avoid handling\n"
+"    -- indent-back computation and mistakes. When leaving a node after formatting\n"
+"    -- it, we simply use indentation of before entering this node.\n"
+"    -----------------------------------------------------------------------------\n"
+"    local configuration = {\n"
+"        indenttable = indenttable,\n"
+"        source = source\n"
+"    }\n"
+"\n    --\n"
+"    local state = {\n"
+"        -- Indentations line numbers\n"
+"        indentation = { },\n"
+"        -- Key:   Line number to indent back.\n"
+"        -- Value: Previous line number, it has the indentation depth wanted.\n"
+"        unindentation = { },\n"
+"        -- cache of handled comment\n"
+"        handledcomments = { },\n"
+"    }\n"
+"\n    local function onNode(...)\n"
+"        local node = (...)\n"
+"        local tag = node.tag\n"
+"        if not tag then case.Do(configuration, state, ...) else\n"
+"            local f = case[tag]\n"
+"            if f then f(configuration, state, ...) end\n"
+"        end\n"
+"\n        -- Do not indent long comment\n"
+"        -- -----------------------------------------\n"
+"        -- Define function to deal with long comment\n"
+"        local function indentlongcomment (comment)\n"
+"            -- If this is a long comment\n"
+"            -- (Only long comment has value at index 2 : this is the number of '=' for this comment)\n"
+"            if comment[2] and not state.handledcomments[comment]\n"
+"                and comment.lineinfo and comment.lineinfo.first and comment.lineinfo.first.line\n"
+"                and comment.lineinfo.last and comment.lineinfo.last.line then\n"
+"\n                state.handledcomments[comment] = true\n"
+"                for i=comment.lineinfo.first.line+1, comment.lineinfo.last.line do\n"
+"                    state.indentation[i] = false\n"
+"                end\n"
+"            end\n"
+"        end\n"
+"        -- manage comment before, then after this node\n"
+"        if node.lineinfo and node.lineinfo.first and node.lineinfo.first.comments then\n"
+"            for _, comment in ipairs(node.lineinfo.first.comments) do\n"
+"                indentlongcomment(comment)\n"
+"            end\n"
+"        end\n"
+"        if node.lineinfo and node.lineinfo.last and node.lineinfo.last.comments then\n"
+"            for _, comment in ipairs(node.lineinfo.last.comments) do\n"
+"                indentlongcomment(comment)\n"
+"            end\n"
+"        end\n"
+"    end\n"
+"\n    local ast = mlc:src_to_ast(source)\n"
+"    Q(ast) :foreach(onNode)\n"
+"\n    -- Built depth table\n"
+"    local currentdepth = 0\n"
+"    local depthtable = {}\n"
+"    for line=1, getlastline(ast[#ast]) do\n"
+"\n        -- Restore depth\n"
+"        if state.unindentation[line] then\n"
+"            currentdepth = depthtable[state.unindentation[line]]\n"
+"        end\n"
+"\n        -- Indent\n"
+"        if state.indentation[line] then\n"
+"            currentdepth = currentdepth + 1\n"
+"            depthtable[line] = currentdepth\n"
+"        elseif state.indentation[line] == false then\n"
+"            -- Ignore any kind of indentation\n"
+"            depthtable[line] = false\n"
+"        else\n"
+"            -- Use current indentation\n"
+"            depthtable[line] = currentdepth\n"
+"        end\n"
+"\n    end\n"
+"    return depthtable\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Trim white spaces before and after given string\n"
+"--\n"
+"-- @usage local trimmedstr = trim('          foo')\n"
+"-- @param #string string to trim\n"
+"-- @return #string string trimmed\n"
+"--------------------------------------------------------------------------------\n"
+"local function trim(string)\n"
+"    local pattern = \"^(%s*)(.*)\"\n"
+"    local _, strip =  string:match(pattern)\n"
+"    if not strip then return string end\n"
+"    local restrip\n"
+"    _, restrip = strip:reverse():match(pattern)\n"
+"    return restrip and restrip:reverse() or strip\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Provides position of next end of line\n"
+"--\n"
+"-- @param #string str Where to seek for end of line\n"
+"-- @param #number strstart Search starting index\n"
+"-- @return #number, #number Start and end of end of line\n"
+"-- @return #nil When no end of line is found\n"
+"--------------------------------------------------------------------------------\n"
+"local delimiterposition = function (str, strstart)\n"
+"    local starts = {}\n"
+"    local ends = {}\n"
+"    for _, delimiter in ipairs({'\\r\\n"
+"', '\\n"
+"', '\\r'}) do\n"
+"        local dstart, dend = str:find(delimiter, strstart, true)\n"
+"        if dstart and not ends[dstart] then\n"
+"            starts[#starts + 1] = dstart\n"
+"            ends[dstart] = dend\n"
+"        end\n"
+"    end\n"
+"    if #starts > 0 then\n"
+"        local min = math.min( unpack(starts) )\n"
+"        return min, ends[min]\n"
+"    end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Indent Lua Source Code.\n"
+"--\n"
+"-- @function [parent=#formatter] indentcode\n"
+"-- @param #string source Source code to format\n"
+"-- @param #string delimiter Delimiter used in resulting formatted source\n"
+"-- @param indenttable true if you want to indent in table\n"
+"-- @param ...\n"
+"-- @return #string Formatted code\n"
+"-- @return #nil, #string In case of error\n"
+"-- @usage indentCode('local var', '\\n"
+"', true, '\\t')\n"
+"-- @usage indentCode('local var', '\\n"
+"', true, --[[tabulationSize]]4, --[[indentationSize]]2)\n"
+"--------------------------------------------------------------------------------\n"
+"function M.indentcode(source, delimiter,indenttable, ...)\n"
+"\n    --\n"
+"    -- Create function which will generate indentation\n"
+"    --\n"
+"    local tabulation\n"
+"    if select('#', ...) > 1 then\n"
+"        local tabSize = select(1, ...)\n"
+"        local indentationSize = select(2, ...)\n"
+"        -- When tabulation size and indentation size is given, tabulation is\n"
+"        -- composed of tabulation and spaces\n"
+"        tabulation = function(depth)\n"
+"            local range = depth * indentationSize\n"
+"            local tabCount = math.floor(range / tabSize)\n"
+"            local spaceCount = range % tabSize\n"
+"            local tab = '\\t'\n"
+"            local space = ' '\n"
+"            return tab:rep(tabCount) .. space:rep(spaceCount)\n"
+"        end\n"
+"    else\n"
+"        local char = select(1, ...)\n"
+"        -- When tabulation character is given, this character will be duplicated\n"
+"        -- according to length\n"
+"        tabulation = function (depth) return char:rep(depth) end\n"
+"    end\n"
+"\n    -- Delimiter position table\n"
+"    -- Initialization represent string's start offset\n"
+"    local positions = {0}\n"
+"\n    -- Handle shebang\n"
+"    local shebang = source:match('^#')\n"
+"    if shebang then\n"
+"        -- Simply comment shebang when formating\n"
+"        source = table.concat({COMMENT, source})\n"
+"    end\n"
+"\n    -- Check code validity\n"
+"    local status, message = loadstring(source,\"isCodeValid\")\n"
+"    if not status then return status, message end\n"
+"\n    --\n"
+"    -- Seek for delimiters positions\n"
+"    --\n"
+"    local sourcePosition = 1\n"
+"    repeat\n"
+"        -- Find end of line\n"
+"        local delimiterStart, delimiterEnd = delimiterposition(source,\n"
+"            sourcePosition)\n"
+"        if delimiterStart then\n"
+"            if delimiterEnd < #source then\n"
+"                positions[#positions + 1] = delimiterStart\n"
+"            end\n"
+"            sourcePosition = delimiterEnd + 1\n"
+"        end\n"
+"    until not delimiterStart\n"
+"\n    -- No need for indentation, when no delimiter has been found\n"
+"    if #positions < 2 then\n"
+"        return shebang and source:sub(1 + #COMMENT) or source\n"
+"    end\n"
+"\n    -- calculate indentation\n"
+"    local linetodepth = getindentlevel(source, indenttable)\n"
+"\n    -- Concatenate string with right indentation\n"
+"    local indented = {}\n"
+"    for position=1, #positions do\n"
+"        -- Extract source code line\n"
+"        local offset = positions[position]\n"
+"        -- Get the interval between two positions\n"
+"        local rawline\n"
+"        if positions[position + 1] then\n"
+"            rawline = source:sub(offset + 1, positions[position + 1] -1)\n"
+"        else\n"
+"            -- From current position to end of line\n"
+"            rawline = source:sub(offset + 1)\n"
+"        end\n"
+"\n        -- Trim white spaces\n"
+"        local indentcount = linetodepth[position]\n"
+"        if not indentcount then\n"
+"            indented[#indented+1] = rawline\n"
+"        else\n"
+"            -- Indent only when there is code on the line\n"
+"            local line = trim(rawline)\n"
+"            if #line > 0 then\n"
+"\n                -- Prefix with right indentation\n"
+"                if indentcount > 0 then\n"
+"                    indented[#indented+1] = tabulation( indentcount )\n"
+"                end\n"
+"\n                -- Append trimmed source code\n"
+"                indented[#indented+1] = line\n"
+"            end\n"
+"        end\n"
+"\n        -- Append new line\n"
+"        if position < #positions then\n"
+"            indented[#indented+1] = delimiter\n"
+"        end\n"
+"    end\n"
+"\n    -- Ensure single final new line\n"
+"    if #indented > 0 and not indented[#indented]:match('%s$') then\n"
+"        indented[#indented + 1] = delimiter\n"
+"    end\n"
+"\n    -- Uncomment shebang when needed\n"
+"    local formattedcode = table.concat(indented)\n"
+"    if shebang and #formattedcode then\n"
+"        return formattedcode:sub(1 + #COMMENT)\n"
+"    end\n"
+"    return formattedcode\n"
+"end\n"
+"\n-- local print = print\n"
+"-- local tconcat = table.concat\n"
+"-- local tinsert = table.insert\n"
+"-- local srep = string.rep\n"
+"-- local type = type\n"
+"-- local pairs = pairs\n"
+"-- local tostring = tostring\n"
+"-- local next = next\n"
+"\n-- function print_r(root)\n"
+"--     local cache = {  [root] = \".\" }\n"
+"--     local function _dump(t,space,name)\n"
+"--         local temp = {}\n"
+"--         for k,v in pairs(t) do\n"
+"--             local key = tostring(k)\n"
+"--             if cache[v] then\n"
+"--                 tinsert(temp,\"+\" .. key .. \" {\" .. cache[v]..\"}\")\n"
+"--             elseif type(v) == \"table\" then\n"
+"--                 local new_key = name .. \".\" .. key\n"
+"--                 cache[v] = new_key\n"
+"--                 tinsert(temp,\"+\" .. key .. _dump(v,space .. (next(t,k) and \"|\" or \" \" ).. srep(\" \",#key),new_key))\n"
+"--             else\n"
+"--                 tinsert(temp,\"+\" .. key .. \" [\" .. tostring(v)..\"]\")\n"
+"--             end\n"
+"--         end\n"
+"--         return tconcat(temp,\"\\n"
+"\"..space)\n"
+"--     end\n"
+"--     print(_dump(root, \"\",\"\"))\n"
+"-- end\n"
+"\nusage =\n"
+"    [[\n"
+"\nUsage: lua -f codeformat.lua ...options...\n"
+"\nOptions are:\n"
+"--file <lua file>\n"
+"--ts <spaces>, tabsize: number of spaces in your tabs\n"
+"--in <spaces>, indent size: number of spaces for each indentation\n"
+"\n]]\n"
+"\nfunction process_args()\n"
+"    -- get args set by user in command line\n"
+"    local t,i = {},1\n"
+"    while i<table.getn(arg) do\n"
+"        local a=arg[i]\n"
+"        if a==\"--file\" then\n"
+"            t.filename,i = arg[i+1],i+2\n"
+"        elseif a==\"--ts\" then\n"
+"            t.mytabsize,i = arg[i+1]+0,i+2\n"
+"        elseif a==\"--in\" then\n"
+"            t.myindent,i = arg[i+1]+0,i+2\n"
+"        else\n"
+"            print(usage..\"Bad flag: \"..a)\n"
+"            os.exit(-1)\n"
+"        end\n"
+"    end\n"
+"    return t\n"
+"end\n"
+"\nfunction readfile(f)\n"
+"    local fh=io.open(f,\"rt\")\n"
+"    local t = fh:read(\"*all\")\n"
+"    fh:close()\n"
+"    return t\n"
+"end\n"
+"\n--args = process_args()\n"
+"--if not args.filename then error(usage..\"no Lua file given\") end\n"
+"--args.mytabsize = args.mytabsize or mytabs\n"
+"--args.myindent = args.myindent or myindent\n"
+"-- print(readfile(args.filename))\n"
+"print(M.indentcode(\"local m;\", '\\n"
+"', true, '    '))\n",
true, false);
// End of /main.lua
Lua5_1.provide_file("/", "checks.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n-- Alternative implementation of checks() in Lua. Slower than\n"
+"-- the C counterpart, but no compilation/porting concerns.\n"
+"\ncheckers = { }\n"
+"\nlocal function check_one(expected, val)\n"
+"    if type(val)==expected then return true end\n"
+"    local mt = getmetatable(val)\n"
+"    if mt and mt.__type==expected then return true end\n"
+"    local f = checkers[expected]\n"
+"    if f and f(val) then return true end\n"
+"    return false\n"
+"end\n"
+"\nlocal function check_many(name, expected, val)\n"
+"    if expected=='?' then return true\n"
+"    elseif expected=='!' then return (val~=nil)\n"
+"    elseif type(expected) ~= 'string' then\n"
+"        error 'strings expected by checks()'\n"
+"    elseif val==nil and expected :sub(1,1) == '?' then return true end\n"
+"    for one in expected :gmatch \"[^|?]+\" do\n"
+"        if check_one(one, val) then return true end\n"
+"    end\n"
+"    return false\n"
+"end\n"
+"\nfunction checks(...)\n"
+"    for i, arg in ipairs{...} do\n"
+"        local name, val = debug.getlocal(2, i)\n"
+"        local success = check_many(name, arg, val)\n"
+"        if not success then\n"
+"            local fname = debug.getinfo(2, 'n').name\n"
+"            local fmt = \"bad argument #%d to '%s' (%s expected, got %s)\"\n"
+"            local msg = string.format(fmt, i, fname or \"?\", arg, type(val))\n"
+"            error(msg, 3)\n"
+"        end\n"
+"    end\n"
+"end\n"
+"\nreturn checks\n",
true, false);
// End of /checks.lua
Lua5_1.provide_file("/metalua/grammar/", "generator.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Summary: parser generator. Collection of higher order functors,\n"
+"--   which allow to build and combine parsers. Relies on a lexer\n"
+"--   that supports the same API as the one exposed in mll.lua.\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Exported API:\n"
+"--\n"
+"-- Parser generators:\n"
+"-- * [gg.sequence()]\n"
+"-- * [gg.multisequence()]\n"
+"-- * [gg.expr()]\n"
+"-- * [gg.list()]\n"
+"-- * [gg.onkeyword()]\n"
+"-- * [gg.optkeyword()]\n"
+"--\n"
+"-- Other functions:\n"
+"-- * [gg.parse_error()]\n"
+"-- * [gg.make_parser()]\n"
+"-- * [gg.is_parser()]\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal M = { }\n"
+"\nlocal lexer = require 'metalua.grammar.lexer'\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Symbol generator: [gensym()] returns a guaranteed-to-be-unique identifier.\n"
+"-- The main purpose is to avoid variable capture in macros.\n"
+"--\n"
+"-- If a string is passed as an argument, theis string will be part of the\n"
+"-- id name (helpful for macro debugging)\n"
+"--------------------------------------------------------------------------------\n"
+"local gensymidx = 0\n"
+"\nfunction M.gensym (arg)\n"
+"   gensymidx = gensymidx + 1\n"
+"   return { tag=\"Id\", string.format(\".%i.%s\", gensymidx, arg or \"\")}\n"
+"end\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"-- parser metatable, which maps __call to method parse, and adds some\n"
+"-- error tracing boilerplate.\n"
+"-------------------------------------------------------------------------------\n"
+"local parser_metatable = { }\n"
+"\nfunction parser_metatable :__call (lx, ...)\n"
+"    return self :parse (lx, ...)\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Turn a table into a parser, mainly by setting the metatable.\n"
+"-------------------------------------------------------------------------------\n"
+"function M.make_parser(kind, p)\n"
+"   p.kind = kind\n"
+"   if not p.transformers then p.transformers = { } end\n"
+"   function p.transformers:add (x)\n"
+"      table.insert (self, x)\n"
+"   end\n"
+"   setmetatable (p, parser_metatable)\n"
+"   return p\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Return true iff [x] is a parser.\n"
+"-- If it's a gg-generated parser, return the name of its kind.\n"
+"-------------------------------------------------------------------------------\n"
+"function M.is_parser (x)\n"
+"   return type(x)==\"function\" or getmetatable(x)==parser_metatable and x.kind\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Parse a sequence, without applying builder nor transformers.\n"
+"-------------------------------------------------------------------------------\n"
+"local function raw_parse_sequence (lx, p)\n"
+"    local r = { }\n"
+"    for i=1, #p do\n"
+"        local e=p[i]\n"
+"        if type(e) == \"string\" then\n"
+"            local kw = lx :next()\n"
+"            if not lx :is_keyword (kw, e) then\n"
+"                M.parse_error(\n"
+"                    lx, \"A keyword was expected, probably `%s'.\", e)\n"
+"            end\n"
+"        elseif M.is_parser (e) then\n"
+"            table.insert (r, e(lx))\n"
+"        else -- Invalid parser definition, this is *not* a parsing error\n"
+"            error(string.format(\n"
+"                      \"Sequence `%s': element #%i is neither a string nor a parser: %s\",\n"
+"                      p.name, i, table.tostring(e)))\n"
+"        end\n"
+"    end\n"
+"    return r\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Parse a multisequence, without applying multisequence transformers.\n"
+"-- The sequences are completely parsed.\n"
+"-------------------------------------------------------------------------------\n"
+"local function raw_parse_multisequence (lx, sequence_table, default)\n"
+"   local seq_parser = sequence_table[lx:is_keyword(lx:peek())]\n"
+"   if seq_parser  then return seq_parser (lx)\n"
+"   elseif default then return default (lx)\n"
+"   else return false end\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Applies all transformers listed in parser on ast.\n"
+"-------------------------------------------------------------------------------\n"
+"local function transform (ast, parser, fli, lli)\n"
+"   if parser.transformers then\n"
+"      for _, t in ipairs (parser.transformers) do ast = t(ast) or ast end\n"
+"   end\n"
+"   if type(ast) == 'table' then\n"
+"      local ali = ast.lineinfo\n"
+"      if not ali or ali.first~=fli or ali.last~=lli then\n"
+"         ast.lineinfo = lexer.new_lineinfo(fli, lli)\n"
+"      end\n"
+"   end\n"
+"   return ast\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Generate a tracable parsing error (not implemented yet)\n"
+"-------------------------------------------------------------------------------\n"
+"function M.parse_error(lx, fmt, ...)\n"
+"   local li = lx:lineinfo_left()\n"
+"   local file, line, column, offset, positions\n"
+"   if li then\n"
+"      file, line, column, offset = li.source, li.line, li.column, li.offset\n"
+"      positions = { first = li, last = li }\n"
+"   else\n"
+"      line, column, offset = -1, -1, -1\n"
+"   end\n"
+"\n   local msg  = string.format(\"line %i, char %i: \"..fmt, line, column, ...)\n"
+"   if file and file~='?' then msg = \"file \"..file..\", \"..msg end\n"
+"\n   local src = lx.src\n"
+"   if offset>0 and src then\n"
+"      local i, j = offset, offset\n"
+"      while src:sub(i,i) ~= '\\n"
+"' and i>=0    do i=i-1 end\n"
+"      while src:sub(j,j) ~= '\\n"
+"' and j<=#src do j=j+1 end\n"
+"      local srcline = src:sub (i+1, j-1)\n"
+"      local idx  = string.rep (\" \", column)..\"^\"\n"
+"      msg = string.format(\"%s\\n"
+">>> %s\\n"
+">>> %s\", msg, srcline, idx)\n"
+"   end\n"
+"   --lx :kill()\n"
+"   error(msg)\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Sequence parser generator\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"-- Input fields:\n"
+"--\n"
+"-- * [builder]: how to build an AST out of sequence parts. let [x] be the list\n"
+"--   of subparser results (keywords are simply omitted). [builder] can be:\n"
+"--    - [nil], in which case the result of parsing is simply [x]\n"
+"--    - a string, which is then put as a tag on [x]\n"
+"--    - a function, which takes [x] as a parameter and returns an AST.\n"
+"--\n"
+"-- * [name]: the name of the parser. Used for debug messages\n"
+"--\n"
+"-- * [transformers]: a list of AST->AST functions, applied in order on ASTs\n"
+"--   returned by the parser.\n"
+"--\n"
+"-- * Table-part entries corresponds to keywords (strings) and subparsers\n"
+"--   (function and callable objects).\n"
+"--\n"
+"-- After creation, the following fields are added:\n"
+"-- * [parse] the parsing function lexer->AST\n"
+"-- * [kind] == \"sequence\"\n"
+"-- * [name] is set, if it wasn't in the input.\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"function M.sequence (p)\n"
+"   M.make_parser (\"sequence\", p)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Parsing method\n"
+"   -------------------------------------------------------------------\n"
+"   function p:parse (lx)\n"
+"\n      -- Raw parsing:\n"
+"      local fli = lx:lineinfo_right()\n"
+"      local seq = raw_parse_sequence (lx, self)\n"
+"      local lli = lx:lineinfo_left()\n"
+"\n      -- Builder application:\n"
+"      local builder, tb = self.builder, type (self.builder)\n"
+"      if tb == \"string\" then seq.tag = builder\n"
+"      elseif tb == \"function\" or builder and builder.__call then seq = builder(seq)\n"
+"      elseif builder == nil then -- nothing\n"
+"      else error (\"Invalid builder of type \"..tb..\" in sequence\") end\n"
+"      seq = transform (seq, self, fli, lli)\n"
+"      assert (not seq or seq.lineinfo)\n"
+"      return seq\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Construction\n"
+"   -------------------------------------------------------------------\n"
+"   -- Try to build a proper name\n"
+"   if p.name then\n"
+"      -- don't touch existing name\n"
+"   elseif type(p[1])==\"string\" then -- find name based on 1st keyword\n"
+"      if #p==1 then p.name=p[1]\n"
+"      elseif type(p[#p])==\"string\" then\n"
+"         p.name = p[1] .. \" ... \" .. p[#p]\n"
+"      else p.name = p[1] .. \" ...\" end\n"
+"   else -- can't find a decent name\n"
+"      p.name = \"unnamed_sequence\"\n"
+"   end\n"
+"\n   return p\n"
+"end --</sequence>\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Multiple, keyword-driven, sequence parser generator\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"-- in [p], useful fields are:\n"
+"--\n"
+"-- * [transformers]: as usual\n"
+"--\n"
+"-- * [name]: as usual\n"
+"--\n"
+"-- * Table-part entries must be sequence parsers, or tables which can\n"
+"--   be turned into a sequence parser by [gg.sequence]. These\n"
+"--   sequences must start with a keyword, and this initial keyword\n"
+"--   must be different for each sequence.  The table-part entries will\n"
+"--   be removed after [gg.multisequence] returns.\n"
+"--\n"
+"-- * [default]: the parser to run if the next keyword in the lexer is\n"
+"--   none of the registered initial keywords. If there's no default\n"
+"--   parser and no suitable initial keyword, the multisequence parser\n"
+"--   simply returns [false].\n"
+"--\n"
+"-- After creation, the following fields are added:\n"
+"--\n"
+"-- * [parse] the parsing function lexer->AST\n"
+"--\n"
+"-- * [sequences] the table of sequences, indexed by initial keywords.\n"
+"--\n"
+"-- * [add] method takes a sequence parser or a config table for\n"
+"--   [gg.sequence], and adds/replaces the corresponding sequence\n"
+"--   parser. If the keyword was already used, the former sequence is\n"
+"--   removed and a warning is issued.\n"
+"--\n"
+"-- * [get] method returns a sequence by its initial keyword\n"
+"--\n"
+"-- * [kind] == \"multisequence\"\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"function M.multisequence (p)\n"
+"   M.make_parser (\"multisequence\", p)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Add a sequence (might be just a config table for [gg.sequence])\n"
+"   -------------------------------------------------------------------\n"
+"   function p :add (s)\n"
+"      -- compile if necessary:\n"
+"      local keyword = type(s)=='table' and s[1]\n"
+"      if type(s)=='table' and not M.is_parser(s) then M.sequence(s) end\n"
+"      if M.is_parser(s)~='sequence' or type(keyword)~='string' then\n"
+"         if self.default then -- two defaults\n"
+"            error (\"In a multisequence parser, all but one sequences \"..\n"
+"                   \"must start with a keyword\")\n"
+"         else self.default = s end -- first default\n"
+"     else\n"
+"         if self.sequences[keyword] then -- duplicate keyword\n"
+"             -- TODO: warn that initial keyword `keyword` is overloaded in multiseq\n"
+"         end\n"
+"         self.sequences[keyword] = s\n"
+"     end\n"
+"   end -- </multisequence.add>\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Get the sequence starting with this keyword. [kw :: string]\n"
+"   -------------------------------------------------------------------\n"
+"   function p :get (kw) return self.sequences [kw] end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Remove the sequence starting with keyword [kw :: string]\n"
+"   -------------------------------------------------------------------\n"
+"   function p :del (kw)\n"
+"      if not self.sequences[kw] then\n"
+"          -- TODO: warn that we try to delete a non-existent entry\n"
+"      end\n"
+"      local removed = self.sequences[kw]\n"
+"      self.sequences[kw] = nil\n"
+"      return removed\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Parsing method\n"
+"   -------------------------------------------------------------------\n"
+"   function p :parse (lx)\n"
+"      local fli = lx:lineinfo_right()\n"
+"      local x = raw_parse_multisequence (lx, self.sequences, self.default)\n"
+"      local lli = lx:lineinfo_left()\n"
+"      return transform (x, self, fli, lli)\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Construction\n"
+"   -------------------------------------------------------------------\n"
+"   -- Register the sequences passed to the constructor. They're going\n"
+"   -- from the array part of the parser to the hash part of field\n"
+"   -- [sequences]\n"
+"   p.sequences = { }\n"
+"   for i=1, #p do p :add (p[i]); p[i] = nil end\n"
+"\n   -- FIXME: why is this commented out?\n"
+"   --if p.default and not is_parser(p.default) then sequence(p.default) end\n"
+"   return p\n"
+"end --</multisequence>\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Expression parser generator\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Expression configuration relies on three tables: [prefix], [infix]\n"
+"-- and [suffix]. Moreover, the primary parser can be replaced by a\n"
+"-- table: in this case the [primary] table will be passed to\n"
+"-- [gg.multisequence] to create a parser.\n"
+"--\n"
+"-- Each of these tables is a modified multisequence parser: the\n"
+"-- differences with respect to regular multisequence config tables are:\n"
+"--\n"
+"-- * the builder takes specific parameters:\n"
+"--   - for [prefix], it takes the result of the prefix sequence parser,\n"
+"--     and the prefixed expression\n"
+"--   - for [infix], it takes the left-hand-side expression, the results\n"
+"--     of the infix sequence parser, and the right-hand-side expression.\n"
+"--   - for [suffix], it takes the suffixed expression, and the result\n"
+"--     of the suffix sequence parser.\n"
+"--\n"
+"-- * the default field is a list, with parameters:\n"
+"--   - [parser] the raw parsing function\n"
+"--   - [transformers], as usual\n"
+"--   - [prec], the operator's precedence\n"
+"--   - [assoc] for [infix] table, the operator's associativity, which\n"
+"--     can be \"left\", \"right\" or \"flat\" (default to left)\n"
+"--\n"
+"-- In [p], useful fields are:\n"
+"-- * [transformers]: as usual\n"
+"-- * [name]: as usual\n"
+"-- * [primary]: the atomic expression parser, or a multisequence config\n"
+"--   table (mandatory)\n"
+"-- * [prefix]:  prefix  operators config table, see above.\n"
+"-- * [infix]:   infix   operators config table, see above.\n"
+"-- * [suffix]: suffix operators config table, see above.\n"
+"--\n"
+"-- After creation, these fields are added:\n"
+"-- * [kind] == \"expr\"\n"
+"-- * [parse] as usual\n"
+"-- * each table is turned into a multisequence, and therefore has an\n"
+"--   [add] method\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"function M.expr (p)\n"
+"   M.make_parser (\"expr\", p)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- parser method.\n"
+"   -- In addition to the lexer, it takes an optional precedence:\n"
+"   -- it won't read expressions whose precedence is lower or equal\n"
+"   -- to [prec].\n"
+"   -------------------------------------------------------------------\n"
+"   function p :parse (lx, prec)\n"
+"      prec = prec or 0\n"
+"\n      ------------------------------------------------------\n"
+"      -- Extract the right parser and the corresponding\n"
+"      -- options table, for (pre|in|suff)fix operators.\n"
+"      -- Options include prec, assoc, transformers.\n"
+"      ------------------------------------------------------\n"
+"      local function get_parser_info (tab)\n"
+"         local p2 = tab :get (lx :is_keyword (lx :peek()))\n"
+"         if p2 then -- keyword-based sequence found\n"
+"            local function parser(lx) return raw_parse_sequence(lx, p2) end\n"
+"            return parser, p2\n"
+"         else -- Got to use the default parser\n"
+"            local d = tab.default\n"
+"            if d then return d.parse or d.parser, d\n"
+"            else return false, false end\n"
+"         end\n"
+"      end\n"
+"\n      ------------------------------------------------------\n"
+"      -- Look for a prefix sequence. Multiple prefixes are\n"
+"      -- handled through the recursive [p.parse] call.\n"
+"      -- Notice the double-transform: one for the primary\n"
+"      -- expr, and one for the one with the prefix op.\n"
+"      ------------------------------------------------------\n"
+"      local function handle_prefix ()\n"
+"         local fli = lx :lineinfo_right()\n"
+"         local p2_func, p2 = get_parser_info (self.prefix)\n"
+"         local op = p2_func and p2_func (lx)\n"
+"         if op then -- Keyword-based sequence found\n"
+"            local ili = lx :lineinfo_right() -- Intermediate LineInfo\n"
+"            local e = p2.builder (op, self :parse (lx, p2.prec))\n"
+"            local lli = lx :lineinfo_left()\n"
+"            return transform (transform (e, p2, ili, lli), self, fli, lli)\n"
+"         else -- No prefix found, get a primary expression\n"
+"            local e = self.primary(lx)\n"
+"            local lli = lx :lineinfo_left()\n"
+"            return transform (e, self, fli, lli)\n"
+"         end\n"
+"      end --</expr.parse.handle_prefix>\n"
+"\n      ------------------------------------------------------\n"
+"      -- Look for an infix sequence+right-hand-side operand.\n"
+"      -- Return the whole binary expression result,\n"
+"      -- or false if no operator was found.\n"
+"      ------------------------------------------------------\n"
+"      local function handle_infix (e)\n"
+"         local p2_func, p2 = get_parser_info (self.infix)\n"
+"         if not p2 then return false end\n"
+"\n         -----------------------------------------\n"
+"         -- Handle flattening operators: gather all operands\n"
+"         -- of the series in [list]; when a different operator\n"
+"         -- is found, stop, build from [list], [transform] and\n"
+"         -- return.\n"
+"         -----------------------------------------\n"
+"         if (not p2.prec or p2.prec>prec) and p2.assoc==\"flat\" then\n"
+"            local fli = lx:lineinfo_right()\n"
+"            local pflat, list = p2, { e }\n"
+"            repeat\n"
+"               local op = p2_func(lx)\n"
+"               if not op then break end\n"
+"               table.insert (list, self:parse (lx, p2.prec))\n"
+"               local _ -- We only care about checking that p2==pflat\n"
+"               _, p2 = get_parser_info (self.infix)\n"
+"            until p2 ~= pflat\n"
+"            local e2 = pflat.builder (list)\n"
+"            local lli = lx:lineinfo_left()\n"
+"            return transform (transform (e2, pflat, fli, lli), self, fli, lli)\n"
+"\n         -----------------------------------------\n"
+"         -- Handle regular infix operators: [e] the LHS is known,\n"
+"         -- just gather the operator and [e2] the RHS.\n"
+"         -- Result goes in [e3].\n"
+"         -----------------------------------------\n"
+"         elseif p2.prec and p2.prec>prec or\n"
+"                p2.prec==prec and p2.assoc==\"right\" then\n"
+"            local fli = e.lineinfo.first -- lx:lineinfo_right()\n"
+"            local op = p2_func(lx)\n"
+"            if not op then return false end\n"
+"            local e2 = self:parse (lx, p2.prec)\n"
+"            local e3 = p2.builder (e, op, e2)\n"
+"            local lli = lx:lineinfo_left()\n"
+"            return transform (transform (e3, p2, fli, lli), self, fli, lli)\n"
+"\n         -----------------------------------------\n"
+"         -- Check for non-associative operators, and complain if applicable.\n"
+"         -----------------------------------------\n"
+"         elseif p2.assoc==\"none\" and p2.prec==prec then\n"
+"            M.parse_error (lx, \"non-associative operator!\")\n"
+"\n         -----------------------------------------\n"
+"         -- No infix operator suitable at that precedence\n"
+"         -----------------------------------------\n"
+"         else return false end\n"
+"\n      end --</expr.parse.handle_infix>\n"
+"\n      ------------------------------------------------------\n"
+"      -- Look for a suffix sequence.\n"
+"      -- Return the result of suffix operator on [e],\n"
+"      -- or false if no operator was found.\n"
+"      ------------------------------------------------------\n"
+"      local function handle_suffix (e)\n"
+"         -- FIXME bad fli, must take e.lineinfo.first\n"
+"         local p2_func, p2 = get_parser_info (self.suffix)\n"
+"         if not p2 then return false end\n"
+"         if not p2.prec or p2.prec>=prec then\n"
+"            --local fli = lx:lineinfo_right()\n"
+"            local fli = e.lineinfo.first\n"
+"            local op = p2_func(lx)\n"
+"            if not op then return false end\n"
+"            local lli = lx:lineinfo_left()\n"
+"            e = p2.builder (e, op)\n"
+"            e = transform (transform (e, p2, fli, lli), self, fli, lli)\n"
+"            return e\n"
+"         end\n"
+"         return false\n"
+"      end --</expr.parse.handle_suffix>\n"
+"\n      ------------------------------------------------------\n"
+"      -- Parser body: read suffix and (infix+operand)\n"
+"      -- extensions as long as we're able to fetch more at\n"
+"      -- this precedence level.\n"
+"      ------------------------------------------------------\n"
+"      local e = handle_prefix()\n"
+"      repeat\n"
+"         local x = handle_suffix (e); e = x or e\n"
+"         local y = handle_infix   (e); e = y or e\n"
+"      until not (x or y)\n"
+"\n      -- No transform: it already happened in operators handling\n"
+"      return e\n"
+"   end --</expr.parse>\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Construction\n"
+"   -------------------------------------------------------------------\n"
+"   if not p.primary then p.primary=p[1]; p[1]=nil end\n"
+"   for _, t in ipairs{ \"primary\", \"prefix\", \"infix\", \"suffix\" } do\n"
+"      if not p[t] then p[t] = { } end\n"
+"      if not M.is_parser(p[t]) then M.multisequence(p[t]) end\n"
+"   end\n"
+"   function p:add(...) return self.primary:add(...) end\n"
+"   return p\n"
+"end --</expr>\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- List parser generator\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"-- In [p], the following fields can be provided in input:\n"
+"--\n"
+"-- * [builder]: takes list of subparser results, returns AST\n"
+"-- * [transformers]: as usual\n"
+"-- * [name]: as usual\n"
+"--\n"
+"-- * [terminators]: list of strings representing the keywords which\n"
+"--   might mark the end of the list. When non-empty, the list is\n"
+"--   allowed to be empty. A string is treated as a single-element\n"
+"--   table, whose element is that string, e.g. [\"do\"] is the same as\n"
+"--   [{\"do\"}].\n"
+"--\n"
+"-- * [separators]: list of strings representing the keywords which can\n"
+"--   separate elements of the list. When non-empty, one of these\n"
+"--   keyword has to be found between each element. Lack of a separator\n"
+"--   indicates the end of the list. A string is treated as a\n"
+"--   single-element table, whose element is that string, e.g. [\"do\"]\n"
+"--   is the same as [{\"do\"}]. If [terminators] is empty/nil, then\n"
+"--   [separators] has to be non-empty.\n"
+"--\n"
+"-- After creation, the following fields are added:\n"
+"-- * [parse] the parsing function lexer->AST\n"
+"-- * [kind] == \"list\"\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"function M.list (p)\n"
+"   M.make_parser (\"list\", p)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Parsing method\n"
+"   -------------------------------------------------------------------\n"
+"   function p :parse (lx)\n"
+"\n      ------------------------------------------------------\n"
+"      -- Used to quickly check whether there's a terminator\n"
+"      -- or a separator immediately ahead\n"
+"      ------------------------------------------------------\n"
+"      local function peek_is_in (keywords)\n"
+"         return keywords and lx:is_keyword(lx:peek(), unpack(keywords)) end\n"
+"\n      local x = { }\n"
+"      local fli = lx :lineinfo_right()\n"
+"\n      -- if there's a terminator to start with, don't bother trying\n"
+"      local is_empty_list = self.terminators and (peek_is_in (self.terminators) or lx:peek().tag==\"Eof\")\n"
+"      if not is_empty_list then\n"
+"         repeat\n"
+"             local item = self.primary(lx)\n"
+"             table.insert (x, item) -- read one element\n"
+"         until\n"
+"            -- There's a separator list specified, and next token isn't in it.\n"
+"            -- Otherwise, consume it with [lx:next()]\n"
+"            self.separators and not(peek_is_in (self.separators) and lx:next()) or\n"
+"            -- Terminator token ahead\n"
+"            peek_is_in (self.terminators) or\n"
+"            -- Last reason: end of file reached\n"
+"            lx:peek().tag==\"Eof\"\n"
+"      end\n"
+"\n      local lli = lx:lineinfo_left()\n"
+"\n      -- Apply the builder. It can be a string, or a callable value,\n"
+"      -- or simply nothing.\n"
+"      local b = self.builder\n"
+"      if b then\n"
+"         if type(b)==\"string\" then x.tag = b -- b is a string, use it as a tag\n"
+"         elseif type(b)==\"function\" then x=b(x)\n"
+"         else\n"
+"            local bmt = getmetatable(b)\n"
+"            if bmt and bmt.__call then x=b(x) end\n"
+"         end\n"
+"      end\n"
+"      return transform (x, self, fli, lli)\n"
+"   end --</list.parse>\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Construction\n"
+"   -------------------------------------------------------------------\n"
+"   if not p.primary then p.primary = p[1]; p[1] = nil end\n"
+"   if type(p.terminators) == \"string\" then p.terminators = { p.terminators }\n"
+"   elseif p.terminators and #p.terminators == 0 then p.terminators = nil end\n"
+"   if type(p.separators) == \"string\" then p.separators = { p.separators }\n"
+"   elseif p.separators and #p.separators == 0 then p.separators = nil end\n"
+"\n   return p\n"
+"end --</list>\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Keyword-conditioned parser generator\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Only apply a parser if a given keyword is found. The result of\n"
+"-- [gg.onkeyword] parser is the result of the subparser (modulo\n"
+"-- [transformers] applications).\n"
+"--\n"
+"-- lineinfo: the keyword is *not* included in the boundaries of the\n"
+"-- resulting lineinfo. A review of all usages of gg.onkeyword() in the\n"
+"-- implementation of metalua has shown that it was the appropriate choice\n"
+"-- in every case.\n"
+"--\n"
+"-- Input fields:\n"
+"--\n"
+"-- * [name]: as usual\n"
+"--\n"
+"-- * [transformers]: as usual\n"
+"--\n"
+"-- * [peek]: if non-nil, the conditioning keyword is left in the lexeme\n"
+"--   stream instead of being consumed.\n"
+"--\n"
+"-- * [primary]: the subparser.\n"
+"--\n"
+"-- * [keywords]: list of strings representing triggering keywords.\n"
+"--\n"
+"-- * Table-part entries can contain strings, and/or exactly one parser.\n"
+"--   Strings are put in [keywords], and the parser is put in [primary].\n"
+"--\n"
+"-- After the call, the following fields will be set:\n"
+"--\n"
+"-- * [parse] the parsing method\n"
+"-- * [kind] == \"onkeyword\"\n"
+"-- * [primary]\n"
+"-- * [keywords]\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"function M.onkeyword (p)\n"
+"   M.make_parser (\"onkeyword\", p)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Parsing method\n"
+"   -------------------------------------------------------------------\n"
+"   function p :parse (lx)\n"
+"      if lx :is_keyword (lx:peek(), unpack(self.keywords)) then\n"
+"         local fli = lx:lineinfo_right()\n"
+"         if not self.peek then lx:next() end\n"
+"         local content = self.primary (lx)\n"
+"         local lli = lx:lineinfo_left()\n"
+"         local li = content.lineinfo or { }\n"
+"         fli, lli = li.first or fli, li.last or lli\n"
+"         return transform (content, p, fli, lli)\n"
+"      else return false end\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Construction\n"
+"   -------------------------------------------------------------------\n"
+"   if not p.keywords then p.keywords = { } end\n"
+"   for _, x in ipairs(p) do\n"
+"      if type(x)==\"string\" then table.insert (p.keywords, x)\n"
+"      else assert (not p.primary and M.is_parser (x)); p.primary = x end\n"
+"   end\n"
+"   assert (next (p.keywords), \"Missing trigger keyword in gg.onkeyword\")\n"
+"   assert (p.primary, 'no primary parser in gg.onkeyword')\n"
+"   return p\n"
+"end --</onkeyword>\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Optional keyword consummer pseudo-parser generator\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- This doesn't return a real parser, just a function. That function parses\n"
+"-- one of the keywords passed as parameters, and returns it. It returns\n"
+"-- [false] if no matching keyword is found.\n"
+"--\n"
+"-- Notice that tokens returned by lexer already carry lineinfo, therefore\n"
+"-- there's no need to add them, as done usually through transform() calls.\n"
+"-------------------------------------------------------------------------------\n"
+"function M.optkeyword (...)\n"
+"   local args = {...}\n"
+"   if type (args[1]) == \"table\" then\n"
+"      assert (#args == 1)\n"
+"      args = args[1]\n"
+"   end\n"
+"   for _, v in ipairs(args) do assert (type(v)==\"string\") end\n"
+"   return function (lx)\n"
+"      local x = lx:is_keyword (lx:peek(), unpack (args))\n"
+"      if x then lx:next(); return x\n"
+"      else return false end\n"
+"   end\n"
+"end\n"
+"\n\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Run a parser with a special lexer\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- This doesn't return a real parser, just a function.\n"
+"-- First argument is the lexer class to be used with the parser,\n"
+"-- 2nd is the parser itself.\n"
+"-- The resulting parser returns whatever the argument parser does.\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"function M.with_lexer(new_lexer, parser)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Most gg functions take their parameters in a table, so it's\n"
+"   -- better to silently accept when with_lexer{ } is called with\n"
+"   -- its arguments in a list:\n"
+"   -------------------------------------------------------------------\n"
+"   if not parser and #new_lexer==2 and type(new_lexer[1])=='table' then\n"
+"      return M.with_lexer(unpack(new_lexer))\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Save the current lexer, switch it for the new one, run the parser,\n"
+"   -- restore the previous lexer, even if the parser caused an error.\n"
+"   -------------------------------------------------------------------\n"
+"   return function (lx)\n"
+"      local old_lexer = getmetatable(lx)\n"
+"      lx:sync()\n"
+"      setmetatable(lx, new_lexer)\n"
+"      local status, result = pcall(parser, lx)\n"
+"      lx:sync()\n"
+"      setmetatable(lx, old_lexer)\n"
+"      if status then return result else error(result) end\n"
+"   end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Make sure a parser is used and returns successfully.\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"function M.nonempty(primary)\n"
+"    local p = M.make_parser('non-empty list', { primary = primary, name=primary.name })\n"
+"    function p :parse (lx)\n"
+"         local fli = lx:lineinfo_right()\n"
+"         local content = self.primary (lx)\n"
+"         local lli = lx:lineinfo_left()\n"
+"         local li = content.lineinfo or { }\n"
+"         fli, lli = li.first or fli, li.last or lli\n"
+"         if #content == 0 then\n"
+"           M.parse_error (lx, \"`%s' must not be empty.\", self.name or \"list\")\n"
+"       else\n"
+"           return transform (content, self, fli, lli)\n"
+"       end\n"
+"    end\n"
+"    return p\n"
+"end\n"
+"\nlocal FUTURE_MT = { }\n"
+"function FUTURE_MT:__tostring() return \"<Proxy parser module>\" end\n"
+"function FUTURE_MT:__newindex(key, value) error \"don't write in futures\" end\n"
+"function FUTURE_MT :__index (parser_name)\n"
+"    return function(...)\n"
+"        local p, m = rawget(self, '__path'), self.__module\n"
+"        if p then for _, name in ipairs(p) do\n"
+"            m=rawget(m, name)\n"
+"            if not m then error (\"Submodule '\"..name..\"' undefined\") end\n"
+"        end end\n"
+"        local f = rawget(m, parser_name)\n"
+"        if not f then error (\"Parser '\"..parser_name..\"' undefined\") end\n"
+"        return f(...)\n"
+"    end\n"
+"end\n"
+"\nfunction M.future(module, ...)\n"
+"    checks('table')\n"
+"    local path = ... and {...}\n"
+"    if path then for _, x in ipairs(path) do \n"
+"        assert(type(x)=='string', \"Bad future arg\")\n"
+"    end end\n"
+"    local self = { __module = module,\n"
+"                   __path   = path }\n"
+"    return setmetatable(self, FUTURE_MT)\n"
+"end\n"
+"\nreturn M\n",
true, false);
// End of /metalua/grammar/generator.lua
Lua5_1.provide_file("/metalua/grammar/", "lexer.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n--require 'checks'\n"
+"\nlocal M = { }\n"
+"\nlocal lexer = { alpha={ }, sym={ } }\n"
+"lexer.__index=lexer\n"
+"lexer.__type='lexer.stream'\n"
+"\nM.lexer = lexer\n"
+"\n\n"
+"local debugf = function() end\n"
+"-- local debugf=printf\n"
+"\n----------------------------------------------------------------------\n"
+"-- Some locale settings produce bad results, e.g. French locale\n"
+"-- expect float numbers to use commas instead of periods.\n"
+"-- TODO: change number parser into something loclae-independent,\n"
+"-- locales are nasty.\n"
+"----------------------------------------------------------------------\n"
+"os.setlocale('C')\n"
+"\nlocal MT = { }\n"
+"\nM.metatables=MT\n"
+"\n----------------------------------------------------------------------\n"
+"-- Create a new metatable, for a new class of objects.\n"
+"----------------------------------------------------------------------\n"
+"local function new_metatable(name)\n"
+"    local mt = { __type = 'lexer.'..name };\n"
+"    mt.__index = mt\n"
+"    MT[name] = mt\n"
+"end\n"
+"\n\n"
+"----------------------------------------------------------------------\n"
+"-- Position: represent a point in a source file.\n"
+"----------------------------------------------------------------------\n"
+"new_metatable 'position'\n"
+"\nlocal position_idx=1\n"
+"\nfunction M.new_position(line, column, offset, source)\n"
+"--    checks('number', 'number', 'number', 'string')\n"
+"    local id = position_idx; position_idx = position_idx+1\n"
+"    return setmetatable({line=line, column=column, offset=offset,\n"
+"                         source=source, id=id}, MT.position)\n"
+"end\n"
+"\nfunction MT.position :__tostring()\n"
+"    return string.format(\"<%s%s|L%d|C%d|K%d>\",\n"
+"        self.comments and \"C|\" or \"\",\n"
+"        self.source, self.line, self.column, self.offset)\n"
+"end\n"
+"\n\n"
+"\n----------------------------------------------------------------------\n"
+"-- Position factory: convert offsets into line/column/offset positions.\n"
+"----------------------------------------------------------------------\n"
+"new_metatable 'position_factory'\n"
+"\nfunction M.new_position_factory(src, src_name)\n"
+"    -- assert(type(src)=='string')\n"
+"    -- assert(type(src_name)=='string')\n"
+"    local lines = { 1 }\n"
+"    for offset in src :gmatch '\\n"
+"()' do table.insert(lines, offset) end\n"
+"    local max = #src+1\n"
+"    table.insert(lines, max+1) -- +1 includes Eof\n"
+"    return setmetatable({ src_name=src_name, line2offset=lines, max=max },\n"
+"        MT.position_factory)\n"
+"end\n"
+"\nfunction MT.position_factory :get_position (offset)\n"
+"    -- assert(type(offset)=='number')\n"
+"    assert(offset<=self.max)\n"
+"    local line2offset = self.line2offset\n"
+"    local left  = self.last_left or 1\n"
+"    if offset<line2offset[left] then left=1 end\n"
+"    local right = left+1\n"
+"    if line2offset[right]<=offset then right = right+1 end\n"
+"    if line2offset[right]<=offset then right = #line2offset end\n"
+"    while true do\n"
+"        -- print (\"  trying lines \"..left..\"/\"..right..\", offsets \"..line2offset[left]..\n"
+"        --        \"/\"..line2offset[right]..\" for offset \"..offset)\n"
+"        -- assert(line2offset[left]<=offset)\n"
+"        -- assert(offset<line2offset[right])\n"
+"        -- assert(left<right)\n"
+"        if left+1==right then break end\n"
+"        local middle = math.floor((left+right)/2)\n"
+"        if line2offset[middle]<=offset then left=middle else right=middle end\n"
+"    end\n"
+"    -- assert(left+1==right)\n"
+"    -- printf(\"found that offset %d is between %d and %d, hence on line %d\",\n"
+"    --    offset, line2offset[left], line2offset[right], left)\n"
+"    local line = left\n"
+"    local column = offset - line2offset[line] + 1\n"
+"    self.last_left = left\n"
+"    return M.new_position(line, column, offset, self.src_name)\n"
+"end\n"
+"\n\n"
+"\n----------------------------------------------------------------------\n"
+"-- Lineinfo: represent a node's range in a source file;\n"
+"-- embed information about prefix and suffix comments.\n"
+"----------------------------------------------------------------------\n"
+"new_metatable 'lineinfo'\n"
+"\nfunction M.new_lineinfo(first, last)\n"
+"--    checks('lexer.position', 'lexer.position')\n"
+"    return setmetatable({first=first, last=last}, MT.lineinfo)\n"
+"end\n"
+"\nfunction MT.lineinfo :__tostring()\n"
+"    local fli, lli = self.first, self.last\n"
+"    local line   = fli.line;   if line~=lli.line     then line  =line  ..'-'..lli.line   end\n"
+"    local column = fli.column; if column~=lli.column then column=column..'-'..lli.column end\n"
+"    local offset = fli.offset; if offset~=lli.offset then offset=offset..'-'..lli.offset end\n"
+"    return string.format(\"<%s%s|L%s|C%s|K%s%s>\",\n"
+"                         fli.comments and \"C|\" or \"\",\n"
+"                         fli.source, line, column, offset,\n"
+"                         lli.comments and \"|C\" or \"\")\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Token: atomic Lua language element, with a category, a content,\n"
+"-- and some lineinfo relating it to its original source.\n"
+"----------------------------------------------------------------------\n"
+"new_metatable 'token'\n"
+"\nfunction M.new_token(tag, content, lineinfo)\n"
+"    --printf(\"TOKEN `%s{ %q, lineinfo = %s} boundaries %d, %d\",\n"
+"    --       tag, content, tostring(lineinfo), lineinfo.first.id, lineinfo.last.id)\n"
+"    return setmetatable({tag=tag, lineinfo=lineinfo, content}, MT.token)\n"
+"end\n"
+"\nfunction MT.token :__tostring()\n"
+"    --return string.format(\"`%s{ %q, %s }\", self.tag, self[1], tostring(self.lineinfo))\n"
+"    return string.format(\"`%s %q\", self.tag, self[1])\n"
+"end\n"
+"\n\n"
+"----------------------------------------------------------------------\n"
+"-- Comment: series of comment blocks with associated lineinfo.\n"
+"-- To be attached to the tokens just before and just after them.\n"
+"----------------------------------------------------------------------\n"
+"new_metatable 'comment'\n"
+"\nfunction M.new_comment(lines)\n"
+"    local first = lines[1].lineinfo.first\n"
+"    local last  = lines[#lines].lineinfo.last\n"
+"    local lineinfo = M.new_lineinfo(first, last)\n"
+"    return setmetatable({lineinfo=lineinfo, unpack(lines)}, MT.comment)\n"
+"end\n"
+"\nfunction MT.comment :text()\n"
+"    local last_line = self[1].lineinfo.last.line\n"
+"    local acc = { }\n"
+"    for i, line in ipairs(self) do\n"
+"        local nreturns = line.lineinfo.first.line - last_line\n"
+"        table.insert(acc, (\"\\n"
+"\"):rep(nreturns))\n"
+"        table.insert(acc, line[1])\n"
+"    end\n"
+"    return table.concat(acc)\n"
+"end\n"
+"\nfunction M.new_comment_line(text, lineinfo, nequals)\n"
+"--    checks('string', 'lexer.lineinfo', '?number')\n"
+"    return { lineinfo = lineinfo, text, nequals }\n"
+"end\n"
+"\n\n"
+"\n----------------------------------------------------------------------\n"
+"-- Patterns used by [lexer :extract] to decompose the raw string into\n"
+"-- correctly tagged tokens.\n"
+"----------------------------------------------------------------------\n"
+"lexer.patterns = {\n"
+"   spaces              = \"^[ \\r\\n"
+"\\t]*()\",\n"
+"   short_comment       = \"^%-%-([^\\n"
+"]*)\\n"
+"?()\",\n"
+"   --final_short_comment = \"^%-%-([^\\n"
+"]*)()$\",\n"
+"   long_comment        = \"^%-%-%[(=*)%[\\n"
+"?(.-)%]%1%]()\",\n"
+"   long_string         = \"^%[(=*)%[\\n"
+"?(.-)%]%1%]()\",\n"
+"   number_mantissa     = { \"^%d+%.?%d*()\", \"^%d*%.%d+()\" },\n"
+"   number_mantissa_hex = { \"^%x+%.?%x*()\", \"^%x*%.%x+()\" }, --Lua5.1 and Lua5.2\n"
+"   number_exponant     = \"^[eE][%+%-]?%d+()\",\n"
+"   number_exponant_hex = \"^[pP][%+%-]?%d+()\", --Lua5.2\n"
+"   number_hex          = \"^0[xX]()\",\n"
+"   word                = \"^([%a_][%w_]*)()\"\n"
+"}\n"
+"\n----------------------------------------------------------------------\n"
+"-- unescape a whole string, applying [unesc_digits] and\n"
+"-- [unesc_letter] as many times as required.\n"
+"----------------------------------------------------------------------\n"
+"local function unescape_string (s)\n"
+"\n   -- Turn the digits of an escape sequence into the corresponding\n"
+"   -- character, e.g. [unesc_digits(\"123\") == string.char(123)].\n"
+"   local function unesc_digits (backslashes, digits)\n"
+"      if #backslashes%2==0 then\n"
+"         -- Even number of backslashes, they escape each other, not the digits.\n"
+"         -- Return them so that unesc_letter() can treat them\n"
+"         return backslashes..digits\n"
+"      else\n"
+"         -- Remove the odd backslash, which escapes the number sequence.\n"
+"         -- The rest will be returned and parsed by unesc_letter()\n"
+"         backslashes = backslashes :sub (1,-2)\n"
+"      end\n"
+"      local k, j, i = digits :reverse() :byte(1, 3)\n"
+"      local z = string.byte \"0\"\n"
+"      local code = (k or z) + 10*(j or z) + 100*(i or z) - 111*z\n"
+"      if code > 255 then\n"
+"         error (\"Illegal escape sequence '\\\\\"..digits..\n"
+"                \"' in string: ASCII codes must be in [0..255]\")\n"
+"      end\n"
+"      local c = string.char (code)\n"
+"      if c == '\\\\' then c = '\\\\\\\\' end -- parsed by unesc_letter (test: \"\\092b\" --> \"\\\\b\")\n"
+"      return backslashes..c\n"
+"   end\n"
+"\n   -- Turn hex digits of escape sequence into char.\n"
+"   local function unesc_hex(backslashes, digits)\n"
+"     if #backslashes%2==0 then\n"
+"       return backslashes..'x'..digits\n"
+"     else\n"
+"       backslashes = backslashes :sub (1,-2)\n"
+"     end\n"
+"     local c = string.char(tonumber(digits,16))\n"
+"     if c == '\\\\' then c = '\\\\\\\\' end -- parsed by unesc_letter (test: \"\\x5cb\" --> \"\\\\b\")\n"
+"     return backslashes..c\n"
+"   end\n"
+"\n   -- Handle Lua 5.2 \\z sequences\n"
+"   local function unesc_z(backslashes, more)\n"
+"     if #backslashes%2==0 then\n"
+"       return backslashes..more\n"
+"     else\n"
+"       return backslashes :sub (1,-2)\n"
+"     end\n"
+"   end\n"
+"\n   -- Take a letter [x], and returns the character represented by the\n"
+"   -- sequence ['\\\\'..x], e.g. [unesc_letter \"n\" == \"\\n"
+"\"].\n"
+"   local function unesc_letter(x)\n"
+"      local t = {\n"
+"         a = \"\\a\", b = \"\\b\", f = \"\\f\",\n"
+"         n = \"\\n"
+"\", r = \"\\r\", t = \"\\t\", v = \"\\v\",\n"
+"         [\"\\\\\"] = \"\\\\\", [\"'\"] = \"'\", ['\"'] = '\"', [\"\\n"
+"\"] = \"\\n"
+"\" }\n"
+"      return t[x] or x\n"
+"   end\n"
+"\n   s = s: gsub (\"(\\\\+)(z%s*)\", unesc_z)  -- Lua 5.2\n"
+"   s = s: gsub (\"(\\\\+)([0-9][0-9]?[0-9]?)\", unesc_digits)\n"
+"   s = s: gsub (\"(\\\\+)x([0-9a-fA-F][0-9a-fA-F])\", unesc_hex) -- Lua 5.2\n"
+"   s = s: gsub (\"\\\\(%D)\",unesc_letter)\n"
+"   return s\n"
+"end\n"
+"\nlexer.extractors = {\n"
+"   \"extract_long_comment\", \"extract_short_comment\",\n"
+"   \"extract_short_string\", \"extract_word\", \"extract_number\",\n"
+"   \"extract_long_string\", \"extract_symbol\" }\n"
+"\n\n"
+"\n----------------------------------------------------------------------\n"
+"-- Really extract next token from the raw string\n"
+"-- (and update the index).\n"
+"-- loc: offset of the position just after spaces and comments\n"
+"-- previous_i: offset in src before extraction began\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract ()\n"
+"   local attached_comments = { }\n"
+"   local function gen_token(...)\n"
+"      local token = M.new_token(...)\n"
+"      if #attached_comments>0 then -- attach previous comments to token\n"
+"         local comments = M.new_comment(attached_comments)\n"
+"         token.lineinfo.first.comments = comments\n"
+"         if self.lineinfo_last_extracted then\n"
+"            self.lineinfo_last_extracted.comments = comments\n"
+"         end\n"
+"         attached_comments = { }\n"
+"      end\n"
+"      token.lineinfo.first.facing = self.lineinfo_last_extracted\n"
+"      self.lineinfo_last_extracted.facing = assert(token.lineinfo.first)\n"
+"      self.lineinfo_last_extracted = assert(token.lineinfo.last)\n"
+"      return token\n"
+"   end\n"
+"   while true do -- loop until a non-comment token is found\n"
+"\n       -- skip whitespaces\n"
+"       self.i = self.src:match (self.patterns.spaces, self.i)\n"
+"       if self.i>#self.src then\n"
+"         local fli = self.posfact :get_position (#self.src+1)\n"
+"         local lli = self.posfact :get_position (#self.src+1) -- ok?\n"
+"         local tok = gen_token(\"Eof\", \"eof\", M.new_lineinfo(fli, lli))\n"
+"         tok.lineinfo.last.facing = lli\n"
+"         return tok\n"
+"       end\n"
+"       local i_first = self.i -- loc = position after whitespaces\n"
+"\n       -- try every extractor until a token is found\n"
+"       for _, extractor in ipairs(self.extractors) do\n"
+"           local tag, content, xtra = self [extractor] (self)\n"
+"           if tag then\n"
+"               local fli = self.posfact :get_position (i_first)\n"
+"               local lli = self.posfact :get_position (self.i-1)\n"
+"               local lineinfo = M.new_lineinfo(fli, lli)\n"
+"               if tag=='Comment' then\n"
+"                   local prev_comment = attached_comments[#attached_comments]\n"
+"                   if not xtra -- new comment is short\n"
+"                   and prev_comment and not prev_comment[2] -- prev comment is short\n"
+"                   and prev_comment.lineinfo.last.line+1==fli.line then -- adjascent lines\n"
+"                       -- concat with previous comment\n"
+"                       prev_comment[1] = prev_comment[1]..\"\\n"
+"\"..content -- TODO quadratic, BAD!\n"
+"                       prev_comment.lineinfo.last = lli\n"
+"                   else -- accumulate comment\n"
+"                       local comment = M.new_comment_line(content, lineinfo, xtra)\n"
+"                       table.insert(attached_comments, comment)\n"
+"                   end\n"
+"                   break -- back to skipping spaces\n"
+"               else -- not a comment: real token, then\n"
+"                   return gen_token(tag, content, lineinfo)\n"
+"               end -- if token is a comment\n"
+"           end -- if token found\n"
+"       end -- for each extractor\n"
+"   end -- while token is a comment\n"
+"end -- :extract()\n"
+"\n\n"
+"\n\n"
+"----------------------------------------------------------------------\n"
+"-- Extract a short comment.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_short_comment()\n"
+"    -- TODO: handle final_short_comment\n"
+"    local content, j = self.src :match (self.patterns.short_comment, self.i)\n"
+"    if content then self.i=j; return 'Comment', content, nil end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Extract a long comment.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_long_comment()\n"
+"    local equals, content, j = self.src:match (self.patterns.long_comment, self.i)\n"
+"    if j then self.i = j; return \"Comment\", content, #equals end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Extract a '...' or \"...\" short string.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_short_string()\n"
+"   local k = self.src :sub (self.i,self.i)   -- first char\n"
+"   if k~=[[']] and k~=[[\"]] then return end  -- no match'\n"
+"   local i = self.i + 1\n"
+"   local j = i\n"
+"   while true do\n"
+"      local x,y; x, j, y = self.src :match (\"([\\\\\\r\\n"
+"\"..k..\"])()(.?)\", j)  -- next interesting char\n"
+"      if x == '\\\\' then\n"
+"        if y == 'z' then -- Lua 5.2 \\z\n"
+"          j = self.src :match (\"^%s*()\", j+1)\n"
+"        else\n"
+"          j=j+1  -- escaped char\n"
+"        end\n"
+"      elseif x == k then break -- end of string\n"
+"      else\n"
+"         assert (not x or x=='\\r' or x=='\\n"
+"')\n"
+"         return nil, 'Unterminated string'\n"
+"      end\n"
+"   end\n"
+"   self.i = j\n"
+"\n   return 'String', unescape_string (self.src :sub (i,j-2))\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Extract Id or Keyword.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_word()\n"
+"   local word, j = self.src:match (self.patterns.word, self.i)\n"
+"   if word then\n"
+"      self.i = j\n"
+"      return (self.alpha [word] and 'Keyword' or 'Id'), word\n"
+"   end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Extract Number.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_number()\n"
+"   local j = self.src:match(self.patterns.number_hex, self.i)\n"
+"   if j then\n"
+"      j = self.src:match (self.patterns.number_mantissa_hex[1], j) or\n"
+"          self.src:match (self.patterns.number_mantissa_hex[2], j)\n"
+"      if j then\n"
+"         j = self.src:match (self.patterns.number_exponant_hex, j) or j\n"
+"      end\n"
+"   else\n"
+"      j = self.src:match (self.patterns.number_mantissa[1], self.i) or\n"
+"          self.src:match (self.patterns.number_mantissa[2], self.i)\n"
+"      if j then\n"
+"         j = self.src:match (self.patterns.number_exponant, j) or j\n"
+"      end\n"
+"   end\n"
+"   if not j then return end\n"
+"   -- Number found, interpret with tonumber() and return it\n"
+"   local str = self.src:sub (self.i, j-1)\n"
+"   -- :TODO: tonumber on Lua5.2 floating hex may or may not work on Lua5.1\n"
+"   local n = tonumber (str)\n"
+"   if not n then error(str..\" is not a valid number according to tonumber()\") end\n"
+"   self.i = j\n"
+"   return 'Number', n\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Extract long string.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_long_string()\n"
+"   local _, content, j = self.src :match (self.patterns.long_string, self.i)\n"
+"   if j then self.i = j; return 'String', content end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Extract symbol.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :extract_symbol()\n"
+"   local k = self.src:sub (self.i,self.i)\n"
+"   local symk = self.sym [k]  -- symbols starting with `k`\n"
+"   if not symk then\n"
+"      self.i = self.i + 1\n"
+"      return 'Keyword', k\n"
+"   end\n"
+"   for _, sym in pairs (symk) do\n"
+"      if sym == self.src:sub (self.i, self.i + #sym - 1) then\n"
+"         self.i = self.i + #sym\n"
+"         return 'Keyword', sym\n"
+"      end\n"
+"   end\n"
+"   self.i = self.i+1\n"
+"   return 'Keyword', k\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Add a keyword to the list of keywords recognized by the lexer.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :add (w, ...)\n"
+"   assert(not ..., \"lexer :add() takes only one arg, although possibly a table\")\n"
+"   if type (w) == \"table\" then\n"
+"      for _, x in ipairs (w) do self :add (x) end\n"
+"   else\n"
+"      if w:match (self.patterns.word .. \"$\") then self.alpha [w] = true\n"
+"      elseif w:match \"^%p%p+$\" then\n"
+"         local k = w:sub(1,1)\n"
+"         local list = self.sym [k]\n"
+"         if not list then list = { }; self.sym [k] = list end\n"
+"         table.insert (list, w)\n"
+"      elseif w:match \"^%p$\" then return\n"
+"      else error \"Invalid keyword\" end\n"
+"   end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Return the [n]th next token, without consuming it.\n"
+"-- [n] defaults to 1. If it goes pass the end of the stream, an EOF\n"
+"-- token is returned.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :peek (n)\n"
+"    if not n then n=1 end\n"
+"    if n > #self.peeked then\n"
+"        for i = #self.peeked+1, n do\n"
+"            self.peeked [i] = self :extract()\n"
+"        end\n"
+"    end\n"
+"    return self.peeked [n]\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Return the [n]th next token, removing it as well as the 0..n-1\n"
+"-- previous tokens. [n] defaults to 1. If it goes pass the end of the\n"
+"-- stream, an EOF token is returned.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :next (n)\n"
+"   n = n or 1\n"
+"   self :peek (n)\n"
+"   local a\n"
+"   for i=1,n do\n"
+"      a = table.remove (self.peeked, 1)\n"
+"      -- TODO: is this used anywhere? I think not.  a.lineinfo.last may be nil.\n"
+"      --self.lastline = a.lineinfo.last.line\n"
+"   end\n"
+"   self.lineinfo_last_consumed = a.lineinfo.last\n"
+"   return a\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Returns an object which saves the stream's current state.\n"
+"----------------------------------------------------------------------\n"
+"-- FIXME there are more fields than that to save\n"
+"function lexer :save () return { self.i; {unpack(self.peeked) } } end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Restore the stream's state, as saved by method [save].\n"
+"----------------------------------------------------------------------\n"
+"-- FIXME there are more fields than that to restore\n"
+"function lexer :restore (s) self.i=s[1]; self.peeked=s[2] end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Resynchronize: cancel any token in self.peeked, by emptying the\n"
+"-- list and resetting the indexes\n"
+"----------------------------------------------------------------------\n"
+"function lexer :sync()\n"
+"   local p1 = self.peeked[1]\n"
+"   if p1 then\n"
+"      local li_first = p1.lineinfo.first\n"
+"      if li_first.comments then li_first=li_first.comments.lineinfo.first end\n"
+"      self.i = li_first.offset\n"
+"      self.column_offset = self.i - li_first.column\n"
+"      self.peeked = { }\n"
+"      self.attached_comments = p1.lineinfo.first.comments or { }\n"
+"   end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Take the source and offset of an old lexer.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :takeover(old)\n"
+"   self :sync(); old :sync()\n"
+"   for _, field in ipairs{ 'i', 'src', 'attached_comments', 'posfact' } do\n"
+"       self[field] = old[field]\n"
+"   end\n"
+"   return self\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Return the current position in the sources. This position is between\n"
+"-- two tokens, and can be within a space / comment area, and therefore\n"
+"-- have a non-null width. :lineinfo_left() returns the beginning of the\n"
+"-- separation area, :lineinfo_right() returns the end of that area.\n"
+"--\n"
+"--    ____ last consummed token    ____ first unconsummed token\n"
+"--   /                            /\n"
+"-- XXXXX  <spaces and comments> YYYYY\n"
+"--      \\____                    \\____\n"
+"--           :lineinfo_left()         :lineinfo_right()\n"
+"----------------------------------------------------------------------\n"
+"function lexer :lineinfo_right()\n"
+"   return self :peek(1).lineinfo.first\n"
+"end\n"
+"\nfunction lexer :lineinfo_left()\n"
+"   return self.lineinfo_last_consumed\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Create a new lexstream.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :newstream (src_or_stream, name)\n"
+"   name = name or \"?\"\n"
+"   if type(src_or_stream)=='table' then -- it's a stream\n"
+"      return setmetatable ({ }, self) :takeover (src_or_stream)\n"
+"   elseif type(src_or_stream)=='string' then -- it's a source string\n"
+"      local src = src_or_stream\n"
+"      local pos1 = M.new_position(1, 1, 1, name)\n"
+"      local stream = {\n"
+"         src_name      = name;   -- Name of the file\n"
+"         src           = src;    -- The source, as a single string\n"
+"         peeked        = { };    -- Already peeked, but not discarded yet, tokens\n"
+"         i             = 1;      -- Character offset in src\n"
+"         attached_comments = { },-- comments accumulator\n"
+"         lineinfo_last_extracted = pos1,\n"
+"         lineinfo_last_consumed  = pos1,\n"
+"         posfact       = M.new_position_factory (src_or_stream, name)\n"
+"      }\n"
+"      setmetatable (stream, self)\n"
+"\n      -- Skip initial sharp-bang for Unix scripts\n"
+"      -- FIXME: redundant with mlp.chunk()\n"
+"      if src and src :match \"^#!\" then\n"
+"         local endofline = src :find \"\\n"
+"\"\n"
+"         stream.i = endofline and (endofline + 1) or #src\n"
+"      end\n"
+"      return stream\n"
+"   else\n"
+"      assert(false, \":newstream() takes a source string or a stream, not a \"..\n"
+"          type(src_or_stream))\n"
+"   end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- If there's no ... args, return the token a (whose truth value is\n"
+"-- true) if it's a `Keyword{ }, or nil.  If there are ... args, they\n"
+"-- have to be strings. if the token a is a keyword, and it's content\n"
+"-- is one of the ... args, then returns it (it's truth value is\n"
+"-- true). If no a keyword or not in ..., return nil.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :is_keyword (a, ...)\n"
+"   if not a or a.tag ~= \"Keyword\" then return false end\n"
+"   local words = {...}\n"
+"   if #words == 0 then return a[1] end\n"
+"   for _, w in ipairs (words) do\n"
+"      if w == a[1] then return w end\n"
+"   end\n"
+"   return false\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Cause an error if the next token isn't a keyword whose content\n"
+"-- is listed among ... args (which have to be strings).\n"
+"----------------------------------------------------------------------\n"
+"function lexer :check (...)\n"
+"   local words = {...}\n"
+"   local a = self :next()\n"
+"   local function err ()\n"
+"      error (\"Got \" .. tostring (a) ..\n"
+"             \", expected one of these keywords : '\" ..\n"
+"             table.concat (words,\"', '\") .. \"'\") end\n"
+"   if not a or a.tag ~= \"Keyword\" then err () end\n"
+"   if #words == 0 then return a[1] end\n"
+"   for _, w in ipairs (words) do\n"
+"       if w == a[1] then return w end\n"
+"   end\n"
+"   err ()\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"--\n"
+"----------------------------------------------------------------------\n"
+"function lexer :clone()\n"
+"    local alpha_clone, sym_clone = { }, { }\n"
+"   for word in pairs(self.alpha) do alpha_clone[word]=true end\n"
+"   for letter, list in pairs(self.sym) do sym_clone[letter] = { unpack(list) } end\n"
+"   local clone = { alpha=alpha_clone, sym=sym_clone }\n"
+"   setmetatable(clone, self)\n"
+"   clone.__index = clone\n"
+"   return clone\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Cancel everything left in a lexer, all subsequent attempts at\n"
+"-- `:peek()` or `:next()` will return `Eof`.\n"
+"----------------------------------------------------------------------\n"
+"function lexer :kill()\n"
+"    self.i = #self.src+1\n"
+"    self.peeked = { }\n"
+"    self.attached_comments = { }\n"
+"    self.lineinfo_last = self.posfact :get_position (#self.src+1)\n"
+"end\n"
+"\nreturn M\n",
true, false);
// End of /metalua/grammar/lexer.lua
Lua5_1.provide_file("/metalua/", "repl.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-- Keep these global:\n"
+"PRINT_AST  = true\n"
+"LINE_WIDTH = 60\n"
+"PROMPT     = \"M> \"\n"
+"PROMPT2    = \">> \"\n"
+"\nlocal pp=require 'metalua.pprint'\n"
+"local M = { }\n"
+"\nmlc = require 'metalua.compiler'.new()\n"
+"\nlocal readline\n"
+"\ndo -- set readline() to a line reader, either editline otr a default\n"
+"   local status, _ = pcall(require, 'editline')\n"
+"   if status then\n"
+"      local rl_handle = editline.init 'metalua'\n"
+"      readline = |p| rl_handle:read(p)\n"
+"   else\n"
+"      local status, rl = pcall(require, 'readline')\n"
+"      if status then\n"
+"         rl.set_options{histfile='~/.metalua_history', keeplines=100, completion=false }\n"
+"         readline = rl.readline\n"
+"      else -- neither editline nor readline available\n"
+"         function readline (p)\n"
+"            io.write (p)\n"
+"            io.flush ()\n"
+"            return io.read '*l'\n"
+"         end\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\nlocal function reached_eof(lx, msg)\n"
+"   return lx:peek().tag=='Eof' or msg:find \"token `Eof\"\n"
+"end\n"
+"\n\n"
+"function M.run()\n"
+"    pp.printf (\"Metalua, interactive REPLoop.\\n"
+"\"..\n"
+"            \"(c) 2006-2013 <metalua@gmail.com>\")\n"
+"   local lines = { }\n"
+"   while true do\n"
+"      local src, lx, ast, f, results, success\n"
+"      repeat\n"
+"         local line = readline(next(lines) and PROMPT2 or PROMPT)\n"
+"         if not line then print(); os.exit(0) end -- line==nil iff eof on stdin\n"
+"         if not next(lines) then\n"
+"            line = line:gsub('^%s*=', 'return ')\n"
+"         end\n"
+"         table.insert(lines, line)\n"
+"         src = table.concat (lines, \"\\n"
+"\")\n"
+"      until #line>0\n"
+"      lx  = mlc :src_to_lexstream(src)\n"
+"      success, ast = pcall(mlc.lexstream_to_ast, mlc, lx)\n"
+"      if success then\n"
+"          success, f = pcall(mlc.ast_to_function, mlc, ast, '=stdin')\n"
+"          if success then\n"
+"              results = { xpcall(f, debug.traceback) }\n"
+"              success = table.remove (results, 1)\n"
+"              if success then\n"
+"                  -- Success!\n"
+"                  for _, x in ipairs(results) do\n"
+"                      pp.print(x, {line_max=LINE_WIDTH, metalua_tag=true})\n"
+"                  end\n"
+"                  lines = { }\n"
+"              else\n"
+"                  print \"Evaluation error:\"\n"
+"                  print (results[1])\n"
+"                  lines = { }\n"
+"              end\n"
+"          else\n"
+"              print \"Can't compile into bytecode:\"\n"
+"              print (f)\n"
+"              lines = { }\n"
+"          end\n"
+"      else\n"
+"         -- If lx has been read entirely, try to read\n"
+"         --  another line before failing.\n"
+"         if not reached_eof(lx, ast) then\n"
+"            print \"Can't compile source into AST:\"\n"
+"            print (ast)\n"
+"            lines = { }\n"
+"         end\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\nreturn M",
true, false);
// End of /metalua/repl.mlua
Lua5_1.provide_file("/metalua/", "loader.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal M = require \"package\" -- extend Lua's basic \"package\" module\n"
+"\nM.metalua_extension_prefix = 'metalua.extension.'\n"
+"\n-- Initialize package.mpath from package.path\n"
+"M.mpath = M.mpath or os.getenv 'LUA_MPATH' or\n"
+"    (M.path..\";\") :gsub(\"%.(lua[:;])\", \".m%1\") :sub(1, -2)\n"
+"\nM.mcache = M.mcache or os.getenv 'LUA_MCACHE'\n"
+"\n----------------------------------------------------------------------\n"
+"-- resc(k) returns \"%\"..k if it's a special regular expression char,\n"
+"-- or just k if it's normal.\n"
+"----------------------------------------------------------------------\n"
+"local regexp_magic = { }\n"
+"for k in (\"^$()%.[]*+-?\") :gmatch \".\" do regexp_magic[k]=\"%\"..k end\n"
+"\nlocal function resc(k) return regexp_magic[k] or k end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Take a Lua module name, return the open file and its name,\n"
+"-- or <false> and an error message.\n"
+"----------------------------------------------------------------------\n"
+"function M.findfile(name, path_string)\n"
+"   local config_regexp = (\"([^\\n"
+"])\\n"
+"\"):rep(5):sub(1, -2)\n"
+"   local dir_sep, path_sep, path_mark, execdir, igmark =\n"
+"      M.config :match (config_regexp)\n"
+"   name = name:gsub ('%.', dir_sep)\n"
+"   local errors = { }\n"
+"   local path_pattern = string.format('[^%s]+', resc(path_sep))\n"
+"   for path in path_string:gmatch (path_pattern) do\n"
+"      --printf('path = %s, rpath_mark=%s, name=%s', path, resc(path_mark), name)\n"
+"      local filename = path:gsub (resc (path_mark), name)\n"
+"      --printf('filename = %s', filename)\n"
+"      local file = io.open (filename, 'r')\n"
+"      if file then return file, filename end\n"
+"      table.insert(errors, string.format(\"\\tno lua file %q\", filename))\n"
+"   end\n"
+"   return false, '\\n"
+"'..table.concat(errors, \"\\n"
+"\")..'\\n"
+"'\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Before compiling a metalua source module, try to find and load\n"
+"-- a more recent bytecode dump. Requires lfs\n"
+"----------------------------------------------------------------------\n"
+"local function metalua_cache_loader(name, src_filename, src)\n"
+"    local mlc          = require 'metalua.compiler'.new()\n"
+"    local lfs          = require 'lfs'\n"
+"    local dir_sep      = M.config:sub(1,1)\n"
+"    local dst_filename = M.mcache :gsub ('%?', (name:gsub('%.', dir_sep)))\n"
+"    local src_a        = lfs.attributes(src_filename)\n"
+"    local src_date     = src_a and src_a.modification or 0\n"
+"    local dst_a        = lfs.attributes(dst_filename)\n"
+"    local dst_date     = dst_a and dst_a.modification or 0\n"
+"    local delta        = dst_date - src_date\n"
+"    local bytecode, file, msg\n"
+"    if delta <= 0 then\n"
+"       print \"NEED TO RECOMPILE\"\n"
+"       bytecode = mlc :src_to_bytecode (src, name)\n"
+"       for x in dst_filename :gmatch('()'..dir_sep) do\n"
+"          lfs.mkdir(dst_filename:sub(1,x))\n"
+"       end\n"
+"       file, msg = io.open(dst_filename, 'wb')\n"
+"       if not file then error(msg) end\n"
+"       file :write (bytecode)\n"
+"       file :close()\n"
+"    else\n"
+"       file, msg = io.open(dst_filename, 'rb')\n"
+"       if not file then error(msg) end\n"
+"       bytecode = file :read '*a'\n"
+"       file :close()\n"
+"    end\n"
+"    return mlc :bytecode_to_function (bytecode)\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Load a metalua source file.\n"
+"----------------------------------------------------------------------\n"
+"function M.metalua_loader (name)\n"
+"   local file, filename_or_msg = M.findfile (name, M.mpath)\n"
+"   if not file then return filename_or_msg end\n"
+"   local luastring = file:read '*a'\n"
+"   file:close()\n"
+"   if M.mcache and pcall(require, 'lfs') then\n"
+"      return metalua_cache_loader(name, filename_or_msg, luastring)\n"
+"   else return require 'metalua.compiler'.new() :src_to_function (luastring, name) end\n"
+"end\n"
+"\n\n"
+"----------------------------------------------------------------------\n"
+"-- Placed after lua/luac loader, so precompiled files have\n"
+"-- higher precedence.\n"
+"----------------------------------------------------------------------\n"
+"table.insert(M.loaders, M.metalua_loader)\n"
+"\n----------------------------------------------------------------------\n"
+"-- Load an extension.\n"
+"----------------------------------------------------------------------\n"
+"function extension (name, mlp)\n"
+"    local complete_name = M.metalua_extension_prefix..name\n"
+"    local extend_func = require (complete_name)\n"
+"    if not mlp.extensions[complete_name] then\n"
+"        local ast =extend_func(mlp)\n"
+"        mlp.extensions[complete_name] =extend_func\n"
+"        return ast\n"
+"     end\n"
+"end\n"
+"\nreturn M\n",
true, false);
// End of /metalua/loader.lua
Lua5_1.provide_file("/metalua/", "compiler.lua",
 "---------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Convert between various code representation formats. Atomic\n"
+"-- converters are written in extenso, others are composed automatically\n"
+"-- by chaining the atomic ones together in a closure.\n"
+"--\n"
+"-- Supported formats are:\n"
+"--\n"
+"-- * srcfile:    the name of a file containing sources.\n"
+"-- * src:        these sources as a single string.\n"
+"-- * lexstream:  a stream of lexemes.\n"
+"-- * ast:        an abstract syntax tree.\n"
+"-- * proto:      a (Yueliang) struture containing a high level\n"
+"--               representation of bytecode. Largely based on the\n"
+"--               Proto structure in Lua's VM\n"
+"-- * bytecode:   a string dump of the function, as taken by\n"
+"--               loadstring() and produced by string.dump().\n"
+"-- * function:   an executable lua function in RAM.\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nrequire 'checks'\n"
+"\nlocal M  = { }\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Order of the transformations. if 'a' is on the left of 'b', then a 'a' can\n"
+"-- be transformed into a 'b' (but not the other way around).\n"
+"-- M.sequence goes for numbers to format names, M.order goes from format\n"
+"-- names to numbers.\n"
+"--------------------------------------------------------------------------------\n"
+"M.sequence = {\n"
+"\t'srcfile',  'src', 'lexstream', 'ast', 'proto', 'bytecode', 'function' }\n"
+"\nlocal arg_types = {\n"
+"\tsrcfile    = { 'string', '?string' },\n"
+"\tsrc        = { 'string', '?string' },\n"
+"\tlexstream  = { 'lexer.stream', '?string' },\n"
+"\tast        = { 'table', '?string' },\n"
+"\tproto      = { 'table', '?string' },\n"
+"\tbytecode   = { 'string', '?string' },\n"
+"}\n"
+"\nif false then\n"
+"    -- if defined, runs on every newly-generated AST\n"
+"    function M.check_ast(ast)\n"
+"        local function rec(x, n, parent)\n"
+"            if not x.lineinfo and parent.lineinfo then\n"
+"                local pp = require 'metalua.pprint'\n"
+"                pp.printf(\"WARNING: Missing lineinfo in child #%s `%s{...} of node at %s\",\n"
+"                          n, x.tag or '', tostring(parent.lineinfo))\n"
+"            end\n"
+"            for i, child in ipairs(x) do\n"
+"                if type(child)=='table' then rec(child, i, x) end\n"
+"            end\n"
+"        end\n"
+"        rec(ast, -1, { })\n"
+"    end\n"
+"end\n"
+"\n\n"
+"M.order= { }; for a,b in pairs(M.sequence) do M.order[b]=a end\n"
+"\nlocal CONV = { } -- conversion metatable __index\n"
+"\nfunction CONV :srcfile_to_src(x, name)\n"
+"\tchecks('metalua.compiler', 'string', '?string')\n"
+"\tname = name or '@'..x\n"
+"\tlocal f, msg = io.open (x, 'rb')\n"
+"\tif not f then error(msg) end\n"
+"\tlocal r, msg = f :read '*a'\n"
+"\tif not r then error(\"Cannot read file '\"..x..\"': \"..msg) end\n"
+"\tf :close()\n"
+"\treturn r, name\n"
+"end\n"
+"\nfunction CONV :src_to_lexstream(src, name)\n"
+"\tchecks('metalua.compiler', 'string', '?string')\n"
+"\tlocal r = self.parser.lexer :newstream (src, name)\n"
+"\treturn r, name\n"
+"end\n"
+"\nfunction CONV :lexstream_to_ast(lx, name)\n"
+"\tchecks('metalua.compiler', 'lexer.stream', '?string')\n"
+"\tlocal r = self.parser.chunk(lx)\n"
+"\tr.source = name\n"
+"    if M.check_ast then M.check_ast (r) end\n"
+"\treturn r, name\n"
+"end\n"
+"\nlocal bytecode_compiler = nil -- cache to avoid repeated `pcall(require(...))`\n"
+"local function get_bytecode_compiler()\n"
+"    if bytecode_compiler then return bytecode_compiler else\n"
+"        local status, result = pcall(require, 'metalua.compiler.bytecode')\n"
+"        if status then\n"
+"            bytecode_compiler = result\n"
+"            return result\n"
+"        elseif string.match(result, \"not found\") then\n"
+"            error \"Compilation only available with full Metalua\"\n"
+"        else error (result) end\n"
+"    end\n"
+"end\n"
+"\nfunction CONV :ast_to_proto(ast, name)\n"
+"\tchecks('metalua.compiler', 'table', '?string')\n"
+"    return get_bytecode_compiler().ast_to_proto(ast, name), name\n"
+"end\n"
+"\nfunction CONV :proto_to_bytecode(proto, name)\n"
+"    return get_bytecode_compiler().proto_to_bytecode(proto), name\n"
+"end\n"
+"\nfunction CONV :bytecode_to_function(bc, name)\n"
+"\tchecks('metalua.compiler', 'string', '?string')\n"
+"\treturn loadstring(bc, name)\n"
+"end\n"
+"\n-- Create all sensible combinations\n"
+"for i=1,#M.sequence do\n"
+"\tlocal src = M.sequence[i]\n"
+"\tfor j=i+2, #M.sequence do\n"
+"\t\tlocal dst = M.sequence[j]\n"
+"\t\tlocal dst_name = src..\"_to_\"..dst\n"
+"\t\tlocal my_arg_types = arg_types[src]\n"
+"\t\tlocal functions = { }\n"
+"\t\tfor k=i, j-1 do\n"
+"\t\t\tlocal name =  M.sequence[k]..\"_to_\"..M.sequence[k+1]\n"
+"\t\t\tlocal f = assert(CONV[name], name)\n"
+"\t\t\ttable.insert (functions, f)\n"
+"\t\tend\n"
+"\t\tCONV[dst_name] = function(self, a, b)\n"
+"\t\t\tchecks('metalua.compiler', unpack(my_arg_types))\n"
+"\t\t\tfor _, f in ipairs(functions) do\n"
+"\t\t\t\ta, b = f(self, a, b)\n"
+"\t\t\tend\n"
+"\t\t\treturn a, b\n"
+"\t\tend\n"
+"\t\t--printf(\"Created M.%s out of %s\", dst_name, table.concat(n, ', '))\n"
+"\tend\n"
+"end\n"
+"\n\n"
+"--------------------------------------------------------------------------------\n"
+"-- This one goes in the \"wrong\" direction, cannot be composed.\n"
+"--------------------------------------------------------------------------------\n"
+"function CONV :function_to_bytecode(...) return string.dump(...) end\n"
+"\nfunction CONV :ast_to_src(...)\n"
+"\trequire 'metalua.loader' -- ast_to_string isn't written in plain lua\n"
+"\treturn require 'metalua.compiler.ast_to_src' (...)\n"
+"end\n"
+"\nlocal MT = { __index=CONV, __type='metalua.compiler' }\n"
+"\nfunction M.new()\n"
+"\tlocal parser = require 'metalua.compiler.parser' .new()\n"
+"\tlocal self = { parser = parser }\n"
+"\tsetmetatable(self, MT)\n"
+"\treturn self\n"
+"end\n"
+"\nreturn M",
true, false);
// End of /metalua/compiler.lua
Lua5_1.provide_file("/metalua/", "bytecode.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal compile = require 'metalua.compiler.bytecode.compile'\n"
+"local ldump   = require 'metalua.compiler.bytecode.ldump'\n"
+"\nlocal M = { }\n"
+"\nM.ast_to_proto      = compile.ast_to_proto\n"
+"M.proto_to_bytecode = ldump.dump_string\n"
+"M.proto_to_file     = ldump.dump_file\n"
+"\nreturn M",
true, false);
// End of /metalua/bytecode.lua
Lua5_1.provide_file("/metalua/treequery/", "walk.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-- Low level AST traversal library.\n"
+"-- This library is a helper for the higher-level treequery library.\n"
+"-- It walks through every node of an AST, depth-first, and executes\n"
+"-- some callbacks contained in its cfg config table:\n"
+"--\n"
+"-- * cfg.down(...) is called when it walks down a node, and receive as\n"
+"--   parameters the node just entered, followed by its parent, grand-parent\n"
+"--   etc. until the root node.\n"
+"--\n"
+"-- * cfg.up(...) is called when it walks back up a node, and receive as\n"
+"--   parameters the node just entered, followed by its parent, grand-parent\n"
+"--   etc. until the root node.\n"
+"--\n"
+"-- * cfg.occurrence(binder, id_node, ...) is called when it visits an `Id{ }\n"
+"--   node which isn't a local variable creator. binder is a reference to its\n"
+"--   binder with its context. The binder is the `Id{ } node which created \n"
+"--   this local variable. By \"binder and its context\", we mean a list starting\n"
+"--   with the `Id{ }, and followed by every ancestor of the binder node, up until\n"
+"--   the common root node.\n"
+"--   binder is nil if the variable is global.\n"
+"--   id_node is followed by its ancestor, up until the root node.\n"
+"--\n"
+"-- cfg.scope is maintained during the traversal, associating a\n"
+"-- variable name to the binder which creates it in the context of the\n"
+"-- node currently visited.\n"
+"--\n"
+"-- walk.traverse.xxx functions are in charge of the recursive descent into\n"
+"-- children nodes. They're private helpers.\n"
+"--\n"
+"-- corresponding walk.xxx functions also take care of calling cfg callbacks.\n"
+"\n-{ extension (\"match\", ...) }\n"
+"\nlocal pp = require 'metalua.pprint'\n"
+"\nlocal M = { traverse = { }; tags = { }; debug = false }\n"
+"\nlocal function table_transpose(t)\n"
+"    local tt = { }; for a, b in pairs(t) do tt[b]=a end; return tt\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Standard tags: can be used to guess the type of an AST, or to check\n"
+"-- that the type of an AST is respected.\n"
+"--------------------------------------------------------------------------------\n"
+"M.tags.stat = table_transpose{\n"
+"   'Do', 'Set', 'While', 'Repeat', 'Local', 'Localrec', 'Return',\n"
+"   'Fornum', 'Forin', 'If', 'Break', 'Goto', 'Label',\n"
+"   'Call', 'Invoke' }\n"
+"M.tags.expr = table_transpose{\n"
+"   'Paren', 'Call', 'Invoke', 'Index', 'Op', 'Function', 'Stat',\n"
+"   'Table', 'Nil', 'Dots', 'True', 'False', 'Number', 'String', 'Id' }\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- These [M.traverse.xxx()] functions are in charge of actually going through\n"
+"-- ASTs. At each node, they make sure to call the appropriate walker.\n"
+"--------------------------------------------------------------------------------\n"
+"function M.traverse.stat (cfg, x, ...)\n"
+"   if M.debug then pp.printf(\"traverse stat %s\", x) end\n"
+"   local ancestors = {...}\n"
+"   local B  = |y| M.block       (cfg, y, x, unpack(ancestors)) -- Block\n"
+"   local S  = |y| M.stat        (cfg, y, x, unpack(ancestors)) -- Statement\n"
+"   local E  = |y| M.expr        (cfg, y, x, unpack(ancestors)) -- Expression\n"
+"   local EL = |y| M.expr_list   (cfg, y, x, unpack(ancestors)) -- Expression List\n"
+"   local IL = |y| M.binder_list (cfg, y, x, unpack(ancestors)) -- Id binders List\n"
+"   local OS = || cfg.scope :save()                             -- Open scope\n"
+"   local CS = || cfg.scope :restore()                          -- Close scope\n"
+"\n   match x with\n"
+"   | {...} if x.tag == nil -> for _, y in ipairs(x) do M.stat(cfg, y, ...) end\n"
+"                          -- no tag --> node not inserted in the history ancestors\n"
+"   | `Do{...}                    -> OS(x); for _, y in ipairs(x) do S(y) end; CS(x)\n"
+"   | `Set{ lhs, rhs }            -> EL(lhs); EL(rhs)\n"
+"   | `While{ cond, body }        -> E(cond); OS(); B(body); CS()\n"
+"   | `Repeat{ body, cond }       -> OS(body); B(body); E(cond); CS(body)\n"
+"   | `Local{ lhs }               -> IL(lhs)\n"
+"   | `Local{ lhs, rhs }          -> EL(rhs); IL(lhs)\n"
+"   | `Localrec{ lhs, rhs }       -> IL(lhs); EL(rhs)\n"
+"   | `Fornum{ i, a, b, body }    -> E(a); E(b); OS(); IL{i}; B(body); CS()\n"
+"   | `Fornum{ i, a, b, c, body } -> E(a); E(b); E(c); OS(); IL{i}; B(body); CS()\n"
+"   | `Forin{ i, rhs, body }      -> EL(rhs); OS(); IL(i); B(body); CS()\n"
+"   | `If{...}                    ->\n"
+"       for i=1, #x-1, 2 do\n"
+"           E(x[i]); OS(); B(x[i+1]); CS()\n"
+"       end\n"
+"       if #x%2 == 1 then\n"
+"           OS(); B(x[#x]); CS()\n"
+"       end\n"
+"   | `Call{...}|`Invoke{...}|`Return{...} -> EL(x)\n"
+"   | `Break | `Goto{ _ } | `Label{ _ }    -> -- nothing\n"
+"   | { tag=tag, ...} if M.tags.stat[tag]->\n"
+"      M.malformed (cfg, x, unpack (ancestors))\n"
+"   | _ ->\n"
+"      M.unknown (cfg, x, unpack (ancestors))\n"
+"   end\n"
+"end\n"
+"\nfunction M.traverse.expr (cfg, x, ...)\n"
+"   if M.debug then pp.printf(\"traverse expr %s\", x) end\n"
+"   local ancestors = {...}\n"
+"   local B  = |y| M.block       (cfg, y, x, unpack(ancestors)) -- Block\n"
+"   local S  = |y| M.stat        (cfg, y, x, unpack(ancestors)) -- Statement\n"
+"   local E  = |y| M.expr        (cfg, y, x, unpack(ancestors)) -- Expression\n"
+"   local EL = |y| M.expr_list   (cfg, y, x, unpack(ancestors)) -- Expression List\n"
+"   local IL = |y| M.binder_list (cfg, y, x, unpack(ancestors)) -- Id binders list\n"
+"   local OS = || cfg.scope :save()                             -- Open scope\n"
+"   local CS = || cfg.scope :restore()                          -- Close scope\n"
+"\n   match x with\n"
+"   | `Paren{ e }               -> E(e)\n"
+"   | `Call{...} | `Invoke{...} -> EL(x)\n"
+"   | `Index{ a, b }            -> E(a); E(b)\n"
+"   | `Op{ opid, ... }          -> E(x[2]); if #x==3 then E(x[3]) end\n"
+"   | `Function{ params, body } -> OS(body); IL(params); B(body); CS(body)\n"
+"   | `Stat{ b, e }             -> OS(b); B(b); E(e); CS(b)\n"
+"   | `Id{ name }               -> M.occurrence(cfg, x, unpack(ancestors))\n"
+"   | `Table{ ... }             ->\n"
+"      for i = 1, #x do match x[i] with\n"
+"         | `Pair{ k, v } -> E(k); E(v)\n"
+"         | v             -> E(v)\n"
+"      end end\n"
+"   | `Nil|`Dots|`True|`False|`Number{_}|`String{_} -> -- terminal node\n"
+"   | { tag=tag, ...} if M.tags.expr[tag]-> M.malformed (cfg, x, unpack (ancestors))\n"
+"   | _ -> M.unknown (cfg, x, unpack (ancestors))\n"
+"   end\n"
+"end\n"
+"\nfunction M.traverse.block (cfg, x, ...)\n"
+"   assert(type(x)=='table', \"traverse.block() expects a table\")\n"
+"   if x.tag then M.malformed(cfg, x, ...)\n"
+"   else for _, y in ipairs(x) do M.stat(cfg, y, x, ...) end\n"
+"   end\n"
+"end\n"
+"\nfunction M.traverse.expr_list (cfg, x, ...)\n"
+"   assert(type(x)=='table', \"traverse.expr_list() expects a table\")\n"
+"   -- x doesn't appear in the ancestors\n"
+"   for _, y in ipairs(x) do M.expr(cfg, y, ...) end\n"
+"end\n"
+"\nfunction M.malformed(cfg, x, ...)\n"
+"    local f = cfg.malformed or cfg.error\n"
+"    if f then f(x, ...) else\n"
+"        error (\"Malformed node of tag \"..(x.tag or '(nil)'))\n"
+"    end\n"
+"end\n"
+"\nfunction M.unknown(cfg, x, ...)\n"
+"    local f = cfg.unknown or cfg.error\n"
+"    if f then f(x, ...) else\n"
+"        error (\"Unknown node tag \"..(x.tag or '(nil)'))\n"
+"    end\n"
+"end\n"
+"\nfunction M.occurrence(cfg, x, ...)\n"
+"    if cfg.occurrence then cfg.occurrence(cfg.scope :get(x[1]),  x, ...) end\n"
+"end\n"
+"\n-- TODO: Is it useful to call each error handling function?\n"
+"function M.binder_list (cfg, id_list, ...)\n"
+"    local f = cfg.binder\n"
+"    local ferror = cfg.error or cfg.malformed or cfg.unknown\n"
+"    for i, id_node in ipairs(id_list) do\n"
+"      if id_node.tag == 'Id' then\n"
+"         cfg.scope :set (id_node[1], { id_node, ... })\n"
+"         if f then f(id_node, ...) end\n"
+"      elseif i==#id_list and id_node.tag=='Dots' then\n"
+"         -- Do nothing, those are valid `Dots\n"
+"      elseif ferror then\n"
+"         -- Traverse error handling function\n"
+"         ferror(id_node, ...)\n"
+"      else\n"
+"         error(\"Invalid binders list\")\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Generic walker generator.\n"
+"-- * if `cfg' has an entry matching the tree name, use this entry\n"
+"-- * if not, try to use the entry whose name matched the ast kind\n"
+"-- * if an entry is a table, look for 'up' and 'down' entries\n"
+"-- * if it is a function, consider it as a `down' traverser.\n"
+"----------------------------------------------------------------------\n"
+"local walker_builder = function(traverse)\n"
+"   assert(traverse)\n"
+"   return function (cfg, ...)\n"
+"      if not cfg.scope then cfg.scope = M.newscope() end\n"
+"      local down, up = cfg.down, cfg.up\n"
+"      local broken = down and down(...)\n"
+"      if broken ~= 'break' then M.traverse[traverse] (cfg, ...) end\n"
+"      if up then up(...) end\n"
+"   end\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Declare [M.stat], [M.expr], [M.block] and [M.expr_list]\n"
+"----------------------------------------------------------------------\n"
+"for _, w in ipairs{ \"stat\", \"expr\", \"block\" } do --, \"malformed\", \"unknown\" } do\n"
+"   M[w] = walker_builder (w, M.traverse[w])\n"
+"end\n"
+"\n-- Don't call up/down callbacks on expr lists\n"
+"M.expr_list = M.traverse.expr_list\n"
+"\n\n"
+"----------------------------------------------------------------------\n"
+"-- Try to guess the type of the AST then choose the right walkker.\n"
+"----------------------------------------------------------------------\n"
+"function M.guess (cfg, x, ...)\n"
+"   assert(type(x)=='table', \"arg #2 in a walker must be an AST\")\n"
+"   if M.tags.expr[x.tag] then return M.expr(cfg, x, ...)  end\n"
+"   if M.tags.stat[x.tag] then return M.stat(cfg, x, ...)  end\n"
+"   if not x.tag          then return M.block(cfg, x, ...) end\n"
+"   error (\"Can't guess the AST type from tag \"..(x.tag or '<none>'))\n"
+"end\n"
+"\nlocal S = { }; S.__index = S\n"
+"\nfunction M.newscope()\n"
+"    local instance = { current = { } }\n"
+"    instance.stack = { instance.current }\n"
+"    setmetatable (instance, S)\n"
+"    return instance\n"
+"end\n"
+"\nfunction S :save(...)\n"
+"    local current_copy = { }\n"
+"    for a, b in pairs(self.current) do current_copy[a]=b end\n"
+"    table.insert (self.stack, current_copy)\n"
+"    if ... then return self :add(...) end\n"
+"end\n"
+"\nfunction S :restore() self.current = table.remove (self.stack) end\n"
+"function S :get (var_name) return self.current[var_name] end\n"
+"function S :set (key, val) self.current[key] = val end\n"
+"\nreturn M\n",
true, false);
// End of /metalua/treequery/walk.mlua
Lua5_1.provide_file("/metalua/", "pprint.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"----------------------------------------------------------------------\n"
+"\n----------------------------------------------------------------------\n"
+"----------------------------------------------------------------------\n"
+"--\n"
+"-- Lua objects pretty-printer\n"
+"--\n"
+"----------------------------------------------------------------------\n"
+"----------------------------------------------------------------------\n"
+"\nlocal M = { }\n"
+"\nM.DEFAULT_CFG = {\n"
+"    hide_hash      = false; -- Print the non-array part of tables?\n"
+"    metalua_tag    = true;  -- Use Metalua's backtick syntax sugar?\n"
+"    fix_indent     = nil;   -- If a number, number of indentation spaces;\n"
+"                            -- If false, indent to the previous brace.\n"
+"    line_max       = nil;   -- If a number, tries to avoid making lines with\n"
+"                            -- more than this number of chars.\n"
+"    initial_indent = 0;     -- If a number, starts at this level of indentation\n"
+"    keywords       = { };   -- Set of keywords which must not use Lua's field\n"
+"                            -- shortcuts {[\"foo\"]=...} -> {foo=...}\n"
+"}\n"
+"\nlocal function valid_id(cfg, x)\n"
+"    if type(x) ~= \"string\" then return false end\n"
+"    if not x:match \"^[a-zA-Z_][a-zA-Z0-9_]*$\" then return false end\n"
+"    if cfg.keywords and cfg.keywords[x] then return false end\n"
+"    return true\n"
+"end\n"
+"\nlocal __tostring_cache = setmetatable({ }, {__mode='k'})\n"
+"\n-- Retrieve the string produced by `__tostring` metamethod if present,\n"
+"-- return `false` otherwise. Cached in `__tostring_cache`.\n"
+"local function __tostring(x)\n"
+"    local the_string = __tostring_cache[x]\n"
+"    if the_string~=nil then return the_string end\n"
+"    local mt = getmetatable(x)\n"
+"    if mt then\n"
+"        local __tostring = mt.__tostring\n"
+"        if __tostring then\n"
+"            the_string = __tostring(x)\n"
+"            __tostring_cache[x] = the_string\n"
+"            return the_string\n"
+"        end\n"
+"    end\n"
+"    if x~=nil then __tostring_cache[x] = false end -- nil is an illegal key\n"
+"    return false\n"
+"end\n"
+"\nlocal xlen -- mutually recursive with `xlen_type`\n"
+"\nlocal xlen_cache = setmetatable({ }, {__mode='k'})\n"
+"\n-- Helpers for the `xlen` function\n"
+"local xlen_type = {\n"
+"    [\"nil\"] = function ( ) return 3 end;\n"
+"    number  = function (x) return #tostring(x) end;\n"
+"    boolean = function (x) return x and 4 or 5 end;\n"
+"    string  = function (x) return #string.format(\"%q\",x) end;\n"
+"}\n"
+"\nfunction xlen_type.table (adt, cfg, nested)\n"
+"    local custom_string = __tostring(adt)\n"
+"    if custom_string then return #custom_string end\n"
+"\n    -- Circular referenced objects are printed with the plain\n"
+"    -- `tostring` function in nested positions.\n"
+"    if nested [adt] then return #tostring(adt) end\n"
+"    nested [adt] = true\n"
+"\n    local has_tag  = cfg.metalua_tag and valid_id(cfg, adt.tag)\n"
+"    local alen     = #adt\n"
+"    local has_arr  = alen>0\n"
+"    local has_hash = false\n"
+"    local x = 0\n"
+"\n    if not cfg.hide_hash then\n"
+"        -- first pass: count hash-part\n"
+"        for k, v in pairs(adt) do\n"
+"            if k==\"tag\" and has_tag then\n"
+"                -- this is the tag -> do nothing!\n"
+"            elseif type(k)==\"number\" and k<=alen and math.fmod(k,1)==0 and k>0 then\n"
+"                -- array-part pair -> do nothing!\n"
+"            else\n"
+"                has_hash = true\n"
+"                if valid_id(cfg, k) then x=x+#k\n"
+"                else x = x + xlen (k, cfg, nested) + 2 end -- count surrounding brackets\n"
+"                x = x + xlen (v, cfg, nested) + 5          -- count \" = \" and \", \"\n"
+"            end\n"
+"        end\n"
+"    end\n"
+"\n    for i = 1, alen do x = x + xlen (adt[i], nested) + 2 end -- count \", \"\n"
+"\n    nested[adt] = false -- No more nested calls\n"
+"\n    if not (has_tag or has_arr or has_hash) then return 3 end\n"
+"    if has_tag then x=x+#adt.tag+1 end\n"
+"    if not (has_arr or has_hash) then return x end\n"
+"    if not has_hash and alen==1 and type(adt[1])~=\"table\" then\n"
+"        return x-2 -- substract extraneous \", \"\n"
+"    end\n"
+"    return x+2 -- count \"{ \" and \" }\", substract extraneous \", \"\n"
+"end\n"
+"\n\n"
+"-- Compute the number of chars it would require to display the table\n"
+"-- on a single line. Helps to decide whether some carriage returns are\n"
+"-- required. Since the size of each sub-table is required many times,\n"
+"-- it's cached in [xlen_cache].\n"
+"xlen = function (x, cfg, nested)\n"
+"    -- no need to compute length for 1-line prints\n"
+"    if not cfg.line_max then return 0 end\n"
+"    nested = nested or { }\n"
+"    if x==nil then return #\"nil\" end\n"
+"    local len = xlen_cache[x]\n"
+"    if len then return len end\n"
+"    local f = xlen_type[type(x)]\n"
+"    if not f then return #tostring(x) end\n"
+"    len = f (x, cfg, nested)\n"
+"    xlen_cache[x] = len\n"
+"    return len\n"
+"end\n"
+"\nlocal function consider_newline(p, len)\n"
+"    if not p.cfg.line_max then return end\n"
+"    if p.current_offset + len <= p.cfg.line_max then return end\n"
+"    if p.indent < p.current_offset then\n"
+"        p:acc \"\\n"
+"\"; p:acc ((\" \"):rep(p.indent))\n"
+"        p.current_offset = p.indent\n"
+"    end\n"
+"end\n"
+"\nlocal acc_value\n"
+"\nlocal acc_type = {\n"
+"    [\"nil\"] = function(p) p:acc(\"nil\") end;\n"
+"    number  = function(p, adt) p:acc (tostring (adt)) end;\n"
+"    string  = function(p, adt) p:acc ((string.format (\"%q\", adt):gsub(\"\\\\\\n"
+"\", \"\\\\n"
+"\"))) end;\n"
+"    boolean = function(p, adt) p:acc (adt and \"true\" or \"false\") end }\n"
+"\n-- Indentation:\n"
+"-- * if `cfg.fix_indent` is set to a number:\n"
+"--   * add this number of space for each level of depth\n"
+"--   * return to the line as soon as it flushes things further left\n"
+"-- * if not, tabulate to one space after the opening brace.\n"
+"--   * as a result, it never saves right-space to return before first element\n"
+"\nfunction acc_type.table(p, adt)\n"
+"    if p.nested[adt] then p:acc(tostring(adt)); return end\n"
+"    p.nested[adt]  = true\n"
+"\n    local has_tag  = p.cfg.metalua_tag and valid_id(p.cfg, adt.tag)\n"
+"    local alen     = #adt\n"
+"    local has_arr  = alen>0\n"
+"    local has_hash = false\n"
+"\n    local previous_indent = p.indent\n"
+"\n    if has_tag then p:acc(\"`\"); p:acc(adt.tag) end\n"
+"\n    local function indent(p)\n"
+"        if not p.cfg.fix_indent then p.indent = p.current_offset\n"
+"        else p.indent = p.indent + p.cfg.fix_indent end\n"
+"    end\n"
+"\n    -- First pass: handle hash-part\n"
+"    if not p.cfg.hide_hash then\n"
+"        for k, v in pairs(adt) do\n"
+"\n            if has_tag and k=='tag' then  -- pass the 'tag' field\n"
+"            elseif type(k)==\"number\" and k<=alen and k>0 and math.fmod(k,1)==0 then\n"
+"                -- pass array-part keys (consecutive ints less than `#adt`)\n"
+"            else -- hash-part keys\n"
+"                if has_hash then p:acc \", \" else -- 1st hash-part pair ever found\n"
+"                    p:acc \"{ \"; indent(p)\n"
+"                end\n"
+"\n                -- Determine whether a newline is required\n"
+"                local is_id, expected_len=valid_id(p.cfg, k)\n"
+"                if is_id then expected_len=#k+xlen(v, p.cfg, p.nested)+#\" = , \"\n"
+"                else expected_len = xlen(k, p.cfg, p.nested)+xlen(v, p.cfg, p.nested)+#\"[] = , \" end\n"
+"                consider_newline(p, expected_len)\n"
+"\n                -- Print the key\n"
+"                if is_id then p:acc(k); p:acc \" = \" else\n"
+"                    p:acc \"[\"; acc_value (p, k); p:acc \"] = \"\n"
+"                end\n"
+"\n                acc_value (p, v) -- Print the value\n"
+"                has_hash = true\n"
+"            end\n"
+"        end\n"
+"    end\n"
+"\n    -- Now we know whether there's a hash-part, an array-part, and a tag.\n"
+"    -- Tag and hash-part are already printed if they're present.\n"
+"    if not has_tag and not has_hash and not has_arr then p:acc \"{ }\";\n"
+"    elseif has_tag and not has_hash and not has_arr then -- nothing, tag already in acc\n"
+"    else\n"
+"        assert (has_hash or has_arr) -- special case { } already handled\n"
+"        local no_brace = false\n"
+"        if has_hash and has_arr then p:acc \", \"\n"
+"        elseif has_tag and not has_hash and alen==1 and type(adt[1])~=\"table\" then\n"
+"            -- No brace required; don't print \"{\", remember not to print \"}\"\n"
+"            p:acc (\" \"); acc_value (p, adt[1]) -- indent= indent+(cfg.fix_indent or 0))\n"
+"            no_brace = true\n"
+"        elseif not has_hash then\n"
+"            -- Braces required, but not opened by hash-part handler yet\n"
+"            p:acc \"{ \"; indent(p)\n"
+"        end\n"
+"\n        -- 2nd pass: array-part\n"
+"        if not no_brace and has_arr then\n"
+"            local expected_len = xlen(adt[1], p.cfg, p.nested)\n"
+"            consider_newline(p, expected_len)\n"
+"            acc_value(p, adt[1]) -- indent+(cfg.fix_indent or 0)\n"
+"            for i=2, alen do\n"
+"                p:acc \", \";\n"
+"                consider_newline(p, xlen(adt[i], p.cfg, p.nested))\n"
+"                acc_value (p, adt[i]) --indent+(cfg.fix_indent or 0)\n"
+"            end\n"
+"        end\n"
+"        if not no_brace then p:acc \" }\" end\n"
+"    end\n"
+"    p.nested[adt] = false -- No more nested calls\n"
+"    p.indent = previous_indent\n"
+"end\n"
+"\n\n"
+"function acc_value(p, v)\n"
+"    local custom_string = __tostring(v)\n"
+"    if custom_string then p:acc(custom_string) else\n"
+"        local f = acc_type[type(v)]\n"
+"        if f then f(p, v) else p:acc(tostring(v)) end\n"
+"    end\n"
+"end\n"
+"\n\n"
+"-- FIXME: new_indent seems to be always nil?!s detection\n"
+"-- FIXME: accumulator function should be configurable,\n"
+"-- so that print() doesn't need to bufferize the whole string\n"
+"-- before starting to print.\n"
+"function M.tostring(t, cfg)\n"
+"\n    cfg = cfg or M.DEFAULT_CFG or { }\n"
+"\n    local p = {\n"
+"        cfg = cfg;\n"
+"        indent = 0;\n"
+"        current_offset = cfg.initial_indent or 0;\n"
+"        buffer = { };\n"
+"        nested = { };\n"
+"        acc = function(self, str)\n"
+"                  table.insert(self.buffer, str)\n"
+"                  self.current_offset = self.current_offset + #str\n"
+"              end;\n"
+"    }\n"
+"    acc_value(p, t)\n"
+"    return table.concat(p.buffer)\n"
+"end\n"
+"\nfunction M.print(...) return print(M.tostring(...)) end\n"
+"function M.sprintf(fmt, ...)\n"
+"    local args={...}\n"
+"    for i, v in pairs(args) do\n"
+"        local t=type(v)\n"
+"        if t=='table' then args[i]=M.tostring(v)\n"
+"        elseif t=='nil' then args[i]='nil' end\n"
+"    end\n"
+"    return string.format(fmt, unpack(args))\n"
+"end\n"
+"\nfunction M.printf(...) print(M.sprintf(...)) end\n"
+"\nreturn M",
true, false);
// End of /metalua/pprint.lua
Lua5_1.provide_file("/metalua/compiler/bytecode/", "compile.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Kein-Hong Man, Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Kein-Hong Man  - Initial implementation for Lua 5.0, part of Yueliang\n"
+"--     Fabien Fleutot - Port to Lua 5.1, integration with Metalua\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n----------------------------------------------------------------------\n"
+"--\n"
+"-- This code mainly results from the borrowing, then ruthless abuse, of\n"
+"-- Yueliang's implementation of Lua 5.0 compiler.\n"
+"--\n"
+"---------------------------------------------------------------------\n"
+"\nlocal pp = require 'metalua.pprint'\n"
+"\nlocal luaK = require 'metalua.compiler.bytecode.lcode'\n"
+"local luaP = require 'metalua.compiler.bytecode.lopcodes'\n"
+"\nlocal debugf = function() end\n"
+"--local debugf=printf\n"
+"\nlocal stat = { }\n"
+"local expr = { }\n"
+"\nlocal M = { }\n"
+"\nM.MAX_INT            = 2147483645 -- INT_MAX-2 for 32-bit systems (llimits.h)\n"
+"M.MAXVARS            = 200        -- (llimits.h)\n"
+"M.MAXUPVALUES        = 32         -- (llimits.h)\n"
+"M.MAXPARAMS          = 100        -- (llimits.h)\n"
+"M.LUA_MAXPARSERLEVEL = 200        -- (llimits.h)\n"
+"\n-- from lobject.h\n"
+"M.VARARG_HASARG   = 1\n"
+"M.VARARG_ISVARARG = 2\n"
+"M.VARARG_NEEDSARG = 4\n"
+"\nlocal function hasmultret (k) \n"
+"   return k==\"VCALL\" or k==\"VVARARG\"\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- Some ASTs take expression lists as children; it should be\n"
+"-- acceptible to give an expression instead, and to automatically\n"
+"-- interpret it as a single element list. That's what does this\n"
+"-- function, adding a surrounding list iff needed.\n"
+"--\n"
+"-- WARNING: \"Do\" is the tag for chunks, which are essentially lists.\n"
+"-- Therefore, we don't listify stuffs with a \"Do\" tag.\n"
+"-----------------------------------------------------------------------\n"
+"local function ensure_list (ast)\n"
+"   return ast.tag and ast.tag ~= \"Do\" and {ast} or ast end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- Get a localvar structure { varname, startpc, endpc } from a \n"
+"-- (zero-based) index of active variable. The catch is: don't get\n"
+"-- confused between local index and active index.\n"
+"--\n"
+"-- locvars[x] contains { varname, startpc, endpc };\n"
+"-- actvar[i] contains the index of the variable in locvars\n"
+"-----------------------------------------------------------------------\n"
+"local function getlocvar (fs, i)\n"
+"  return fs.f.locvars[fs.actvar[i]] \n"
+"end\n"
+"\nlocal function removevars (fs, tolevel)\n"
+"  while fs.nactvar > tolevel do\n"
+"     fs.nactvar = fs.nactvar - 1\n"
+"     -- There may be dummy locvars due to expr.Stat\n"
+"     -- FIXME: strange that they didn't disappear?!\n"
+"     local locvar = getlocvar (fs, fs.nactvar)\n"
+"     --printf(\"[REMOVEVARS] removing var #%i = %s\", fs.nactvar,\n"
+"     --    locvar and tostringv(locvar) or \"<nil>\")\n"
+"     if locvar then locvar.endpc = fs.pc end\n"
+"  end\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- [f] has a list of all its local variables, active and inactive.\n"
+"-- Some local vars can correspond to the same register, if they exist\n"
+"-- in different scopes. \n"
+"-- [fs.nlocvars] is the total number of local variables, not to be\n"
+"-- confused with [fs.nactvar] the numebr of variables active at the\n"
+"-- current PC.\n"
+"-- At this stage, the existence of the variable is not yet aknowledged,\n"
+"-- since [fs.nactvar] and [fs.freereg] aren't updated.\n"
+"-----------------------------------------------------------------------\n"
+"local function registerlocalvar (fs, varname)\n"
+"   --debugf(\"[locvar: %s = reg %i]\", varname, fs.nlocvars)\n"
+"   local f = fs.f\n"
+"   f.locvars[fs.nlocvars] = { } -- LocVar\n"
+"   f.locvars[fs.nlocvars].varname = varname\n"
+"   local nlocvars = fs.nlocvars\n"
+"   fs.nlocvars = fs.nlocvars + 1\n"
+"   return nlocvars\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- update the active vars counter in [fs] by adding [nvars] of them,\n"
+"-- and sets those variables' [startpc] to the current [fs.pc].\n"
+"-- These variables were allready created, but not yet counted, by\n"
+"-- new_localvar.\n"
+"-----------------------------------------------------------------------\n"
+"local function adjustlocalvars (fs, nvars)\n"
+"   --debugf(\"adjustlocalvars, nvars=%i, previous fs.nactvar=%i,\"..\n"
+"   --       \" #locvars=%i, #actvar=%i\", \n"
+"   --       nvars, fs.nactvar, #fs.f.locvars, #fs.actvar)\n"
+"\n   fs.nactvar = fs.nactvar + nvars\n"
+"   for i = nvars, 1, -1 do\n"
+"      --printf (\"adjusting actvar #%i\", fs.nactvar - i)\n"
+"      getlocvar (fs, fs.nactvar - i).startpc = fs.pc\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- check whether, in an assignment to a local variable, the local variable\n"
+"-- is needed in a previous assignment (to a table). If so, save original\n"
+"-- local value in a safe place and use this safe copy in the previous\n"
+"-- assignment.\n"
+"------------------------------------------------------------------------\n"
+"local function check_conflict (fs, lh, v)\n"
+"  local extra = fs.freereg  -- eventual position to save local variable\n"
+"  local conflict = false\n"
+"  while lh do\n"
+"    if lh.v.k == \"VINDEXED\" then\n"
+"      if lh.v.info == v.info then  -- conflict?\n"
+"        conflict = true\n"
+"        lh.v.info = extra  -- previous assignment will use safe copy\n"
+"      end\n"
+"      if lh.v.aux == v.info then  -- conflict?\n"
+"        conflict = true\n"
+"        lh.v.aux = extra  -- previous assignment will use safe copy\n"
+"      end\n"
+"    end\n"
+"    lh = lh.prev\n"
+"  end\n"
+"  if conflict then\n"
+"    luaK:codeABC (fs, \"OP_MOVE\", fs.freereg, v.info, 0)  -- make copy\n"
+"    luaK:reserveregs (fs, 1)\n"
+"  end\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- Create an expdesc. To be updated when expdesc is lua-ified.\n"
+"-----------------------------------------------------------------------\n"
+"local function init_exp (e, k, i)\n"
+"  e.f, e.t, e.k, e.info = luaK.NO_JUMP, luaK.NO_JUMP, k, i end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- Reserve the string in tthe constant pool, and return an expdesc\n"
+"-- referring to it.\n"
+"-----------------------------------------------------------------------\n"
+"local function codestring (fs, e, str)\n"
+"  --printf( \"codestring(%s)\", disp.ast(str))\n"
+"  init_exp (e, \"VK\", luaK:stringK (fs, str))\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- search for a local variable named [name] in the function being\n"
+"-- built by [fs]. Doesn't try to visit upvalues.\n"
+"-----------------------------------------------------------------------\n"
+"local function searchvar (fs, name)\n"
+"   for i = fs.nactvar - 1, 0, -1 do\n"
+"      -- Because of expr.Stat, there can be some actvars which don't\n"
+"      -- correspond to any locvar. Hence the checking for locvar's \n"
+"      -- nonnilness before getting the varname.\n"
+"      local locvar = getlocvar(fs, i)\n"
+"      if locvar and name == locvar.varname then \n"
+"         --printf(\"Found local var: %s; i = %i\", tostringv(locvar), i)\n"
+"         return i \n"
+"      end\n"
+"   end\n"
+"   return -1  -- not found\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- create and return a new proto [f]\n"
+"-----------------------------------------------------------------------\n"
+"local function newproto () \n"
+"  local f = {}\n"
+"  f.k = {}\n"
+"  f.sizek = 0\n"
+"  f.p = {}\n"
+"  f.sizep = 0\n"
+"  f.code = {}\n"
+"  f.sizecode = 0\n"
+"  f.sizelineinfo = 0\n"
+"  f.sizeupvalues = 0\n"
+"  f.nups = 0\n"
+"  f.upvalues = {}\n"
+"  f.numparams = 0\n"
+"  f.is_vararg = 0\n"
+"  f.maxstacksize = 0\n"
+"  f.lineinfo = {}\n"
+"  f.sizelocvars = 0\n"
+"  f.locvars = {}\n"
+"  f.lineDefined = 0\n"
+"  f.source = nil\n"
+"  return f\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- create and return a function state [new_fs] as a sub-funcstate of [fs].\n"
+"------------------------------------------------------------------------\n"
+"local function open_func (old_fs)\n"
+"  local new_fs = { }\n"
+"  new_fs.upvalues = { }\n"
+"  new_fs.actvar = { }\n"
+"  local f = newproto ()\n"
+"  new_fs.f = f\n"
+"  new_fs.prev = old_fs  -- linked list of funcstates\n"
+"  new_fs.pc = 0\n"
+"  new_fs.lasttarget = -1\n"
+"  new_fs.jpc = luaK.NO_JUMP\n"
+"  new_fs.freereg = 0\n"
+"  new_fs.nk = 0\n"
+"  new_fs.h = {}  -- constant table; was luaH_new call\n"
+"  new_fs.np = 0\n"
+"  new_fs.nlocvars = 0\n"
+"  new_fs.nactvar = 0\n"
+"  new_fs.bl = nil\n"
+"  new_fs.nestlevel =  old_fs and old_fs.nestlevel or 0\n"
+"  f.maxstacksize = 2  -- registers 0/1 are always valid\n"
+"  new_fs.lastline = 0\n"
+"  new_fs.forward_gotos = { }\n"
+"  new_fs.labels = { }\n"
+"  return new_fs\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- Finish to set up [f] according to final state of [fs]\n"
+"------------------------------------------------------------------------\n"
+"local function close_func (fs)\n"
+"  local f = fs.f\n"
+"  --printf(\"[CLOSE_FUNC] remove any remaining var\")\n"
+"  removevars (fs, 0)\n"
+"  luaK:ret (fs, 0, 0)\n"
+"  f.sizecode = fs.pc\n"
+"  f.sizelineinfo = fs.pc\n"
+"  f.sizek = fs.nk\n"
+"  f.sizep = fs.np\n"
+"  f.sizelocvars = fs.nlocvars\n"
+"  f.sizeupvalues = f.nups\n"
+"  assert (fs.bl == nil)\n"
+"  if next(fs.forward_gotos) then\n"
+"     local x = pp.tostring(fs.forward_gotos)\n"
+"     error (\"Unresolved goto: \"..x)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function pushclosure(fs, func, v)\n"
+"   local f = fs.f\n"
+"   f.p [fs.np] = func.f\n"
+"   fs.np = fs.np + 1\n"
+"   init_exp (v, \"VRELOCABLE\", luaK:codeABx (fs, \"OP_CLOSURE\", 0, fs.np - 1))\n"
+"  for i = 0, func.f.nups - 1 do\n"
+"    local o = (func.upvalues[i].k == \"VLOCAL\") and \"OP_MOVE\" or \"OP_GETUPVAL\"\n"
+"    luaK:codeABC (fs, o, 0, func.upvalues[i].info, 0)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- FIXME: is there a need for f=fs.f? if yes, why not always using it? \n"
+"------------------------------------------------------------------------\n"
+"local function indexupvalue(fs, name, v)\n"
+"   local f = fs.f\n"
+"   for i = 0, f.nups - 1 do\n"
+"      if fs.upvalues[i].k == v.k and fs.upvalues[i].info == v.info then\n"
+"         assert(fs.f.upvalues[i] == name)\n"
+"         return i\n"
+"      end\n"
+"   end\n"
+"  -- new one\n"
+"  f.upvalues[f.nups] = name\n"
+"  assert (v.k == \"VLOCAL\" or v.k == \"VUPVAL\")\n"
+"  fs.upvalues[f.nups] = { k = v.k; info = v.info }\n"
+"  local nups = f.nups\n"
+"  f.nups = f.nups + 1\n"
+"  return nups\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"local function markupval(fs, level)\n"
+"  local bl = fs.bl\n"
+"  while bl and bl.nactvar > level do bl = bl.previous end\n"
+"  if bl then bl.upval = true end\n"
+"end\n"
+"\n\n"
+"--for debug only\n"
+"--[[\n"
+"local function bldepth(fs)\n"
+"   local i, x= 1, fs.bl\n"
+"   while x do i=i+1; x=x.previous end\n"
+"   return i\n"
+"end\n"
+"--]]\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"local function enterblock (fs, bl, isbreakable)\n"
+"  bl.breaklist = luaK.NO_JUMP\n"
+"  bl.isbreakable = isbreakable\n"
+"  bl.nactvar = fs.nactvar\n"
+"  bl.upval = false\n"
+"  bl.previous = fs.bl\n"
+"  fs.bl = bl\n"
+"  assert (fs.freereg == fs.nactvar)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"local function leaveblock (fs)\n"
+"   local bl = fs.bl\n"
+"   fs.bl = bl.previous\n"
+"   --printf(\"[LEAVEBLOCK] Removing vars...\")\n"
+"   removevars (fs, bl.nactvar)\n"
+"   --printf(\"[LEAVEBLOCK] ...Vars removed\")\n"
+"   if bl.upval then\n"
+"      luaK:codeABC (fs, \"OP_CLOSE\", bl.nactvar, 0, 0)\n"
+"   end\n"
+"   -- a block either controls scope or breaks (never both)\n"
+"   assert (not bl.isbreakable or not bl.upval)\n"
+"   assert (bl.nactvar == fs.nactvar)\n"
+"   fs.freereg = fs.nactvar  -- free registers\n"
+"   luaK:patchtohere (fs, bl.breaklist)\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"-- read a list of expressions from a list of ast [astlist]\n"
+"-- starts at the [offset]th element of the list (defaults to 1)\n"
+"------------------------------------------------------------------------\n"
+"local function explist(fs, astlist, v, offset)\n"
+"  offset = offset or 1\n"
+"  if #astlist < offset then error \"I don't handle empty expr lists yet\" end\n"
+"  --printf(\"[EXPLIST] about to precompile 1st element %s\", disp.ast(astlist[offset]))\n"
+"  expr.expr (fs, astlist[offset], v)\n"
+"  --printf(\"[EXPLIST] precompiled first element v=%s\", tostringv(v))\n"
+"  for i = offset+1, #astlist do\n"
+"    luaK:exp2nextreg (fs, v)\n"
+"    --printf(\"[EXPLIST] flushed v=%s\", tostringv(v))\n"
+"    expr.expr (fs, astlist[i], v)\n"
+"    --printf(\"[EXPLIST] precompiled element v=%s\", tostringv(v))\n"
+"  end\n"
+"  return #astlist - offset + 1\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function funcargs (fs, ast, v, idx_from)\n"
+"  local args = { }  -- expdesc\n"
+"  local nparams\n"
+"  if #ast < idx_from then args.k = \"VVOID\" else\n"
+"     explist(fs, ast, args, idx_from)\n"
+"     luaK:setmultret(fs, args)\n"
+"  end\n"
+"  assert(v.k == \"VNONRELOC\")\n"
+"  local base = v.info  -- base register for call\n"
+"  if hasmultret(args.k) then nparams = luaK.LUA_MULTRET else -- open call\n"
+"    if args.k ~= \"VVOID\" then \n"
+"       luaK:exp2nextreg(fs, args) end -- close last argument\n"
+"    nparams = fs.freereg - (base + 1)\n"
+"  end\n"
+"  init_exp(v, \"VCALL\", luaK:codeABC(fs, \"OP_CALL\", base, nparams + 1, 2))\n"
+"  if ast.lineinfo then\n"
+"     luaK:fixline(fs, ast.lineinfo.first.line)\n"
+"  else \n"
+"    luaK:fixline(fs, ast.line)\n"
+"  end\n"
+"  fs.freereg = base + 1  -- call remove function and arguments and leaves\n"
+"                         -- (unless changed) one result\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- calculates log value for encoding the hash portion's size\n"
+"------------------------------------------------------------------------\n"
+"local function log2(x)\n"
+"  -- math result is always one more than lua0_log2()\n"
+"  local mn, ex = math.frexp(x)\n"
+"  return ex - 1\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- converts an integer to a \"floating point byte\", represented as\n"
+"-- (mmmmmxxx), where the real value is (xxx) * 2^(mmmmm)\n"
+"------------------------------------------------------------------------\n"
+"\n-- local function int2fb(x)\n"
+"--   local m = 0  -- mantissa\n"
+"--   while x >= 8 do x = math.floor((x + 1) / 2); m = m + 1 end\n"
+"--   return m * 8 + x\n"
+"-- end\n"
+"\nlocal function int2fb(x)\n"
+"   local e = 0\n"
+"   while x >= 16 do\n"
+"      x = math.floor ( (x+1) / 2)\n"
+"      e = e+1\n"
+"   end\n"
+"   if x<8 then return x\n"
+"   else return (e+1) * 8 + x - 8 end\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"-- FIXME: to be unified with singlevar\n"
+"------------------------------------------------------------------------\n"
+"local function singlevaraux(fs, n, var, base)\n"
+"--[[\n"
+"print(\"\\n"
+"\\n"
+"singlevaraux: fs, n, var, base\")\n"
+"printv(fs)\n"
+"printv(n)\n"
+"printv(var)\n"
+"printv(base)\n"
+"print(\"\\n"
+"\")\n"
+"--]]\n"
+"   if fs == nil then  -- no more levels?\n"
+"      init_exp(var, \"VGLOBAL\", luaP.NO_REG)  -- default is global variable\n"
+"      return \"VGLOBAL\"\n"
+"   else\n"
+"      local v = searchvar(fs, n)  -- look up at current level\n"
+"      if v >= 0 then\n"
+"         init_exp(var, \"VLOCAL\", v)\n"
+"         if not base then\n"
+"            markupval(fs, v)  -- local will be used as an upval\n"
+"         end\n"
+"      else  -- not found at current level; try upper one\n"
+"         if singlevaraux(fs.prev, n, var, false) == \"VGLOBAL\" then\n"
+"            return \"VGLOBAL\" end\n"
+"         var.info = indexupvalue (fs, n, var)\n"
+"         var.k = \"VUPVAL\"\n"
+"         return \"VUPVAL\"\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function singlevar(fs, varname, var)   \n"
+"  if singlevaraux(fs, varname, var, true) == \"VGLOBAL\" then\n"
+"     var.info = luaK:stringK (fs, varname) end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function new_localvar (fs, name, n)\n"
+"  assert (type (name) == \"string\")\n"
+"  if fs.nactvar + n > M.MAXVARS then error (\"too many local vars\") end\n"
+"  fs.actvar[fs.nactvar + n] = registerlocalvar (fs, name)\n"
+"  --printf(\"[NEW_LOCVAR] %i = %s\", fs.nactvar+n, name)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function parlist (fs, ast_params)\n"
+"   local dots = (#ast_params > 0 and ast_params[#ast_params].tag == \"Dots\")\n"
+"   local nparams = dots and #ast_params - 1 or #ast_params\n"
+"   for i = 1, nparams do\n"
+"      assert (ast_params[i].tag == \"Id\", \"Function parameters must be Ids\")\n"
+"      new_localvar (fs, ast_params[i][1], i-1)\n"
+"   end\n"
+"   -- from [code_param]:\n"
+"   --checklimit (fs, fs.nactvar, self.M.MAXPARAMS, \"parameters\")\n"
+"   fs.f.numparams = fs.nactvar\n"
+"   fs.f.is_vararg = dots and M.VARARG_ISVARARG or 0 \n"
+"   adjustlocalvars (fs, nparams)\n"
+"   fs.f.numparams = fs.nactvar --FIXME vararg must be taken in account\n"
+"   luaK:reserveregs (fs, fs.nactvar)  -- reserve register for parameters\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- if there's more variables than expressions in an assignment,\n"
+"-- some assignations to nil are made for extraneous vars.\n"
+"-- Also handles multiret functions\n"
+"------------------------------------------------------------------------\n"
+"local function adjust_assign (fs, nvars, nexps, e)\n"
+"  local extra = nvars - nexps\n"
+"  if hasmultret (e.k) then\n"
+"    extra = extra+1  -- includes call itself\n"
+"    if extra <= 0 then extra = 0 end\n"
+"    luaK:setreturns(fs, e, extra)  -- call provides the difference\n"
+"    if extra > 1 then luaK:reserveregs(fs, extra-1) end\n"
+"  else\n"
+"    if e.k ~= \"VVOID\" then \n"
+"       luaK:exp2nextreg(fs, e) end  -- close last expression\n"
+"    if extra > 0 then\n"
+"      local reg = fs.freereg\n"
+"      luaK:reserveregs(fs, extra)\n"
+"      luaK:_nil(fs, reg, extra)\n"
+"    end\n"
+"  end\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function enterlevel (fs)\n"
+"   fs.nestlevel = fs.nestlevel + 1\n"
+"   assert (fs.nestlevel <= M.LUA_MAXPARSERLEVEL, \"too many syntax levels\")\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function leavelevel (fs)\n"
+"  fs.nestlevel = fs.nestlevel - 1\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- Parse conditions in if/then/else, while, repeat\n"
+"------------------------------------------------------------------------\n"
+"local function cond (fs, ast)\n"
+"   local v = { }\n"
+"   expr.expr(fs, ast, v)  -- read condition\n"
+"   if v.k == \"VNIL\" then v.k = \"VFALSE\" end  -- 'falses' are all equal here\n"
+"   luaK:goiftrue (fs, v)\n"
+"   return v.f\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function chunk (fs, ast)\n"
+"   enterlevel (fs)\n"
+"   assert (not ast.tag)\n"
+"   for i=1, #ast do \n"
+"      stat.stat (fs, ast[i]); \n"
+"      fs.freereg = fs.nactvar\n"
+"   end\n"
+"   leavelevel (fs)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"local function block (fs, ast)\n"
+"  local bl = {}\n"
+"  enterblock (fs, bl, false)\n"
+"  for i=1, #ast do\n"
+"     stat.stat (fs, ast[i])\n"
+"     fs.freereg = fs.nactvar\n"
+"  end\n"
+"  assert (bl.breaklist == luaK.NO_JUMP)\n"
+"  leaveblock (fs)\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"-- Forin / Fornum body parser\n"
+"-- [fs]\n"
+"-- [body]\n"
+"-- [base]\n"
+"-- [nvars]\n"
+"-- [isnum]\n"
+"------------------------------------------------------------------------\n"
+"local function forbody (fs, ast_body, base, nvars, isnum)\n"
+"   local bl = {}  -- BlockCnt\n"
+"   adjustlocalvars (fs, 3)  -- control variables\n"
+"   local prep = \n"
+"      isnum and luaK:codeAsBx (fs, \"OP_FORPREP\", base, luaK.NO_JUMP)\n"
+"      or luaK:jump (fs) \n"
+"   enterblock (fs, bl, false)  -- loop block\n"
+"   adjustlocalvars (fs, nvars)  -- scope for declared variables\n"
+"   luaK:reserveregs (fs, nvars)\n"
+"   block (fs, ast_body)\n"
+"   leaveblock (fs)\n"
+"   --luaK:patchtohere (fs, prep-1)\n"
+"   luaK:patchtohere (fs, prep)\n"
+"   local endfor = \n"
+"      isnum and luaK:codeAsBx (fs, \"OP_FORLOOP\", base, luaK.NO_JUMP)\n"
+"      or luaK:codeABC (fs, \"OP_TFORLOOP\", base, 0, nvars)\n"
+"   luaK:fixline (fs, ast_body.line)  -- pretend that 'OP_FOR' starts the loop\n"
+"   luaK:patchlist (fs, isnum and endfor or luaK:jump(fs), prep + 1)\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"local function recfield (fs, ast, cc)\n"
+"  local reg = fs.freereg\n"
+"  local key, val = {}, {}  -- expdesc\n"
+"  --FIXME: expr + exp2val = index -->\n"
+"  --       check reduncancy between exp2val and exp2rk\n"
+"  cc.nh = cc.nh + 1\n"
+"  expr.expr(fs, ast[1], key); \n"
+"  luaK:exp2val (fs, key) \n"
+"  local keyreg = luaK:exp2RK (fs, key)\n"
+"  expr.expr(fs, ast[2], val)\n"
+"  local valreg = luaK:exp2RK (fs, val)\n"
+"  luaK:codeABC(fs, \"OP_SETTABLE\", cc.t.info, keyreg, valreg)\n"
+"  fs.freereg = reg  -- free registers\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"local function listfield(fs, ast, cc)\n"
+"  expr.expr(fs, ast, cc.v)\n"
+"  assert (cc.na <= luaP.MAXARG_Bx) -- FIXME check <= or <\n"
+"  cc.na = cc.na + 1\n"
+"  cc.tostore = cc.tostore + 1\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"local function closelistfield(fs, cc)\n"
+"   if cc.v.k == \"VVOID\" then return end  -- there is no list item\n"
+"   luaK:exp2nextreg(fs, cc.v)\n"
+"   cc.v.k = \"VVOID\"\n"
+"   if cc.tostore == luaP.LFIELDS_PER_FLUSH then\n"
+"      luaK:setlist (fs, cc.t.info, cc.na, cc.tostore)\n"
+"      cc.tostore = 0\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- The last field might be a call to a multireturn function. In that\n"
+"-- case, we must unfold all of its results into the list.\n"
+"------------------------------------------------------------------------\n"
+"local function lastlistfield(fs, cc)\n"
+"  if cc.tostore == 0 then return end\n"
+"  if hasmultret (cc.v.k) then\n"
+"    luaK:setmultret(fs, cc.v)\n"
+"    luaK:setlist (fs, cc.t.info, cc.na, luaK.LUA_MULTRET)\n"
+"    cc.na = cc.na - 1\n"
+"  else\n"
+"    if cc.v.k ~= \"VVOID\" then luaK:exp2nextreg(fs, cc.v) end\n"
+"    luaK:setlist (fs, cc.t.info, cc.na, cc.tostore)\n"
+"  end\n"
+"end\n"
+"------------------------------------------------------------------------\n"
+"------------------------------------------------------------------------\n"
+"-- \n"
+"-- Statement parsers table\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"------------------------------------------------------------------------\n"
+"\nfunction stat.stat (fs, ast)\n"
+"   if ast.lineinfo then fs.lastline = ast.lineinfo.last.line end\n"
+"   --debugf (\" - Statement %s\", table.tostring (ast) )\n"
+"\n   if not ast.tag then chunk (fs, ast) else\n"
+"\n      local parser = stat [ast.tag]\n"
+"      if not parser then \n"
+"         error (\"A statement cannot have tag `\"..ast.tag) end\n"
+"      parser (fs, ast)\n"
+"   end\n"
+"   --debugf (\" - /Statement `%s\", ast.tag)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nstat.Do = block\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Break (fs, ast)\n"
+"   --   if ast.lineinfo then fs.lastline = ast.lineinfo.last.line\n"
+"   local bl, upval = fs.bl, false\n"
+"   while bl and not bl.isbreakable do\n"
+"      if bl.upval then upval = true end\n"
+"      bl = bl.previous\n"
+"   end\n"
+"   assert (bl, \"no loop to break\")\n"
+"   if upval then luaK:codeABC(fs, \"OP_CLOSE\", bl.nactvar, 0, 0) end\n"
+"   bl.breaklist = luaK:concat(fs, bl.breaklist, luaK:jump(fs))\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Return (fs, ast)\n"
+"   local e = {}  -- expdesc\n"
+"   local first -- registers with returned values\n"
+"   local nret = #ast\n"
+"\n   if nret == 0 then first = 0\n"
+"   else\n"
+"      --printf(\"[RETURN] compiling explist\")\n"
+"      explist (fs, ast, e)\n"
+"      --printf(\"[RETURN] explist e=%s\", tostringv(e))\n"
+"      if hasmultret (e.k) then\n"
+"         luaK:setmultret(fs, e)\n"
+"         if e.k == \"VCALL\" and nret == 1 then\n"
+"            luaP:SET_OPCODE(luaK:getcode(fs, e), \"OP_TAILCALL\")\n"
+"            assert(luaP:GETARG_A(luaK:getcode(fs, e)) == fs.nactvar)\n"
+"         end\n"
+"         first = fs.nactvar\n"
+"         nret = luaK.LUA_MULTRET  -- return all values\n"
+"      elseif nret == 1 then\n"
+"         first = luaK:exp2anyreg(fs, e)\n"
+"      else\n"
+"         --printf(\"* Return multiple vals in nextreg %i\", fs.freereg)\n"
+"         luaK:exp2nextreg(fs, e)  -- values must go to the 'stack'\n"
+"         first = fs.nactvar  -- return all 'active' values\n"
+"         assert(nret == fs.freereg - first)\n"
+"      end\n"
+"   end\n"
+"   luaK:ret(fs, first, nret)\n"
+"end\n"
+"------------------------------------------------------------------------\n"
+"\nfunction stat.Local (fs, ast)\n"
+"  local names, values = ast[1], ast[2] or { }\n"
+"  for i = 1, #names do new_localvar (fs, names[i][1], i-1) end\n"
+"  local e = { }\n"
+"  if #values == 0 then e.k = \"VVOID\" else explist (fs, values, e) end\n"
+"  adjust_assign (fs, #names, #values, e)\n"
+"  adjustlocalvars (fs, #names)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Localrec (fs, ast)\n"
+"   assert(#ast[1]==1 and #ast[2]==1, \"Multiple letrecs not implemented yet\")\n"
+"   local ast_var, ast_val, e_var, e_val = ast[1][1], ast[2][1], { }, { }\n"
+"   new_localvar (fs, ast_var[1], 0)\n"
+"   init_exp (e_var, \"VLOCAL\", fs.freereg)\n"
+"   luaK:reserveregs (fs, 1)\n"
+"   adjustlocalvars (fs, 1)\n"
+"   expr.expr (fs, ast_val, e_val)\n"
+"   luaK:storevar (fs, e_var, e_val)\n"
+"   getlocvar (fs, fs.nactvar-1).startpc = fs.pc\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.If (fs, ast)\n"
+"  local astlen = #ast\n"
+"  -- Degenerate case #1: no statement\n"
+"  if astlen==0 then return block(fs, { }) end\n"
+"  -- Degenerate case #2: only an else statement\n"
+"  if astlen==1 then return block(fs, ast[1]) end   \n"
+"\n  local function test_then_block (fs, test, body)\n"
+"    local condexit = cond (fs, test); \n"
+"    block (fs, body) \n"
+"    return condexit\n"
+"  end\n"
+"\n  local escapelist = luaK.NO_JUMP\n"
+"\n  local flist = test_then_block (fs, ast[1], ast[2]) -- 'then' statement\n"
+"  for i = 3, #ast - 1, 2 do -- 'elseif' statement\n"
+"    escapelist = luaK:concat( fs, escapelist, luaK:jump(fs))\n"
+"    luaK:patchtohere (fs, flist)\n"
+"    flist = test_then_block (fs, ast[i], ast[i+1])\n"
+"  end\n"
+"  if #ast % 2 == 1 then -- 'else' statement\n"
+"    escapelist = luaK:concat(fs, escapelist, luaK:jump(fs))\n"
+"    luaK:patchtohere(fs, flist)\n"
+"    block (fs, ast[#ast])\n"
+"  else\n"
+"    escapelist = luaK:concat(fs, escapelist, flist)\n"
+"  end\n"
+"  luaK:patchtohere(fs, escapelist)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Forin (fs, ast)\n"
+"   local vars, vals, body = ast[1], ast[2], ast[3]\n"
+"   -- imitating forstat:\n"
+"   local bl = { }\n"
+"   enterblock (fs, bl, true)\n"
+"   -- imitating forlist:\n"
+"   local e, base = { }, fs.freereg\n"
+"   new_localvar (fs, \"(for generator)\", 0)\n"
+"   new_localvar (fs, \"(for state)\", 1)\n"
+"   new_localvar (fs, \"(for control)\", 2)\n"
+"   for i = 1, #vars do new_localvar (fs, vars[i][1], i+2) end\n"
+"   explist (fs, vals, e)\n"
+"   adjust_assign (fs, 3, #vals, e)\n"
+"   luaK:checkstack (fs, 3)\n"
+"   forbody (fs, body, base, #vars, false)\n"
+"   -- back to forstat:\n"
+"   leaveblock (fs)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Fornum (fs, ast)\n"
+"\n   local function exp1 (ast_e)\n"
+"      local e = { }\n"
+"      expr.expr (fs, ast_e, e)\n"
+"      luaK:exp2nextreg (fs, e)\n"
+"   end\n"
+"   -- imitating forstat:\n"
+"   local bl = { }\n"
+"   enterblock (fs, bl, true)\n"
+"   -- imitating fornum:\n"
+"   local base = fs.freereg\n"
+"   new_localvar (fs, \"(for index)\", 0)\n"
+"   new_localvar (fs, \"(for limit)\", 1)\n"
+"   new_localvar (fs, \"(for step)\", 2)\n"
+"   new_localvar (fs, ast[1][1], 3) \n"
+"   exp1 (ast[2]) -- initial value\n"
+"   exp1 (ast[3]) -- limit\n"
+"   if #ast == 5 then exp1 (ast[4]) else -- default step = 1\n"
+"      luaK:codeABx(fs, \"OP_LOADK\", fs.freereg, luaK:numberK(fs, 1))\n"
+"      luaK:reserveregs(fs, 1)\n"
+"   end\n"
+"   forbody (fs, ast[#ast], base, 1, true)\n"
+"   -- back to forstat:\n"
+"   leaveblock (fs)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"function stat.Repeat (fs, ast)\n"
+"  local repeat_init = luaK:getlabel (fs)\n"
+"  local bl1, bl2 = { }, { }\n"
+"  enterblock (fs, bl1, true)\n"
+"  enterblock (fs, bl2, false)\n"
+"  chunk (fs, ast[1])\n"
+"  local condexit = cond (fs, ast[2])\n"
+"  if not bl2.upval then\n"
+"    leaveblock (fs)\n"
+"    luaK:patchlist (fs, condexit, repeat_init)\n"
+"  else\n"
+"    stat.Break (fs)\n"
+"    luaK:patchtohere (fs, condexit)\n"
+"    leaveblock (fs)\n"
+"    luaK:patchlist (fs, luaK:jump (fs), repeat_init)\n"
+"  end\n"
+"  leaveblock (fs)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.While (fs, ast)\n"
+"   local whileinit = luaK:getlabel (fs)\n"
+"   local condexit = cond (fs, ast[1])\n"
+"   local bl = { }\n"
+"   enterblock (fs, bl, true)\n"
+"   block (fs, ast[2])\n"
+"   luaK:patchlist (fs, luaK:jump (fs), whileinit)\n"
+"   leaveblock (fs)\n"
+"   luaK:patchtohere (fs, condexit);\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\n-- FIXME: it's cumbersome to write this in this semi-recursive way.\n"
+"function stat.Set (fs, ast)\n"
+"   local ast_lhs, ast_vals, e = ast[1], ast[2], { }\n"
+"\n   --print \"\\n"
+"\\n"
+"Set ast_lhs ast_vals:\"\n"
+"   --print(disp.ast(ast_lhs))\n"
+"   --print(disp.ast(ast_vals))\n"
+"\n   local function let_aux (lhs, nvars)\n"
+"      local legal = { VLOCAL=1, VUPVAL=1, VGLOBAL=1, VINDEXED=1 }\n"
+"      --printv(lhs)\n"
+"      if not legal [lhs.v.k] then \n"
+"         error (\"Bad lhs expr: \"..pp.tostring(ast_lhs)) \n"
+"      end\n"
+"      if nvars < #ast_lhs then -- this is not the last lhs\n"
+"         local nv = { v = { }, prev = lhs }\n"
+"         expr.expr (fs, ast_lhs [nvars+1], nv.v)\n"
+"         if nv.v.k == \"VLOCAL\" then check_conflict (fs, lhs, nv.v) end\n"
+"         let_aux (nv, nvars+1)\n"
+"      else -- this IS the last lhs\n"
+"         explist (fs, ast_vals, e)\n"
+"         if #ast_vals < nvars then            \n"
+"            adjust_assign (fs, nvars, #ast_vals, e)\n"
+"         elseif #ast_vals > nvars then \n"
+"            adjust_assign (fs, nvars, #ast_vals, e)\n"
+"            fs.freereg = fs.freereg - #ast_vals + nvars\n"
+"         else -- #ast_vals == nvars (and we're at last lhs)\n"
+"            luaK:setoneret (fs, e)  -- close last expression\n"
+"            luaK:storevar (fs, lhs.v, e)\n"
+"            return  -- avoid default\n"
+"         end\n"
+"      end\n"
+"      init_exp (e, \"VNONRELOC\", fs.freereg - 1)  -- default assignment\n"
+"      luaK:storevar (fs, lhs.v, e)\n"
+"   end\n"
+"\n   local lhs = { v = { }, prev = nil }\n"
+"   expr.expr (fs, ast_lhs[1], lhs.v)\n"
+"   let_aux( lhs, 1)\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Call (fs, ast)\n"
+"   local v = {  }\n"
+"   expr.Call (fs, ast, v)\n"
+"   luaP:SETARG_C (luaK:getcode(fs, v), 1)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction stat.Invoke (fs, ast)\n"
+"   local v = {  }\n"
+"   expr.Invoke (fs, ast, v)\n"
+"   --FIXME: didn't check that, just copied from stat.Call\n"
+"   luaP:SETARG_C (luaK:getcode(fs, v), 1)\n"
+"end\n"
+"\n\n"
+"local function patch_goto (fs, src, dst)\n"
+"\nend\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"-- Goto/Label data:\n"
+"-- fs.labels        :: string => { nactvar :: int; pc :: int }\n"
+"-- fs.forward_gotos :: string => list(int)\n"
+"--\n"
+"-- fs.labels goes from label ids to the number of active variables at\n"
+"-- the label's PC, and that PC\n"
+"--\n"
+"-- fs.forward_gotos goes from label ids to the list of the PC where\n"
+"-- some goto wants to jump to this label. Since gotos are actually made\n"
+"-- up of two instructions OP_CLOSE and OP_JMP, it's the first instruction's\n"
+"-- PC that's stored in fs.forward_gotos\n"
+"--\n"
+"-- Note that backward gotos aren't stored: since their destination is knowns\n"
+"-- when they're compiled, their target is directly set.\n"
+"------------------------------------------------------------------------\n"
+"\n------------------------------------------------------------------------\n"
+"-- Set a Label to jump to with Goto\n"
+"------------------------------------------------------------------------\n"
+"function stat.Label (fs, ast)\n"
+"   local label_id = ast[1]\n"
+"   if type(label_id)=='table' then label_id=label_id[1] end\n"
+"   -- printf(\"Label %s at PC %i\", label_id, fs.pc)\n"
+"   -------------------------------------------------------------------\n"
+"   -- Register the label, so that future gotos can use it.\n"
+"   -------------------------------------------------------------------\n"
+"   if   fs.labels [label_id] then error \"Duplicate label in function\"\n"
+"   else fs.labels [label_id] = { pc = fs.pc; nactvar = fs.nactvar } end\n"
+"   local gotos = fs.forward_gotos [label_id]\n"
+"   if gotos then \n"
+"      ----------------------------------------------------------------\n"
+"      -- Patch forward gotos which were targetting this label.\n"
+"      ----------------------------------------------------------------\n"
+"      for _, goto_pc in ipairs(gotos) do\n"
+"         local close_instr  = fs.f.code[goto_pc]\n"
+"         local jmp_instr    = fs.f.code[goto_pc+1]\n"
+"         local goto_nactvar = luaP:GETARG_A (close_instr)\n"
+"         if fs.nactvar < goto_nactvar then \n"
+"            luaP:SETARG_A (close_instr, fs.nactvar) end\n"
+"         luaP:SETARG_sBx (jmp_instr, fs.pc - goto_pc - 2)\n"
+"      end\n"
+"      ----------------------------------------------------------------\n"
+"      -- Gotos are patched, they can be forgotten about (when the\n"
+"      -- function will be finished, it will be checked that all gotos\n"
+"      -- have been patched, by checking that forward_goto is empty).\n"
+"      ----------------------------------------------------------------\n"
+"      fs.forward_gotos[label_id] = nil\n"
+"   end \n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- jumps to a label set with stat.Label. \n"
+"-- Argument must be a String or an Id\n"
+"-- FIXME/optim: get rid of useless OP_CLOSE when nactvar doesn't change.\n"
+"-- Thsi must be done both here for backward gotos, and in\n"
+"-- stat.Label for forward gotos.\n"
+"------------------------------------------------------------------------\n"
+"function stat.Goto (fs, ast)\n"
+"   local label_id = ast[1]\n"
+"   if type(label_id)=='table' then label_id=label_id[1] end\n"
+"   -- printf(\"Goto %s at PC %i\", label_id, fs.pc)\n"
+"   local label = fs.labels[label_id]\n"
+"   if label then\n"
+"      ----------------------------------------------------------------\n"
+"      -- Backward goto: the label already exists, so I can get its\n"
+"      -- nactvar and address directly. nactvar is used to close\n"
+"      -- upvalues if we get out of scoping blocks by jumping.\n"
+"      ----------------------------------------------------------------\n"
+"      if fs.nactvar > label.nactvar then\n"
+"         luaK:codeABC  (fs, \"OP_CLOSE\", label.nactvar, 0, 0) end\n"
+"      local offset = label.pc - fs.pc - 1\n"
+"      luaK:codeAsBx (fs, \"OP_JMP\", 0, offset)\n"
+"   else\n"
+"      ----------------------------------------------------------------\n"
+"      -- Forward goto: will be patched when the matching label is\n"
+"      -- found, forward_gotos[label_id] keeps the PC of the CLOSE\n"
+"      -- instruction just before the JMP. [stat.Label] will use it to\n"
+"      -- patch the OP_CLOSE and the OP_JMP.\n"
+"      ----------------------------------------------------------------\n"
+"      if not fs.forward_gotos[label_id] then \n"
+"         fs.forward_gotos[label_id] = { } end\n"
+"      table.insert (fs.forward_gotos[label_id], fs.pc)\n"
+"      luaK:codeABC  (fs, \"OP_CLOSE\", fs.nactvar, 0, 0)\n"
+"      luaK:codeAsBx (fs, \"OP_JMP\", 0, luaK.NO_JUMP)\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"------------------------------------------------------------------------\n"
+"-- \n"
+"-- Expression parsers table\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"------------------------------------------------------------------------\n"
+"\nfunction expr.expr (fs, ast, v)\n"
+"   if type(ast) ~= \"table\" then \n"
+"      error (\"Expr AST expected, got \"..pp.tostring(ast)) end\n"
+"\n   if ast.lineinfo then fs.lastline = ast.lineinfo.last.line end\n"
+"\n   --debugf (\" - Expression %s\", table.tostring (ast))\n"
+"   local parser = expr[ast.tag]\n"
+"   if parser then parser (fs, ast, v)\n"
+"   elseif not ast.tag then \n"
+"       error (\"No tag in expression \"..\n"
+"              pp.tostring(ast, {line_max=80, hide_hash=1, metalua_tag=1}))\n"
+"   else \n"
+"      error (\"No parser for node `\"..ast.tag) end\n"
+"   --debugf (\" - /Expression `%s\", ast.tag)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Nil (fs, ast, v) init_exp (v, \"VNIL\", 0) end\n"
+"function expr.True (fs, ast, v) init_exp (v, \"VTRUE\", 0) end\n"
+"function expr.False (fs, ast, v) init_exp (v, \"VFALSE\", 0) end\n"
+"function expr.String (fs, ast, v) codestring (fs, v, ast[1]) end\n"
+"function expr.Number (fs, ast, v)\n"
+"   init_exp (v, \"VKNUM\", 0)\n"
+"   v.nval = ast[1] \n"
+"end\n"
+"\nfunction expr.Paren (fs, ast, v) \n"
+"   expr.expr (fs, ast[1], v)\n"
+"   luaK:setoneret (fs, v)\n"
+"end\n"
+"\nfunction expr.Dots (fs, ast, v)\n"
+"   assert (fs.f.is_vararg ~= 0, \"No vararg in this function\")\n"
+"   -- NEEDSARG flag is set if and only if the function is a vararg,\n"
+"   -- but no vararg has been used yet in its code.\n"
+"   if fs.f.is_vararg < M.VARARG_NEEDSARG then \n"
+"      fs.f.is_varag = fs.f.is_vararg - M.VARARG_NEEDSARG end\n"
+"   init_exp (v, \"VVARARG\", luaK:codeABC (fs, \"OP_VARARG\", 0, 1, 0))\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Table (fs, ast, v)\n"
+"  local pc = luaK:codeABC(fs, \"OP_NEWTABLE\", 0, 0, 0)\n"
+"  local cc = { v = { } , na = 0, nh = 0, tostore = 0, t = v }  -- ConsControl\n"
+"  init_exp (v, \"VRELOCABLE\", pc)\n"
+"  init_exp (cc.v, \"VVOID\", 0)  -- no value (yet)\n"
+"  luaK:exp2nextreg (fs, v)  -- fix it at stack top (for gc)\n"
+"  for i = 1, #ast do\n"
+"    assert(cc.v.k == \"VVOID\" or cc.tostore > 0)\n"
+"    closelistfield(fs, cc);\n"
+"    (ast[i].tag == \"Pair\" and recfield or listfield) (fs, ast[i], cc)\n"
+"  end    \n"
+"  lastlistfield(fs, cc)\n"
+"\n  -- Configure [OP_NEWTABLE] dimensions\n"
+"  luaP:SETARG_B(fs.f.code[pc], int2fb(cc.na)) -- set initial array size\n"
+"  luaP:SETARG_C(fs.f.code[pc], int2fb(cc.nh))  -- set initial table size\n"
+"  --printv(fs.f.code[pc])\n"
+"end  \n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"\nfunction expr.Function (fs, ast, v)\n"
+"   if ast.lineinfo then fs.lastline = ast.lineinfo.last.line end\n"
+"\n  local new_fs = open_func(fs)\n"
+"  if ast.lineinfo then \n"
+"    new_fs.f.lineDefined, new_fs.f.lastLineDefined = \n"
+"        ast.lineinfo.first.line, ast.lineinfo.last.line\n"
+"  end\n"
+"  parlist (new_fs, ast[1])\n"
+"  chunk (new_fs, ast[2])\n"
+"  close_func (new_fs)\n"
+"  pushclosure(fs, new_fs, v)\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Op (fs, ast, v)\n"
+"   if ast.lineinfo then fs.lastline = ast.lineinfo.last.line end\n"
+"   local op = ast[1]\n"
+"\n   if #ast == 2 then\n"
+"      expr.expr (fs, ast[2], v)\n"
+"      luaK:prefix (fs, op, v)\n"
+"   elseif #ast == 3 then\n"
+"      local v2 = { }\n"
+"      expr.expr (fs, ast[2], v)\n"
+"      luaK:infix (fs, op, v)\n"
+"      expr.expr (fs, ast[3], v2)\n"
+"      luaK:posfix (fs, op, v, v2)\n"
+"   else\n"
+"      error \"Wrong arg number\"\n"
+"   end\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Call (fs, ast, v)\n"
+"   expr.expr (fs, ast[1], v)\n"
+"   luaK:exp2nextreg (fs, v)\n"
+"   funcargs(fs, ast, v, 2)\n"
+"   --debugf(\"after expr.Call: %s, %s\", v.k, luaP.opnames[luaK:getcode(fs, v).OP])\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"-- `Invoke{ table key args }\n"
+"function expr.Invoke (fs, ast, v)\n"
+"   expr.expr (fs, ast[1], v)\n"
+"   luaK:dischargevars (fs, v)\n"
+"   local key = { }\n"
+"   codestring (fs, key, ast[2][1])\n"
+"   luaK:_self (fs, v, key)\n"
+"   funcargs (fs, ast, v, 3)\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Index (fs, ast, v)\n"
+"   if #ast ~= 2 then\n"
+"      print\"\\n"
+"\\n"
+"BAD INDEX AST:\"\n"
+"      pp.print(ast)\n"
+"      error \"generalized indexes not implemented\" end\n"
+"\n   if ast.lineinfo then fs.lastline = ast.lineinfo.last.line end\n"
+"\n   --assert(fs.lastline ~= 0, ast.tag)\n"
+"\n   expr.expr (fs, ast[1], v)\n"
+"   luaK:exp2anyreg (fs, v)\n"
+"\n   local k = { }\n"
+"   expr.expr (fs, ast[2], k)\n"
+"   luaK:exp2val (fs, k)\n"
+"   luaK:indexed (fs, v, k)\n"
+"end  \n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Id (fs, ast, v)\n"
+"   assert (ast.tag == \"Id\")\n"
+"   singlevar (fs, ast[1], v)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"\nfunction expr.Stat (fs, ast, v)\n"
+"   --printf(\" * Stat: %i actvars, first freereg is %i\", fs.nactvar, fs.freereg)\n"
+"   --printf(\"   actvars: %s\", table.tostring(fs.actvar))\n"
+"\n   -- Protect temporary stack values by pretending they are local\n"
+"   -- variables. Local vars are in registers 0 ... fs.nactvar-1, \n"
+"   -- and temporary unnamed variables in fs.nactvar ... fs.freereg-1\n"
+"   local save_nactvar = fs.nactvar\n"
+"\n   -- Eventually, the result should go on top of stack *after all\n"
+"   -- `Stat{ } related computation and string usage is over. The index\n"
+"   -- of this destination register is kept here:\n"
+"   local dest_reg = fs.freereg\n"
+"\n   -- There might be variables in actvar whose register is > nactvar,\n"
+"   -- and therefore will not be protected by the \"nactvar := freereg\"\n"
+"   -- trick. Indeed, `Local only increases nactvar after the variable\n"
+"   -- content has been computed. Therefore, in \n"
+"   -- \"local foo = -{`Stat{...}}\", variable foo will be messed up by\n"
+"   -- the compilation of `Stat.\n"
+"   -- FIX: save the active variables at indices >= nactvar in\n"
+"   -- save_actvar, and restore them after `Stat has been computed.\n"
+"   --\n"
+"   -- I use a while rather than for loops and length operators because\n"
+"   -- fs.actvar is a 0-based array...\n"
+"   local save_actvar = { } do\n"
+"      local i = fs.nactvar\n"
+"      while true do\n"
+"         local v = fs.actvar[i]\n"
+"         if not v then break end\n"
+"         --printf(\"save hald-baked actvar %s at index %i\", table.tostring(v), i)\n"
+"         save_actvar[i] = v\n"
+"         i=i+1\n"
+"      end\n"
+"   end\n"
+"\n   fs.nactvar = fs.freereg -- Now temp unnamed registers are protected\n"
+"   enterblock (fs, { }, false)\n"
+"   chunk (fs, ast[1])\n"
+"   expr.expr (fs, ast[2], v)\n"
+"   luaK:exp2nextreg (fs, v)\n"
+"   leaveblock (fs)\n"
+"   luaK:exp2reg (fs, v, dest_reg)\n"
+"\n   -- Reserve the newly allocated stack level\n"
+"   -- Puzzled note: here was written \"fs.freereg = fs.freereg+1\".\n"
+"   -- I'm pretty sure it should rather be dest_reg+1, but maybe\n"
+"   -- both are equivalent?\n"
+"   fs.freereg = dest_reg+1\n"
+"\n   -- Restore nactvar, so that intermediate stacked value stop\n"
+"   -- being protected.\n"
+"   --printf(\"   nactvar back from %i to %i\", fs.nactvar, save_nactvar)\n"
+"   fs.nactvar = save_nactvar\n"
+"\n   -- restore messed-up unregistered local vars\n"
+"   for i, j in pairs(save_actvar) do\n"
+"      --printf(\"   Restoring actvar %i\", i)\n"
+"      fs.actvar[i] = j\n"
+"   end\n"
+"   --printf(\" * End of Stat\")\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- Main function: ast --> proto\n"
+"------------------------------------------------------------------------\n"
+"function M.ast_to_proto (ast, source)\n"
+"  local fs = open_func (nil)\n"
+"  fs.f.is_vararg = M.VARARG_ISVARARG\n"
+"  chunk (fs, ast)\n"
+"  close_func (fs)\n"
+"  assert (fs.prev == nil)\n"
+"  assert (fs.f.nups == 0)\n"
+"  assert (fs.nestlevel == 0)\n"
+"  if source then fs.f.source = source end\n"
+"  return fs.f, source\n"
+"end\n"
+"\nreturn M",
true, false);
// End of /metalua/compiler/bytecode/compile.lua
Lua5_1.provide_file("/metalua/compiler/bytecode/", "lcode.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2005-2013 Kein-Hong Man, Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Kein-Hong Man  - Initial implementation for Lua 5.0, part of Yueliang\n"
+"--     Fabien Fleutot - Port to Lua 5.1, integration with Metalua\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n--[[--------------------------------------------------------------------\n"
+"\n  $Id$\n"
+"\n  lcode.lua\n"
+"  Lua 5 code generator in Lua\n"
+"  This file is part of Yueliang.\n"
+"\n  Copyright (c) 2005 Kein-Hong Man <khman@users.sf.net>\n"
+"  The COPYRIGHT file describes the conditions\n"
+"  under which this software may be distributed.\n"
+"\n  See the ChangeLog for more information.\n"
+"\n------------------------------------------------------------------------\n"
+"\n  [FF] Slightly modified, mainly to produce Lua 5.1 bytecode.\n"
+"\n----------------------------------------------------------------------]]\n"
+"\n--[[--------------------------------------------------------------------\n"
+"-- Notes:\n"
+"-- * one function manipulate a pointer argument with a simple data type\n"
+"--   (can't be emulated by a table, ambiguous), now returns that value:\n"
+"--   luaK:concat(fs, l1, l2)\n"
+"-- * some function parameters changed to boolean, additional code\n"
+"--   translates boolean back to 1/0 for instruction fields\n"
+"-- * Added:\n"
+"--   luaK:ttisnumber(o) (from lobject.h)\n"
+"--   luaK:nvalue(o) (from lobject.h)\n"
+"--   luaK:setnilvalue(o) (from lobject.h)\n"
+"--   luaK:setsvalue(o) (from lobject.h)\n"
+"--   luaK:setnvalue(o) (from lobject.h)\n"
+"--   luaK:sethvalue(o) (from lobject.h)\n"
+"----------------------------------------------------------------------]]\n"
+"\nlocal luaP = require 'metalua.compiler.bytecode.lopcodes'\n"
+"\nlocal function debugf() end\n"
+"\nlocal luaK = { }\n"
+"\nluaK.MAXSTACK    = 250        -- (llimits.h, used in lcode.lua)\n"
+"luaK.LUA_MULTRET = -1         -- (lua.h)\n"
+"\n------------------------------------------------------------------------\n"
+"-- Marks the end of a patch list. It is an invalid value both as an absolute\n"
+"-- address, and as a list link (would link an element to itself).\n"
+"------------------------------------------------------------------------\n"
+"luaK.NO_JUMP = -1\n"
+"\n--FF 5.1\n"
+"function luaK:isnumeral(e)\n"
+"   return e.k==\"VKNUM\" and e.t==self.NO_JUMP and e.t==self.NO_JUMP\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- emulation of TObject macros (these are from lobject.h)\n"
+"-- * TObject is a table since lcode passes references around\n"
+"-- * tt member field removed, using Lua's type() instead\n"
+"------------------------------------------------------------------------\n"
+"function luaK:ttisnumber(o)\n"
+"  if o then return type(o.value) == \"number\" else return false end\n"
+"end\n"
+"function luaK:nvalue(o) return o.value end\n"
+"function luaK:setnilvalue(o) o.value = nil end\n"
+"function luaK:setsvalue(o, s) o.value = s end\n"
+"luaK.setnvalue = luaK.setsvalue\n"
+"luaK.sethvalue = luaK.setsvalue\n"
+"\n------------------------------------------------------------------------\n"
+"-- returns the instruction object for given e (expdesc)\n"
+"------------------------------------------------------------------------\n"
+"function luaK:getcode(fs, e)\n"
+"  return fs.f.code[e.info]\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- codes an instruction with a signed Bx (sBx) field\n"
+"------------------------------------------------------------------------\n"
+"function luaK:codeAsBx(fs, o, A, sBx)\n"
+"  return self:codeABx(fs, o, A, sBx + luaP.MAXARG_sBx)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:hasjumps(e)\n"
+"  return e.t ~= e.f\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- FF updated 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaK:_nil(fs, from, n)\n"
+"   if fs.pc > fs.lasttarget then  -- no jumps to current position?\n"
+"      if fs.pc == 0 then return end --function start, positions are already clean\n"
+"      local previous = fs.f.code[fs.pc - 1]\n"
+"      if luaP:GET_OPCODE(previous) == \"OP_LOADNIL\" then\n"
+"         local pfrom = luaP:GETARG_A(previous)\n"
+"         local pto = luaP:GETARG_B(previous)\n"
+"         if pfrom <= from and from <= pto + 1 then  -- can connect both?\n"
+"            if from + n - 1 > pto then\n"
+"               luaP:SETARG_B(previous, from + n - 1)\n"
+"            end\n"
+"            return\n"
+"         end\n"
+"      end\n"
+"   end\n"
+"   self:codeABC(fs, \"OP_LOADNIL\", from, from + n - 1, 0)  -- else no optimization\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:jump(fs)\n"
+"  local jpc = fs.jpc  -- save list of jumps to here\n"
+"  fs.jpc = self.NO_JUMP\n"
+"  local j = self:codeAsBx(fs, \"OP_JMP\", 0, self.NO_JUMP)\n"
+"  return self:concat(fs, j, jpc)  -- keep them on hold\n"
+"end\n"
+"\n--FF 5.1\n"
+"function luaK:ret (fs, first, nret)\n"
+"   luaK:codeABC (fs, \"OP_RETURN\", first, nret+1, 0)\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:condjump(fs, op, A, B, C)\n"
+"  self:codeABC(fs, op, A, B, C)\n"
+"  return self:jump(fs)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:fixjump(fs, pc, dest)\n"
+"  local jmp = fs.f.code[pc]\n"
+"  local offset = dest - (pc + 1)\n"
+"  assert(dest ~= self.NO_JUMP)\n"
+"  if math.abs(offset) > luaP.MAXARG_sBx then\n"
+"    error(\"control structure too long\")\n"
+"  end\n"
+"  luaP:SETARG_sBx(jmp, offset)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- returns current 'pc' and marks it as a jump target (to avoid wrong\n"
+"-- optimizations with consecutive instructions not in the same basic block).\n"
+"------------------------------------------------------------------------\n"
+"function luaK:getlabel(fs)\n"
+"  fs.lasttarget = fs.pc\n"
+"  return fs.pc\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:getjump(fs, pc)\n"
+"  local offset = luaP:GETARG_sBx(fs.f.code[pc])\n"
+"  if offset == self.NO_JUMP then  -- point to itself represents end of list\n"
+"    return self.NO_JUMP  -- end of list\n"
+"  else\n"
+"    return (pc + 1) + offset  -- turn offset into absolute position\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:getjumpcontrol(fs, pc)\n"
+"  local pi = fs.f.code[pc]\n"
+"  local ppi = fs.f.code[pc - 1]\n"
+"  if pc >= 1 and luaP:testOpMode(luaP:GET_OPCODE(ppi), \"OpModeT\") then\n"
+"    return ppi\n"
+"  else\n"
+"    return pi\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- check whether list has any jump that do not produce a value\n"
+"-- (or produce an inverted value)\n"
+"------------------------------------------------------------------------\n"
+"--FF updated 5.1\n"
+"function luaK:need_value(fs, list, cond)\n"
+"  while list ~= self.NO_JUMP do\n"
+"    local i = self:getjumpcontrol(fs, list)\n"
+"    if luaP:GET_OPCODE(i) ~= \"OP_TESTSET\" or\n"
+"       luaP:GETARG_A(i) ~= luaP.NO_REG or\n"
+"       luaP:GETARG_C(i) ~= cond then\n"
+"      return true\n"
+"    end\n"
+"    list = self:getjump(fs, list)\n"
+"  end\n"
+"  return false  -- not found\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"--FF updated 5.1\n"
+"function luaK:patchtestreg(fs, node, reg)\n"
+"   assert(reg) -- pour assurer, vu que j'ai ajoute un parametre p/r a 5.0\n"
+"   local i = self:getjumpcontrol(fs, node)\n"
+"   if luaP:GET_OPCODE(i) ~= \"OP_TESTSET\" then \n"
+"      return false end -- cannot patch other instructions\n"
+"   if reg ~= luaP.NO_REG and reg ~= luaP:GETARG_B(i) then\n"
+"      luaP:SETARG_A(i, reg)\n"
+"   else \n"
+"      -- no register to put value or register already has the value\n"
+"      luaP:SET_OPCODE(i, \"OP_TEST\")\n"
+"      luaP:SETARG_A(i, luaP:GETARG_B(i))\n"
+"      luaP:SETARG_B(i, 0)\n"
+"      luaP:SETARG_C(i, luaP:GETARG_C(i))\n"
+"   end\n"
+"   return true\n"
+"end\n"
+"\n--FF added 5.1\n"
+"function luaK:removevalues (fs, list)\n"
+"   while list ~= self.NO_JUMP do\n"
+"      self:patchtestreg (fs, list, luaP.NO_REG)\n"
+"      list = self:getjump (fs, list)\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- FF updated 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaK:patchlistaux(fs, list, vtarget, reg, dtarget)\n"
+"   while list ~= self.NO_JUMP do\n"
+"      local _next = self:getjump(fs, list)\n"
+"      if self:patchtestreg (fs, list, reg) then\n"
+"         self:fixjump(fs, list, vtarget)\n"
+"      else\n"
+"         self:fixjump (fs, list, dtarget)\n"
+"      end\n"
+"      list = _next\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:dischargejpc(fs)\n"
+"  self:patchlistaux(fs, fs.jpc, fs.pc, luaP.NO_REG, fs.pc)\n"
+"  fs.jpc = self.NO_JUMP\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:patchlist(fs, list, target)\n"
+"  if target == fs.pc then\n"
+"    self:patchtohere(fs, list)\n"
+"  else\n"
+"    assert(target < fs.pc)\n"
+"    self:patchlistaux(fs, list, target, luaP.NO_REG, target)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:patchtohere(fs, list)\n"
+"  self:getlabel(fs)\n"
+"  fs.jpc = self:concat(fs, fs.jpc, list)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- * l1 was a pointer, now l1 is returned and callee assigns the value\n"
+"------------------------------------------------------------------------\n"
+"function luaK:concat(fs, l1, l2)\n"
+"  if l2 == self.NO_JUMP then return l1  -- unchanged\n"
+"  elseif l1 == self.NO_JUMP then\n"
+"    return l2  -- changed\n"
+"  else\n"
+"    local list = l1\n"
+"    local _next = self:getjump(fs, list)\n"
+"    while _next ~= self.NO_JUMP do  -- find last element\n"
+"      list = _next\n"
+"      _next = self:getjump(fs, list)\n"
+"    end\n"
+"    self:fixjump(fs, list, l2)\n"
+"  end\n"
+"  return l1  -- unchanged\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:checkstack(fs, n)\n"
+"  local newstack = fs.freereg + n\n"
+"  if newstack > fs.f.maxstacksize then\n"
+"    if newstack >= luaK.MAXSTACK then\n"
+"      error(\"function or expression too complex\")\n"
+"    end\n"
+"    fs.f.maxstacksize = newstack\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:reserveregs(fs, n)\n"
+"  self:checkstack(fs, n)\n"
+"  fs.freereg = fs.freereg + n\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:freereg(fs, reg)\n"
+"  if not luaP:ISK (reg) and reg >= fs.nactvar then\n"
+"    fs.freereg = fs.freereg - 1\n"
+"    assert(reg == fs.freereg, \n"
+"           string.format(\"reg=%i, fs.freereg=%i\", reg, fs.freereg))\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:freeexp(fs, e)\n"
+"  if e.k == \"VNONRELOC\" then\n"
+"    self:freereg(fs, e.info)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- k is a constant, v is... what?\n"
+"-- fs.h is a hash value --> index in f.k\n"
+"------------------------------------------------------------------------\n"
+"-- * luaH_get, luaH_set deleted; direct table access used instead\n"
+"-- * luaO_rawequalObj deleted in first assert\n"
+"-- * setobj2n deleted in assignment of v to f.k table\n"
+"------------------------------------------------------------------------\n"
+"--FF radically updated, not completely understood\n"
+"function luaK:addk(fs, k, v)\n"
+"   local idx = fs.h[k.value]\n"
+"   local f = fs.f\n"
+"--   local oldsize = f.sizek\n"
+"   if self:ttisnumber (idx) then\n"
+"      --TODO this assert currently FAILS\n"
+"      --assert(fs.f.k[self:nvalue(idx)] == v)\n"
+"      return self:nvalue(idx)\n"
+"   else  -- constant not found; create a new entry\n"
+"      do\n"
+"         local t = type (v.value)\n"
+"         assert(t==\"nil\" or t==\"string\" or t==\"number\" or t==\"boolean\")\n"
+"      end\n"
+"      --debugf(\"[const: k[%i] = %s ]\", fs.nk, tostringv(v.value))\n"
+"      fs.f.k[fs.nk] = v\n"
+"      fs.h[k.value] = { }\n"
+"      self:setnvalue(fs.h[k.value], fs.nk)\n"
+"      local nk = fs.nk\n"
+"      fs.nk = fs.nk+1\n"
+"      return nk\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:stringK(fs, s)\n"
+"   assert (type(s)==\"string\")\n"
+"   local o = {}  -- TObject\n"
+"   self:setsvalue(o, s)\n"
+"   return self:addk(fs, o, o)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:numberK(fs, r)\n"
+"   assert (type(r)==\"number\")\n"
+"  local o = {}  -- TObject\n"
+"  self:setnvalue(o, r)\n"
+"  return self:addk(fs, o, o)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:boolK(fs, r)\n"
+"   assert (type(r)==\"boolean\")\n"
+"   local o = {}  -- TObject\n"
+"   self:setnvalue(o, r)\n"
+"   return self:addk(fs, o, o)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:nilK(fs)\n"
+"  local k, v = {}, {}  -- TObject\n"
+"  self:setnilvalue(v)\n"
+"  self:sethvalue(k, fs.h)  -- cannot use nil as key; instead use table itself\n"
+"  return self:addk(fs, k, v)\n"
+"end\n"
+"\n\n"
+"--FF 5.1\n"
+"function luaK:setreturns (fs, e, nresults)\n"
+"   if e.k == \"VCALL\" then  -- expression is an open function call?\n"
+"      luaP:SETARG_C(self:getcode(fs, e), nresults + 1)\n"
+"   elseif e.k == \"VVARARG\" then\n"
+"      luaP:SETARG_B (self:getcode (fs, e), nresults + 1)\n"
+"      luaP:SETARG_A (self:getcode (fs, e), fs.freereg)\n"
+"      self:reserveregs (fs, 1)\n"
+"   end\n"
+"end\n"
+"\n--FF 5.1\n"
+"function luaK:setmultret (fs, e)\n"
+"   self:setreturns (fs, e, self.LUA_MULTRET)\n"
+"end\n"
+"\n--FF 5.1\n"
+"function luaK:setoneret (fs, e)\n"
+"   if e.k == \"VCALL\" then  -- expression is an open function call?\n"
+"      e.k = \"VNONRELOC\"\n"
+"      e.info = luaP:GETARG_A(self:getcode(fs, e))\n"
+"   elseif e.k == \"VVARARG\" then\n"
+"      luaP:SETARG_B (self:getcode (fs, e), 2)\n"
+"      e.k = \"VRELOCABLE\"\n"
+"   end\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"--FF deprecated in 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaK:setcallreturns(fs, e, nresults)\n"
+"   assert (false, \"setcallreturns deprecated\")\n"
+"   --print \"SCR:\"\n"
+"   --printv(e)\n"
+"   --printv(self:getcode(fs, e))\n"
+"   if e.k == \"VCALL\" then  -- expression is an open function call?\n"
+"      luaP:SETARG_C(self:getcode(fs, e), nresults + 1)\n"
+"      if nresults == 1 then  -- 'regular' expression?\n"
+"         e.k = \"VNONRELOC\"\n"
+"         e.info = luaP:GETARG_A(self:getcode(fs, e))\n"
+"      end\n"
+"   elseif e.k == \"VVARARG\" then\n"
+"      --printf(\"Handle vararg return on expr %s, whose code is %s\", \n"
+"      --       tostringv(e), tostringv(self:getcode(fs, e)))\n"
+"      if nresults == 1 then\n"
+"         luaP:SETARG_B (self:getcode (fs, e), 2)\n"
+"         e.k = \"VRELOCABLE\"\n"
+"--FIXME: why no SETARG_A???\n"
+"      else\n"
+"         luaP:SETARG_B (self:getcode (fs, e), nresults + 1)\n"
+"         luaP:SETARG_A (self:getcode (fs, e), fs.freereg)\n"
+"         self:reserveregs (fs, 1)\n"
+"      --printf(\"Now code is %s\", tostringv(self:getcode(fs, e)))\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- Ajoute le code pour effectuer l'extraction de la locvar/upval/globvar\n"
+"-- /idx, sachant\n"
+"------------------------------------------------------------------------\n"
+"function luaK:dischargevars(fs, e)\n"
+"--printf(\"\\n"
+"dischargevars\\n"
+"\")\n"
+"  local k = e.k\n"
+"  if k == \"VLOCAL\" then\n"
+"    e.k = \"VNONRELOC\"\n"
+"  elseif k == \"VUPVAL\" then\n"
+"    e.info = self:codeABC(fs, \"OP_GETUPVAL\", 0, e.info, 0)\n"
+"    e.k = \"VRELOCABLE\"\n"
+"  elseif k == \"VGLOBAL\" then\n"
+"    e.info = self:codeABx(fs, \"OP_GETGLOBAL\", 0, e.info)\n"
+"    e.k = \"VRELOCABLE\"\n"
+"  elseif k == \"VINDEXED\" then\n"
+"    self:freereg(fs, e.aux)\n"
+"    self:freereg(fs, e.info)\n"
+"    e.info = self:codeABC(fs, \"OP_GETTABLE\", 0, e.info, e.aux)\n"
+"    e.k = \"VRELOCABLE\"\n"
+"  elseif k == \"VCALL\" or k == \"VVARARG\" then\n"
+"    self:setoneret(fs, e)\n"
+"  else\n"
+"    -- there is one value available (somewhere)\n"
+"  end\n"
+"--printf(\"\\n"
+"/dischargevars\\n"
+"\")\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:code_label(fs, A, b, jump)\n"
+"  self:getlabel(fs)  -- those instructions may be jump targets\n"
+"  return self:codeABC(fs, \"OP_LOADBOOL\", A, b, jump)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- FF updated 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaK:discharge2reg(fs, e, reg)\n"
+"   self:dischargevars(fs, e)\n"
+"   local k = e.k\n"
+"   if k == \"VNIL\" then\n"
+"      self:_nil(fs, reg, 1)\n"
+"   elseif k == \"VFALSE\" or k == \"VTRUE\" then\n"
+"      self:codeABC(fs, \"OP_LOADBOOL\", reg, (e.k == \"VTRUE\") and 1 or 0, 0)\n"
+"   elseif k == \"VKNUM\" then\n"
+"      self:codeABx (fs, \"OP_LOADK\", reg, self:numberK(fs, e.nval))\n"
+"   elseif k == \"VK\" then\n"
+"      self:codeABx(fs, \"OP_LOADK\", reg, e.info)\n"
+"   elseif k == \"VRELOCABLE\" then\n"
+"      local pc = self:getcode(fs, e)\n"
+"      luaP:SETARG_A(pc, reg)\n"
+"   elseif k == \"VNONRELOC\" then\n"
+"      if reg ~= e.info then\n"
+"         self:codeABC(fs, \"OP_MOVE\", reg, e.info, 0)\n"
+"      end\n"
+"   else\n"
+"      assert(e.k == \"VVOID\" or e.k == \"VJMP\")\n"
+"      return  -- nothing to do...\n"
+"   end\n"
+"   e.info = reg\n"
+"   e.k = \"VNONRELOC\"\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:discharge2anyreg(fs, e)\n"
+"  if e.k ~= \"VNONRELOC\" then\n"
+"    self:reserveregs(fs, 1)\n"
+"    self:discharge2reg(fs, e, fs.freereg - 1)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:exp2reg(fs, e, reg)\n"
+"  self:discharge2reg(fs, e, reg)\n"
+"  if e.k == \"VJMP\" then\n"
+"    e.t = self:concat(fs, e.t, e.info)  -- put this jump in 't' list\n"
+"  end\n"
+"  if self:hasjumps(e) then\n"
+"    local final  -- position after whole expression\n"
+"    local p_f = self.NO_JUMP  -- position of an eventual LOAD false\n"
+"    local p_t = self.NO_JUMP  -- position of an eventual LOAD true\n"
+"    if self:need_value(fs, e.t, 1) or self:need_value(fs, e.f, 0) then\n"
+"      local fj = self.NO_JUMP  -- first jump (over LOAD ops.)\n"
+"      if e.k ~= \"VJMP\" then fj = self:jump(fs) end\n"
+"      p_f = self:code_label(fs, reg, 0, 1)\n"
+"      p_t = self:code_label(fs, reg, 1, 0)\n"
+"      self:patchtohere(fs, fj)\n"
+"    end\n"
+"    final = self:getlabel(fs)\n"
+"    self:patchlistaux(fs, e.f, final, reg, p_f)\n"
+"    self:patchlistaux(fs, e.t, final, reg, p_t)\n"
+"  end\n"
+"  e.f, e.t = self.NO_JUMP, self.NO_JUMP\n"
+"  e.info = reg\n"
+"  e.k = \"VNONRELOC\"\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:exp2nextreg(fs, e)\n"
+"  self:dischargevars(fs, e)\n"
+"  --[FF] Allready in place (added for expr.Stat)\n"
+"  if e.k == \"VNONRELOC\" and e.info == fs.freereg then \n"
+"     --printf(\"Expression already in next reg %i: %s\", fs.freereg, tostringv(e))\n"
+"     return end\n"
+"  self:freeexp(fs, e)\n"
+"  self:reserveregs(fs, 1)\n"
+"  self:exp2reg(fs, e, fs.freereg - 1)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:exp2anyreg(fs, e)\n"
+"   --printf(\"exp2anyregs(e=%s)\", tostringv(e))\n"
+"   self:dischargevars(fs, e)\n"
+"   if e.k == \"VNONRELOC\" then\n"
+"      if not self:hasjumps(e) then  -- exp is already in a register\n"
+"         return e.info\n"
+"      end\n"
+"      if e.info >= fs.nactvar then  -- reg. is not a local?\n"
+"         self:exp2reg(fs, e, e.info)  -- put value on it\n"
+"         return e.info\n"
+"      end\n"
+"   end\n"
+"   self:exp2nextreg(fs, e)  -- default\n"
+"   return e.info\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:exp2val(fs, e)\n"
+"  if self:hasjumps(e) then\n"
+"    self:exp2anyreg(fs, e)\n"
+"  else\n"
+"    self:dischargevars(fs, e)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- FF updated 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaK:exp2RK(fs, e)\n"
+"   self:exp2val(fs, e)\n"
+"   local k = e.k\n"
+"   if k==\"VNIL\" or k==\"VTRUE\" or k==\"VFALSE\" or k==\"VKNUM\" then\n"
+"      if fs.nk <= luaP.MAXINDEXRK then\n"
+"         if     k==\"VNIL\"  then e.info = self:nilK(fs)\n"
+"         elseif k==\"VKNUM\" then e.info = self:numberK (fs, e.nval)\n"
+"         else                   e.info = self:boolK(fs, e.k==\"VTRUE\") end\n"
+"         e.k = \"VK\"\n"
+"         return luaP:RKASK(e.info)\n"
+"      end\n"
+"   elseif k == \"VK\" then\n"
+"      if e.info <= luaP.MAXINDEXRK then  -- constant fit in argC?\n"
+"         return luaP:RKASK (e.info)\n"
+"      end\n"
+"   end\n"
+"   -- not a constant in the right range: put it in a register\n"
+"   return self:exp2anyreg(fs, e)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:storevar(fs, var, exp)\n"
+"   --print(\"STOREVAR\")\n"
+"   --printf(\"var=%s\", tostringv(var))\n"
+"   --printf(\"exp=%s\", tostringv(exp))\n"
+"\n   local k = var.k\n"
+"   if k == \"VLOCAL\" then\n"
+"      self:freeexp(fs, exp)\n"
+"      self:exp2reg(fs, exp, var.info)\n"
+"      return\n"
+"   elseif k == \"VUPVAL\" then\n"
+"      local e = self:exp2anyreg(fs, exp)\n"
+"      self:codeABC(fs, \"OP_SETUPVAL\", e, var.info, 0)\n"
+"   elseif k == \"VGLOBAL\" then\n"
+"      --printf(\"store global, exp=%s\", tostringv(exp))\n"
+"      local e = self:exp2anyreg(fs, exp)\n"
+"      self:codeABx(fs, \"OP_SETGLOBAL\", e, var.info)\n"
+"   elseif k == \"VINDEXED\" then\n"
+"      local e = self:exp2RK(fs, exp)\n"
+"      self:codeABC(fs, \"OP_SETTABLE\", var.info, var.aux, e)\n"
+"   else\n"
+"      assert(0)  -- invalid var kind to store\n"
+"   end\n"
+"   self:freeexp(fs, exp)\n"
+"   --print(\"/STOREVAR\")\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:_self(fs, e, key)\n"
+"  self:exp2anyreg(fs, e)\n"
+"  self:freeexp(fs, e)\n"
+"  local func = fs.freereg\n"
+"  self:reserveregs(fs, 2)\n"
+"  self:codeABC(fs, \"OP_SELF\", func, e.info, self:exp2RK(fs, key))\n"
+"  self:freeexp(fs, key)\n"
+"  e.info = func\n"
+"  e.k = \"VNONRELOC\"\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- FF updated 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaK:invertjump(fs, e)\n"
+"   --printf(\"invertjump on jump instruction #%i\", e.info)\n"
+"   --printv(self:getcode(fs, e))\n"
+"   local pc = self:getjumpcontrol(fs, e.info)\n"
+"   assert(luaP:testOpMode(luaP:GET_OPCODE(pc), \"OpModeT\") and\n"
+"             luaP:GET_OPCODE(pc) ~= \"OP_TESTSET\" and\n"
+"             luaP:GET_OPCODE(pc) ~= \"OP_TEST\")\n"
+"   --printf(\"Before invert:\")\n"
+"   --printv(pc)\n"
+"   luaP:SETARG_A(pc, (luaP:GETARG_A(pc) == 0) and 1 or 0)\n"
+"   --printf(\"After invert:\")\n"
+"   --printv(pc)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:jumponcond(fs, e, cond)\n"
+"  if e.k == \"VRELOCABLE\" then\n"
+"    local ie = self:getcode(fs, e)\n"
+"    if luaP:GET_OPCODE(ie) == \"OP_NOT\" then\n"
+"      fs.pc = fs.pc - 1  -- remove previous OP_NOT\n"
+"      return self:condjump(fs, \"OP_TEST\", luaP:GETARG_B(ie), 0,\n"
+"                           cond and 0 or 1)\n"
+"    end\n"
+"    -- else go through\n"
+"  end\n"
+"  self:discharge2anyreg(fs, e)\n"
+"  self:freeexp(fs, e)\n"
+"  return self:condjump(fs, \"OP_TESTSET\", luaP.NO_REG, e.info, cond and 1 or 0)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:goiftrue(fs, e)\n"
+"  local pc  -- pc of last jump\n"
+"  self:dischargevars(fs, e)\n"
+"  local k = e.k\n"
+"  if k == \"VK\" or k == \"VTRUE\" or k == \"VKNUM\" then\n"
+"    pc = self.NO_JUMP  -- always true; do nothing\n"
+"  elseif k == \"VFALSE\" then\n"
+"    pc = self:jump(fs)  -- always jump\n"
+"  elseif k == \"VJMP\" then\n"
+"    self:invertjump(fs, e)\n"
+"    pc = e.info\n"
+"  else\n"
+"    pc = self:jumponcond(fs, e, false)\n"
+" end\n"
+"  e.f = self:concat(fs, e.f, pc)  -- insert last jump in 'f' list\n"
+"  self:patchtohere(fs, e.t)\n"
+"  e.t = self.NO_JUMP\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:goiffalse(fs, e)\n"
+"  local pc  -- pc of last jump\n"
+"  self:dischargevars(fs, e)\n"
+"  local k = e.k\n"
+"  if k == \"VNIL\" or k == \"VFALSE\"then\n"
+"    pc = self.NO_JUMP  -- always false; do nothing\n"
+"  elseif k == \"VTRUE\" then\n"
+"    pc = self:jump(fs)  -- always jump\n"
+"  elseif k == \"VJMP\" then\n"
+"    pc = e.info\n"
+"  else\n"
+"    pc = self:jumponcond(fs, e, true)\n"
+"  end\n"
+"  e.t = self:concat(fs, e.t, pc)  -- insert last jump in 't' list\n"
+"  self:patchtohere(fs, e.f)\n"
+"  e.f = self.NO_JUMP\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:codenot(fs, e)\n"
+"  self:dischargevars(fs, e)\n"
+"  local k = e.k\n"
+"  if k == \"VNIL\" or k == \"VFALSE\" then\n"
+"    e.k = \"VTRUE\"\n"
+"  elseif k == \"VK\" or k == \"VKNUM\" or k == \"VTRUE\" then\n"
+"    e.k = \"VFALSE\"\n"
+"  elseif k == \"VJMP\" then\n"
+"    self:invertjump(fs, e)\n"
+"  elseif k == \"VRELOCABLE\" or k == \"VNONRELOC\" then\n"
+"    self:discharge2anyreg(fs, e)\n"
+"    self:freeexp(fs, e)\n"
+"    e.info = self:codeABC(fs, \"OP_NOT\", 0, e.info, 0)\n"
+"    e.k = \"VRELOCABLE\"\n"
+"  else\n"
+"    assert(0)  -- cannot happen\n"
+"  end\n"
+"  -- interchange true and false lists\n"
+"  e.f, e.t = e.t, e.f\n"
+"  self:removevalues(fs, e.f)\n"
+"  self:removevalues(fs, e.t)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:indexed(fs, t, k)\n"
+"  t.aux = self:exp2RK(fs, k)\n"
+"  t.k = \"VINDEXED\"\n"
+"end\n"
+"\n--FF 5.1\n"
+"function luaK:constfolding (op, e1, e2)\n"
+"   if not self:isnumeral(e1) or not self:isnumeral(e2) then return false end\n"
+"   local v1, v2, e, r = e1.nval, e2 and e2.nval, nil\n"
+"   if     op == \"OP_ADD\" then r = v1+v2\n"
+"   elseif op == \"OP_SUB\" then r = v1-v2\n"
+"   elseif op == \"OP_MUL\" then r = v1*v2\n"
+"   elseif op == \"OP_DIV\" then if v2==0 then return false end r = v1/v2\n"
+"   elseif op == \"OP_MOD\" then if v2==0 then return false end r = v1%v2\n"
+"   elseif op == \"OP_POW\" then r = v1^v2\n"
+"   elseif op == \"OP_UNM\" then r = -v1\n"
+"   elseif op == \"OP_LEN\" then return false\n"
+"   else   assert (false, \"Unknown numeric value\") end\n"
+"   e1.nval = r\n"
+"   return true\n"
+"end\n"
+"\n--FF 5.1\n"
+"function luaK:codearith (fs, op, e1, e2)\n"
+"   if self:constfolding (op, e1, e2) then return else\n"
+"      local o1 = self:exp2RK (fs, e1)\n"
+"      local o2 = 0\n"
+"      if op ~= \"OP_UNM\" and op ~= \"OP_LEN\" then \n"
+"         o2 = self:exp2RK (fs, e2) end\n"
+"      self:freeexp(fs, e2)\n"
+"      self:freeexp(fs, e1)\n"
+"      e1.info = self:codeABC (fs, op, 0, o1, o2)\n"
+"      e1.k = \"VRELOCABLE\"\n"
+"   end\n"
+"end\n"
+"\n--FF 5.1\n"
+"function luaK:codecomp (fs, op, cond, e1, e2)\n"
+"   assert (type (cond) == \"boolean\")\n"
+"   local o1 = self:exp2RK (fs, e1)\n"
+"   local o2 = self:exp2RK (fs, e2)\n"
+"   self:freeexp (fs, e2)\n"
+"   self:freeexp (fs, e1)\n"
+"   if not cond and op ~= \"OP_EQ\" then \n"
+"      local temp = o1; o1=o2; o2=temp cond = true end\n"
+"   e1.info = self:condjump (fs, op, cond and 1 or 0, o1, o2)\n"
+"   e1.k = \"VJMP\"\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:prefix (fs, op, e)\n"
+"   local e2 = { t = self.NO_JUMP; f = self.NO_JUMP;\n"
+"                k = \"VKNUM\"; nval = 0 }\n"
+"   if op == \"unm\" then\n"
+"      if e.k == \"VK\" then\n"
+"         self:exp2anyreg (fs, e) end\n"
+"      self:codearith (fs, \"OP_UNM\", e, e2)\n"
+"   elseif op == \"not\" then\n"
+"      self:codenot (fs, e)\n"
+"   elseif op == \"len\" then\n"
+"      self:exp2anyreg (fs, e)\n"
+"      self:codearith (fs, \"OP_LEN\", e, e2)\n"
+"   else\n"
+"      assert (false, \"Unknown unary operator\")\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:infix (fs, op, v)\n"
+"  if op == \"and\" then\n"
+"    self:goiftrue(fs, v)\n"
+"  elseif op == \"or\" then\n"
+"    self:goiffalse(fs, v)\n"
+"  elseif op == \"concat\" then\n"
+"    self:exp2nextreg(fs, v)  -- operand must be on the 'stack'\n"
+" else\n"
+"    if not self:isnumeral (v) then self:exp2RK(fs, v) end\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"-- grep \"ORDER OPR\" if you change these enums\n"
+"------------------------------------------------------------------------\n"
+"luaK.arith_opc = {  -- done as a table lookup instead of a calc\n"
+"   add = \"OP_ADD\",\n"
+"   sub = \"OP_SUB\",\n"
+"   mul = \"OP_MUL\",\n"
+"   mod = \"OP_MOD\",\n"
+"   div = \"OP_DIV\",\n"
+"   pow = \"OP_POW\",\n"
+"   len = \"OP_LEN\",\n"
+"   [\"not\"] = \"OP_NOT\"\n"
+"}\n"
+"luaK.test_opc = {  -- was ops[] in the codebinop function\n"
+"  eq = {opc=\"OP_EQ\", cond=true},\n"
+"  lt = {opc=\"OP_LT\", cond=true},\n"
+"  le = {opc=\"OP_LE\", cond=true},\n"
+"\n  -- Pseudo-ops, with no metatable equivalent:\n"
+"  ne = {opc=\"OP_EQ\", cond=false},\n"
+"  gt = {opc=\"OP_LT\", cond=false},\n"
+"  ge = {opc=\"OP_LE\", cond=false}\n"
+"}\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:posfix(fs, op, e1, e2)\n"
+"   if op == \"and\" then\n"
+"      assert(e1.t == self.NO_JUMP)  -- list must be closed\n"
+"      self:dischargevars(fs, e2)\n"
+"      e2.f = self:concat(fs, e2.f, e1.f)\n"
+"      for k,v in pairs(e2) do e1[k]=v end -- *e1 = *e2\n"
+"   elseif op == \"or\" then\n"
+"      assert(e1.f == self.NO_JUMP)  -- list must be closed\n"
+"      self:dischargevars(fs, e2)\n"
+"      e2.t = self:concat(fs, e2.t, e1.t)\n"
+"      for k,v in pairs(e2) do e1[k]=v end -- *e1 = *e2\n"
+"   elseif op == \"concat\" then\n"
+"      self:exp2val(fs, e2)\n"
+"      if e2.k == \"VRELOCABLE\"\n"
+"         and luaP:GET_OPCODE(self:getcode(fs, e2)) == \"OP_CONCAT\" then\n"
+"         assert(e1.info == luaP:GETARG_B(self:getcode(fs, e2)) - 1)\n"
+"         self:freeexp(fs, e1)\n"
+"         luaP:SETARG_B(self:getcode(fs, e2), e1.info)\n"
+"         e1.k = \"VRELOCABLE\"; e1.info = e2.info\n"
+"      else\n"
+"         self:exp2nextreg(fs, e2)\n"
+"         self:codearith (fs, \"OP_CONCAT\", e1, e2)\n"
+"      end\n"
+"   else\n"
+"      local opc = self.arith_opc[op]\n"
+"      if opc then self:codearith (fs, opc, e1, e2) else\n"
+"         opc = self.test_opc[op] or error (\"Unknown operator \"..op)\n"
+"         self:codecomp (fs, opc.opc, opc.cond, e1, e2)\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:fixline(fs, line)\n"
+"   --assert (line)\n"
+"   if not line then\n"
+"     --print(debug.traceback \"fixline (line == nil)\")\n"
+"   end\n"
+"   fs.f.lineinfo[fs.pc - 1] = line or 0\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:code(fs, i, line)\n"
+"  if not line then \n"
+"    line = 0\n"
+"    --print(debug.traceback \"line == nil\")\n"
+"  end\n"
+"  local f = fs.f\n"
+"\n  do -- print it\n"
+"    local params = { }\n"
+"    for _,x in ipairs{\"A\",\"B\",\"Bx\", \"sBx\", \"C\"} do\n"
+"      if i[x] then table.insert (params, string.format (\"%s=%i\", x, i[x])) end\n"
+"    end\n"
+"    debugf (\"[code:\\t%s\\t%s]\", luaP.opnames[i.OP], table.concat (params, \", \"))\n"
+"  end\n"
+"\n  self:dischargejpc(fs)  -- 'pc' will change\n"
+"\n  f.code[fs.pc] = i\n"
+"  f.lineinfo[fs.pc] = line\n"
+"\n  if line == 0 then\n"
+"    f.lineinfo[fs.pc] = fs.lastline\n"
+"    if fs.lastline == 0 then\n"
+"      --print(debug.traceback())\n"
+"    end    \n"
+"  end\n"
+"\n  if f.lineinfo[fs.pc] == 0 then\n"
+"    f.lineinfo[fs.pc] = 42\n"
+"  end\n"
+"\n  local pc = fs.pc\n"
+"  fs.pc = fs.pc + 1\n"
+"  return pc\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- \n"
+"------------------------------------------------------------------------\n"
+"function luaK:codeABC(fs, o, a, b, c)\n"
+"  assert(luaP:getOpMode(o) == \"iABC\", o..\" is not an ABC operation\")\n"
+"  --assert getbmode(o) ~= opargn or b == 0\n"
+"  --assert getcmode(o) ~= opargn or c == 0\n"
+"  --FF\n"
+"  --return self:code(fs, luaP:CREATE_ABC(o, a, b, c), fs.ls.lastline)\n"
+"  return self:code(fs, luaP:CREATE_ABC(o, a, b, c), fs.lastline)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:codeABx(fs, o, a, bc)\n"
+"  assert(luaP:getOpMode(o) == \"iABx\" or luaP:getOpMode(o) == \"iAsBx\")\n"
+"  --assert getcmode(o) == opargn\n"
+"  --FF\n"
+"  --return self:code(fs, luaP:CREATE_ABx(o, a, bc), fs.ls.lastline)\n"
+"  return self:code(fs, luaP:CREATE_ABx(o, a, bc), fs.lastline)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"--\n"
+"------------------------------------------------------------------------\n"
+"function luaK:setlist (fs, base, nelems, tostore)\n"
+"   local c = math.floor ((nelems-1) / luaP.LFIELDS_PER_FLUSH + 1)\n"
+"   local b = tostore == self.LUA_MULTRET and 0 or tostore\n"
+"   assert (tostore ~= 0)\n"
+"   if c <= luaP.MAXARG_C then self:codeABC (fs, \"OP_SETLIST\", base, b, c)\n"
+"   else\n"
+"      self:codeABC (fs, \"OP_SETLIST\", base, b, 0)\n"
+"      self:code (fs, c, fs.lastline)--FIXME\n"
+"   end\n"
+"   fs.freereg = base + 1\n"
+"end\n"
+"\nreturn luaK",
true, false);
// End of /metalua/compiler/bytecode/lcode.lua
Lua5_1.provide_file("/metalua/compiler/bytecode/", "ldump.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2005-2013 Kein-Hong Man, Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Kein-Hong Man  - Initial implementation for Lua 5.0, part of Yueliang\n"
+"--     Fabien Fleutot - Port to Lua 5.1, integration with Metalua\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n--[[--------------------------------------------------------------------\n"
+"\n  ldump.lua\n"
+"  Save bytecodes in Lua\n"
+"  This file is part of Yueliang.\n"
+"\n  Copyright (c) 2005 Kein-Hong Man <khman@users.sf.net>\n"
+"  The COPYRIGHT file describes the conditions\n"
+"  under which this software may be distributed.\n"
+"\n------------------------------------------------------------------------\n"
+"\n  [FF] Slightly modified, mainly to produce Lua 5.1 bytecode.\n"
+"\n----------------------------------------------------------------------]]\n"
+"\n--[[--------------------------------------------------------------------\n"
+"-- Notes:\n"
+"-- * LUA_NUMBER (double), byte order (little endian) and some other\n"
+"--   header values hard-coded; see other notes below...\n"
+"-- * One significant difference is that instructions are still in table\n"
+"--   form (with OP/A/B/C/Bx fields) and luaP:Instruction() is needed to\n"
+"--   convert them into 4-char strings\n"
+"-- * Deleted:\n"
+"--   luaU:DumpVector: folded into DumpLines, DumpCode\n"
+"-- * Added:\n"
+"--   luaU:endianness() (from lundump.c)\n"
+"--   luaU:make_setS: create a chunk writer that writes to a string\n"
+"--   luaU:make_setF: create a chunk writer that writes to a file\n"
+"--     (lua.h contains a typedef for a Chunkwriter pointer, and\n"
+"--      a Lua-based implementation exists, writer() in lstrlib.c)\n"
+"--   luaU:from_double(x): encode double value for writing\n"
+"--   luaU:from_int(x): encode integer value for writing\n"
+"--     (error checking is limited for these conversion functions)\n"
+"--     (double conversion does not support denormals or NaNs)\n"
+"--   luaU:ttype(o) (from lobject.h)\n"
+"----------------------------------------------------------------------]]\n"
+"\nlocal luaP = require 'metalua.compiler.bytecode.lopcodes'\n"
+"\nlocal M = { }\n"
+"\nlocal format = { }\n"
+"format.header = string.dump(function()end):sub(1, 12)\n"
+"format.little_endian, format.int_size, \n"
+"format.size_t_size,   format.instr_size, \n"
+"format.number_size,   format.integral = format.header:byte(7, 12)\n"
+"format.little_endian = format.little_endian~=0\n"
+"format.integral      = format.integral     ~=0\n"
+"\nassert(format.integral or format.number_size==8, \"Number format not supported by dumper\")\n"
+"assert(format.little_endian, \"Big endian architectures not supported by dumper\")\n"
+"\n--requires luaP\n"
+"local luaU = { }\n"
+"M.luaU = luaU\n"
+"\nluaU.format = format\n"
+"\n-- constants used by dumper\n"
+"luaU.LUA_TNIL     = 0\n"
+"luaU.LUA_TBOOLEAN = 1\n"
+"luaU.LUA_TNUMBER  = 3 -- (all in lua.h)\n"
+"luaU.LUA_TSTRING  = 4\n"
+"luaU.LUA_TNONE   = -1\n"
+"\n-- definitions for headers of binary files\n"
+"--luaU.LUA_SIGNATURE = \"\\27Lua\"   -- binary files start with \"<esc>Lua\"\n"
+"--luaU.VERSION = 81               -- 0x50; last format change was in 5.0\n"
+"--luaU.FORMAT_VERSION = 0         -- 0 is official version. yeah I know I'm a liar.\n"
+"\n-- a multiple of PI for testing native format\n"
+"-- multiplying by 1E7 gives non-trivial integer values\n"
+"--luaU.TEST_NUMBER = 3.14159265358979323846E7\n"
+"\n--[[--------------------------------------------------------------------\n"
+"-- Additional functions to handle chunk writing\n"
+"-- * to use make_setS and make_setF, see test_ldump.lua elsewhere\n"
+"----------------------------------------------------------------------]]\n"
+"\n------------------------------------------------------------------------\n"
+"-- works like the lobject.h version except that TObject used in these\n"
+"-- scripts only has a 'value' field, no 'tt' field (native types used)\n"
+"------------------------------------------------------------------------\n"
+"function luaU:ttype(o)\n"
+"  local tt = type(o.value)\n"
+"  if     tt == \"number\"  then return self.LUA_TNUMBER\n"
+"  elseif tt == \"string\"  then return self.LUA_TSTRING\n"
+"  elseif tt == \"nil\"     then return self.LUA_TNIL\n"
+"  elseif tt == \"boolean\" then return self.LUA_TBOOLEAN\n"
+"  else\n"
+"    return self.LUA_TNONE  -- the rest should not appear\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- create a chunk writer that writes to a string\n"
+"-- * returns the writer function and a table containing the string\n"
+"-- * to get the final result, look in buff.data\n"
+"------------------------------------------------------------------------\n"
+"function luaU:make_setS()\n"
+"  local buff = {}\n"
+"        buff.data = \"\"\n"
+"  local writer =\n"
+"    function(s, buff)  -- chunk writer\n"
+"      if not s then return end\n"
+"      buff.data = buff.data..s\n"
+"    end\n"
+"  return writer, buff\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- create a chunk writer that writes to a file\n"
+"-- * returns the writer function and a table containing the file handle\n"
+"-- * if a nil is passed, then writer should close the open file\n"
+"------------------------------------------------------------------------\n"
+"function luaU:make_setF(filename)\n"
+"  local buff = {}\n"
+"        buff.h = io.open(filename, \"wb\")\n"
+"  if not buff.h then return nil end\n"
+"  local writer =\n"
+"    function(s, buff)  -- chunk writer\n"
+"      if not buff.h then return end\n"
+"      if not s then buff.h:close(); return end\n"
+"      buff.h:write(s)\n"
+"    end\n"
+"  return writer, buff\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- converts a IEEE754 double number to an 8-byte little-endian string\n"
+"-- * luaU:from_double() and luaU:from_int() are from ChunkBake project\n"
+"-- * supports +/- Infinity, but not denormals or NaNs\n"
+"-----------------------------------------------------------------------\n"
+"function luaU:from_double(x)\n"
+"  local function grab_byte(v)\n"
+"    return math.floor(v / 256),\n"
+"           string.char(math.mod(math.floor(v), 256))\n"
+"  end\n"
+"  local sign = 0\n"
+"  if x < 0 then sign = 1; x = -x end\n"
+"  local mantissa, exponent = math.frexp(x)\n"
+"  if x == 0 then -- zero\n"
+"    mantissa, exponent = 0, 0\n"
+"  elseif x == 1/0 then\n"
+"    mantissa, exponent = 0, 2047\n"
+"  else\n"
+"    mantissa = (mantissa * 2 - 1) * math.ldexp(0.5, 53)\n"
+"    exponent = exponent + 1022\n"
+"  end\n"
+"  local v, byte = \"\" -- convert to bytes\n"
+"  x = mantissa\n"
+"  for i = 1,6 do\n"
+"    x, byte = grab_byte(x); v = v..byte -- 47:0\n"
+"  end\n"
+"  x, byte = grab_byte(exponent * 16 + x); v = v..byte -- 55:48\n"
+"  x, byte = grab_byte(sign * 128 + x); v = v..byte -- 63:56\n"
+"  return v\n"
+"end\n"
+"\n-----------------------------------------------------------------------\n"
+"-- converts a number to a little-endian 32-bit integer string\n"
+"-- * input value assumed to not overflow, can be signed/unsigned\n"
+"-----------------------------------------------------------------------\n"
+"function luaU:from_int(x, size)\n"
+"  local v = \"\"\n"
+"  x = math.floor(x)\n"
+"  if x >= 0 then\n"
+"    for i = 1, size do\n"
+"      v = v..string.char(math.mod(x, 256)); x = math.floor(x / 256)\n"
+"    end\n"
+"  else -- x < 0\n"
+"    x = -x\n"
+"    local carry = 1\n"
+"    for i = 1, size do\n"
+"      local c = 255 - math.mod(x, 256) + carry\n"
+"      if c == 256 then c = 0; carry = 1 else carry = 0 end\n"
+"      v = v..string.char(c); x = math.floor(x / 256)\n"
+"    end\n"
+"  end\n"
+"  return v\n"
+"end\n"
+"\n--[[--------------------------------------------------------------------\n"
+"-- Functions to make a binary chunk\n"
+"-- * many functions have the size parameter removed, since output is\n"
+"--   in the form of a string and some sizes are implicit or hard-coded\n"
+"-- * luaU:DumpVector has been deleted (used in DumpCode & DumpLines)\n"
+"----------------------------------------------------------------------]]\n"
+"\n------------------------------------------------------------------------\n"
+"-- dump a block of literal bytes\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpLiteral(s, D) self:DumpBlock(s, D) end\n"
+"\n--[[--------------------------------------------------------------------\n"
+"-- struct DumpState:\n"
+"--   L  -- lua_State (not used in this script)\n"
+"--   write  -- lua_Chunkwriter (chunk writer function)\n"
+"--   data  -- void* (chunk writer context or data already written)\n"
+"----------------------------------------------------------------------]]\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps a block of bytes\n"
+"-- * lua_unlock(D.L), lua_lock(D.L) deleted\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpBlock(b, D) D.write(b, D.data) end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps a single byte\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpByte(y, D)\n"
+"  self:DumpBlock(string.char(y), D)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps a signed integer of size `format.int_size` (for int)\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpInt(x, D)\n"
+"  self:DumpBlock(self:from_int(x, format.int_size), D)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps an unsigned integer of size `format.size_t_size` (for size_t)\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpSize(x, D)\n"
+"  self:DumpBlock(self:from_int(x, format.size_t_size), D)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps a LUA_NUMBER; can be an int or double depending on the VM.\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpNumber(x, D)\n"
+"   if format.integral then\n"
+"      self:DumpBlock(self:from_int(x, format.number_size), D)\n"
+"   else\n"
+"      self:DumpBlock(self:from_double(x), D)\n"
+"   end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps a Lua string\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpString(s, D)\n"
+"  if s == nil then\n"
+"    self:DumpSize(0, D)\n"
+"  else\n"
+"    s = s..\"\\0\"  -- include trailing '\\0'\n"
+"    self:DumpSize(string.len(s), D)\n"
+"    self:DumpBlock(s, D)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps instruction block from function prototype\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpCode(f, D)\n"
+"  local n = f.sizecode\n"
+"  self:DumpInt(n, D)\n"
+"  --was DumpVector\n"
+"  for i = 0, n - 1 do\n"
+"    self:DumpBlock(luaP:Instruction(f.code[i]), D)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps local variable names from function prototype\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpLocals(f, D)\n"
+"  local n = f.sizelocvars\n"
+"  self:DumpInt(n, D)\n"
+"  for i = 0, n - 1 do\n"
+"    -- Dirty temporary fix: \n"
+"    -- `Stat{ } keeps properly count of the number of local vars,\n"
+"    -- but fails to keep score of their debug info (names).\n"
+"    -- It therefore might happen that #f.localvars < f.sizelocvars, or\n"
+"    -- that a variable's startpc and endpc fields are left unset.\n"
+"    -- FIXME: This might not be needed anymore, check the bug report\n"
+"    --        by J. Belmonte.\n"
+"    local var = f.locvars[i]\n"
+"    if not var then break end \n"
+"    -- printf(\"[DUMPLOCALS] dumping local var #%i = %s\", i, table.tostring(var))\n"
+"    self:DumpString(var.varname, D)\n"
+"    self:DumpInt(var.startpc or 0, D)\n"
+"    self:DumpInt(var.endpc or 0, D)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dumps line information from function prototype\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpLines(f, D)\n"
+"  local n = f.sizelineinfo\n"
+"  self:DumpInt(n, D)\n"
+"  --was DumpVector\n"
+"  for i = 0, n - 1 do\n"
+"    self:DumpInt(f.lineinfo[i], D)  -- was DumpBlock\n"
+"    --print(i, f.lineinfo[i])\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dump upvalue names from function prototype\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpUpvalues(f, D)\n"
+"  local n = f.sizeupvalues\n"
+"  self:DumpInt(n, D)\n"
+"  for i = 0, n - 1 do\n"
+"    self:DumpString(f.upvalues[i], D)\n"
+"  end\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dump constant pool from function prototype\n"
+"-- * nvalue(o) and tsvalue(o) macros removed\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpConstants(f, D)\n"
+"  local n = f.sizek\n"
+"  self:DumpInt(n, D)\n"
+"  for i = 0, n - 1 do\n"
+"    local o = f.k[i]  -- TObject\n"
+"    local tt = self:ttype(o)\n"
+"    assert (tt >= 0)\n"
+"    self:DumpByte(tt, D)\n"
+"    if tt == self.LUA_TNUMBER then\n"
+"       self:DumpNumber(o.value, D)\n"
+"    elseif tt == self.LUA_TSTRING then\n"
+"       self:DumpString(o.value, D)\n"
+"    elseif tt == self.LUA_TBOOLEAN then\n"
+"       self:DumpByte (o.value and 1 or 0, D)\n"
+"    elseif tt == self.LUA_TNIL then\n"
+"    else\n"
+"      assert(false)  -- cannot happen\n"
+"    end\n"
+"  end\n"
+"end\n"
+"\n\n"
+"function luaU:DumpProtos (f, D)\n"
+"  local n = f.sizep\n"
+"  assert (n)\n"
+"  self:DumpInt(n, D)\n"
+"  for i = 0, n - 1 do\n"
+"    self:DumpFunction(f.p[i], f.source, D)\n"
+"  end\n"
+"end\n"
+"\nfunction luaU:DumpDebug(f, D)\n"
+"  self:DumpLines(f, D)\n"
+"  self:DumpLocals(f, D)\n"
+"  self:DumpUpvalues(f, D)\n"
+"end\n"
+"\n\n"
+"------------------------------------------------------------------------\n"
+"-- dump child function prototypes from function prototype\n"
+"--FF completely reworked for 5.1 format\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpFunction(f, p, D)\n"
+"   -- print \"Dumping function:\"\n"
+"   -- table.print(f, 60)\n"
+"\n  local source = f.source\n"
+"  if source == p then source = nil end\n"
+"  self:DumpString(source, D)\n"
+"  self:DumpInt(f.lineDefined, D)\n"
+"  self:DumpInt(f.lastLineDefined or 42, D)\n"
+"  self:DumpByte(f.nups, D)\n"
+"  self:DumpByte(f.numparams, D)\n"
+"  self:DumpByte(f.is_vararg, D)\n"
+"  self:DumpByte(f.maxstacksize, D)\n"
+"  self:DumpCode(f, D)\n"
+"  self:DumpConstants(f, D)\n"
+"  self:DumpProtos( f, D)\n"
+"  self:DumpDebug(f, D)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dump Lua header section (some sizes hard-coded)\n"
+"--FF: updated for version 5.1\n"
+"------------------------------------------------------------------------\n"
+"function luaU:DumpHeader(D)\n"
+"  self:DumpLiteral(format.header, D)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- dump function as precompiled chunk\n"
+"-- * w, data are created from make_setS, make_setF\n"
+"--FF: suppressed extraneous [L] param\n"
+"------------------------------------------------------------------------\n"
+"function luaU:dump (Main, w, data)\n"
+"  local D = {}  -- DumpState\n"
+"  D.write = w\n"
+"  D.data = data\n"
+"  self:DumpHeader(D)\n"
+"  self:DumpFunction(Main, nil, D)\n"
+"  -- added: for a chunk writer writing to a file, this final call with\n"
+"  -- nil data is to indicate to the writer to close the file\n"
+"  D.write(nil, D.data)\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- find byte order (from lundump.c)\n"
+"-- * hard-coded to little-endian\n"
+"------------------------------------------------------------------------\n"
+"function luaU:endianness()\n"
+"  return 1\n"
+"end\n"
+"\n-- FIXME: ugly concat-base generation in [make_setS], bufferize properly! \n"
+"function M.dump_string (proto)\n"
+"   local writer, buff = luaU:make_setS()\n"
+"   luaU:dump (proto, writer, buff)\n"
+"   return buff.data\n"
+"end\n"
+"\n-- FIXME: [make_setS] sucks, perform synchronous file writing\n"
+"-- Now unused\n"
+"function M.dump_file (proto, filename)\n"
+"   local writer, buff = luaU:make_setS()\n"
+"   luaU:dump (proto, writer, buff)\n"
+"   local file = io.open (filename, \"wb\")\n"
+"   file:write (buff.data)\n"
+"   io.close(file)\n"
+"   --if UNIX_SHARPBANG then os.execute (\"chmod a+x \"..filename) end\n"
+"end\n"
+"\nreturn M\n",
true, false);
// End of /metalua/compiler/bytecode/ldump.lua
Lua5_1.provide_file("/metalua/compiler/bytecode/", "lopcodes.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2005-2013 Kein-Hong Man, Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Kein-Hong Man  - Initial implementation for Lua 5.0, part of Yueliang\n"
+"--     Fabien Fleutot - Port to Lua 5.1, integration with Metalua\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n--[[--------------------------------------------------------------------\n"
+"\n  $Id$\n"
+"\n  lopcodes.lua\n"
+"  Lua 5 virtual machine opcodes in Lua\n"
+"  This file is part of Yueliang.\n"
+"\n  Copyright (c) 2005 Kein-Hong Man <khman@users.sf.net>\n"
+"  The COPYRIGHT file describes the conditions\n"
+"  under which this software may be distributed.\n"
+"\n  See the ChangeLog for more information.\n"
+"\n------------------------------------------------------------------------\n"
+"\n  [FF] Slightly modified, mainly to produce Lua 5.1 bytecode.\n"
+"\n----------------------------------------------------------------------]]\n"
+"\n--[[--------------------------------------------------------------------\n"
+"-- Notes:\n"
+"-- * an Instruction is a table with OP, A, B, C, Bx elements; this\n"
+"--   should allow instruction handling to work with doubles and ints\n"
+"-- * Added:\n"
+"--   luaP:Instruction(i): convert field elements to a 4-char string\n"
+"--   luaP:DecodeInst(x): convert 4-char string into field elements\n"
+"-- * WARNING luaP:Instruction outputs instructions encoded in little-\n"
+"--   endian form and field size and positions are hard-coded\n"
+"----------------------------------------------------------------------]]\n"
+"\nlocal function debugf() end\n"
+"\nlocal luaP = { }\n"
+"\n--[[\n"
+"===========================================================================\n"
+"  We assume that instructions are unsigned numbers.\n"
+"  All instructions have an opcode in the first 6 bits.\n"
+"  Instructions can have the following fields:\n"
+"        'A' : 8 bits\n"
+"        'B' : 9 bits\n"
+"        'C' : 9 bits\n"
+"        'Bx' : 18 bits ('B' and 'C' together)\n"
+"        'sBx' : signed Bx\n"
+"\n  A signed argument is represented in excess K; that is, the number\n"
+"  value is the unsigned value minus K. K is exactly the maximum value\n"
+"  for that argument (so that -max is represented by 0, and +max is\n"
+"  represented by 2*max), which is half the maximum for the corresponding\n"
+"  unsigned argument.\n"
+"===========================================================================\n"
+"--]]\n"
+"\nluaP.OpMode = {\"iABC\", \"iABx\", \"iAsBx\"}  -- basic instruction format\n"
+"\n------------------------------------------------------------------------\n"
+"-- size and position of opcode arguments.\n"
+"-- * WARNING size and position is hard-coded elsewhere in this script\n"
+"------------------------------------------------------------------------\n"
+"luaP.SIZE_C  = 9\n"
+"luaP.SIZE_B  = 9\n"
+"luaP.SIZE_Bx = luaP.SIZE_C + luaP.SIZE_B\n"
+"luaP.SIZE_A  = 8\n"
+"\nluaP.SIZE_OP = 6\n"
+"\nluaP.POS_C  = luaP.SIZE_OP\n"
+"luaP.POS_B  = luaP.POS_C + luaP.SIZE_C\n"
+"luaP.POS_Bx = luaP.POS_C\n"
+"luaP.POS_A  = luaP.POS_B + luaP.SIZE_B\n"
+"\n--FF from 5.1\n"
+"luaP.BITRK = 2^(luaP.SIZE_B - 1)\n"
+"function luaP:ISK(x) return x >= self.BITRK end\n"
+"luaP.MAXINDEXRK = luaP.BITRK - 1\n"
+"function luaP:RKASK(x)\n"
+"   if x < self.BITRK then return x+self.BITRK else return x end\n"
+"end\n"
+"\n\n"
+"\n------------------------------------------------------------------------\n"
+"-- limits for opcode arguments.\n"
+"-- we use (signed) int to manipulate most arguments,\n"
+"-- so they must fit in BITS_INT-1 bits (-1 for sign)\n"
+"------------------------------------------------------------------------\n"
+"-- removed \"#if SIZE_Bx < BITS_INT-1\" test, assume this script is\n"
+"-- running on a Lua VM with double or int as LUA_NUMBER\n"
+"\nluaP.MAXARG_Bx  = math.ldexp(1, luaP.SIZE_Bx) - 1\n"
+"luaP.MAXARG_sBx = math.floor(luaP.MAXARG_Bx / 2)  -- 'sBx' is signed\n"
+"\nluaP.MAXARG_A = math.ldexp(1, luaP.SIZE_A) - 1\n"
+"luaP.MAXARG_B = math.ldexp(1, luaP.SIZE_B) - 1\n"
+"luaP.MAXARG_C = math.ldexp(1, luaP.SIZE_C) - 1\n"
+"\n-- creates a mask with 'n' 1 bits at position 'p'\n"
+"-- MASK1(n,p) deleted\n"
+"-- creates a mask with 'n' 0 bits at position 'p'\n"
+"-- MASK0(n,p) deleted\n"
+"\n--[[--------------------------------------------------------------------\n"
+"  Visual representation for reference:\n"
+"\n   31     |     |     |          0      bit position\n"
+"    +-----+-----+-----+----------+\n"
+"    |  B  |  C  |  A  |  Opcode  |      iABC format\n"
+"    +-----+-----+-----+----------+\n"
+"    -  9  -  9  -  8  -    6     -      field sizes\n"
+"    +-----+-----+-----+----------+\n"
+"    |   [s]Bx   |  A  |  Opcode  |      iABx | iAsBx format\n"
+"    +-----+-----+-----+----------+\n"
+"----------------------------------------------------------------------]]\n"
+"\n------------------------------------------------------------------------\n"
+"-- the following macros help to manipulate instructions\n"
+"-- * changed to a table object representation, very clean compared to\n"
+"--   the [nightmare] alternatives of using a number or a string\n"
+"------------------------------------------------------------------------\n"
+"\n-- these accept or return opcodes in the form of string names\n"
+"function luaP:GET_OPCODE(i) return self.ROpCode[i.OP] end\n"
+"function luaP:SET_OPCODE(i, o) i.OP = self.OpCode[o] end\n"
+"\nfunction luaP:GETARG_A(i) return i.A end\n"
+"function luaP:SETARG_A(i, u) i.A = u end\n"
+"\nfunction luaP:GETARG_B(i) return i.B end\n"
+"function luaP:SETARG_B(i, b) i.B = b end\n"
+"\nfunction luaP:GETARG_C(i) return i.C end\n"
+"function luaP:SETARG_C(i, b) i.C = b end\n"
+"\nfunction luaP:GETARG_Bx(i) return i.Bx end\n"
+"function luaP:SETARG_Bx(i, b) i.Bx = b end\n"
+"\nfunction luaP:GETARG_sBx(i) return i.Bx - self.MAXARG_sBx end\n"
+"function luaP:SETARG_sBx(i, b) i.Bx = b + self.MAXARG_sBx end\n"
+"\nfunction luaP:CREATE_ABC(o,a,b,c)\n"
+"  return {OP = self.OpCode[o], A = a, B = b, C = c}\n"
+"end\n"
+"\nfunction luaP:CREATE_ABx(o,a,bc)\n"
+"  return {OP = self.OpCode[o], A = a, Bx = bc}\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- Bit shuffling stuffs\n"
+"------------------------------------------------------------------------\n"
+"\nif false and pcall (require, 'bit') then\n"
+"   ------------------------------------------------------------------------\n"
+"   -- Return a 4-char string little-endian encoded form of an instruction\n"
+"   ------------------------------------------------------------------------\n"
+"   function luaP:Instruction(i)\n"
+"      --FIXME\n"
+"   end\n"
+"else\n"
+"   ------------------------------------------------------------------------   \n"
+"   -- Version without bit manipulation library.\n"
+"   ------------------------------------------------------------------------\n"
+"   local p2 = {1,2,4,8,16,32,64,128,256, 512, 1024, 2048, 4096}\n"
+"   -- keeps [n] bits from [x]\n"
+"   local function keep (x, n) return x % p2[n+1] end\n"
+"   -- shifts bits of [x] [n] places to the right\n"
+"   local function srb (x,n) return math.floor (x / p2[n+1]) end\n"
+"   -- shifts bits of [x] [n] places to the left\n"
+"   local function slb (x,n) return x * p2[n+1] end\n"
+"\n   ------------------------------------------------------------------------\n"
+"   -- Return a 4-char string little-endian encoded form of an instruction\n"
+"   ------------------------------------------------------------------------\n"
+"   function luaP:Instruction(i)\n"
+"      -- printf(\"Instr->string: %s %s\", self.opnames[i.OP], table.tostring(i))\n"
+"      local c0, c1, c2, c3\n"
+"      -- change to OP/A/B/C format if needed\n"
+"      if i.Bx then i.C = keep (i.Bx, 9); i.B = srb (i.Bx, 9) end\n"
+"      -- c0 = 6B from opcode + 2LSB from A (flushed to MSB)\n"
+"      c0 = i.OP + slb (keep (i.A, 2), 6) \n"
+"      -- c1 = 6MSB from A + 2LSB from C (flushed to MSB)\n"
+"      c1 = srb (i.A, 2) + slb (keep (i.C, 2), 6)\n"
+"      -- c2 = 7MSB from C + 1LSB from B (flushed to MSB)\n"
+"      c2 = srb (i.C, 2) + slb (keep (i.B, 1), 7)\n"
+"      -- c3 = 8MSB from B\n"
+"      c3 = srb (i.B, 1)\n"
+"      --printf (\"Instruction:   %s %s\", self.opnames[i.OP], tostringv (i))\n"
+"      --printf (\"Bin encoding:  %x %x %x %x\", c0, c1, c2, c3)  \n"
+"      return string.char(c0, c1, c2, c3)\n"
+"   end\n"
+"end\n"
+"------------------------------------------------------------------------\n"
+"-- decodes a 4-char little-endian string into an instruction struct\n"
+"------------------------------------------------------------------------\n"
+"function luaP:DecodeInst(x)\n"
+"  error \"Not implemented\"\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- invalid register that fits in 8 bits\n"
+"------------------------------------------------------------------------\n"
+"luaP.NO_REG = luaP.MAXARG_A\n"
+"\n------------------------------------------------------------------------\n"
+"-- R(x) - register\n"
+"-- Kst(x) - constant (in constant table)\n"
+"-- RK(x) == if x < MAXSTACK then R(x) else Kst(x-MAXSTACK)\n"
+"------------------------------------------------------------------------\n"
+"\n------------------------------------------------------------------------\n"
+"-- grep \"ORDER OP\" if you change these enums\n"
+"------------------------------------------------------------------------\n"
+"\n--[[--------------------------------------------------------------------\n"
+"Lua virtual machine opcodes (enum OpCode):\n"
+"------------------------------------------------------------------------\n"
+"name          args    description\n"
+"------------------------------------------------------------------------\n"
+"OP_MOVE       A B     R(A) := R(B)\n"
+"OP_LOADK      A Bx    R(A) := Kst(Bx)\n"
+"OP_LOADBOOL   A B C   R(A) := (Bool)B; if (C) PC++\n"
+"OP_LOADNIL    A B     R(A) := ... := R(B) := nil\n"
+"OP_GETUPVAL   A B     R(A) := UpValue[B]\n"
+"OP_GETGLOBAL  A Bx    R(A) := Gbl[Kst(Bx)]\n"
+"OP_GETTABLE   A B C   R(A) := R(B)[RK(C)]\n"
+"OP_SETGLOBAL  A Bx    Gbl[Kst(Bx)] := R(A)\n"
+"OP_SETUPVAL   A B     UpValue[B] := R(A)\n"
+"OP_SETTABLE   A B C   R(A)[RK(B)] := RK(C)\n"
+"OP_NEWTABLE   A B C   R(A) := {} (size = B,C)\n"
+"OP_SELF       A B C   R(A+1) := R(B); R(A) := R(B)[RK(C)]\n"
+"OP_ADD        A B C   R(A) := RK(B) + RK(C)\n"
+"OP_SUB        A B C   R(A) := RK(B) - RK(C)\n"
+"OP_MUL        A B C   R(A) := RK(B) * RK(C)\n"
+"OP_DIV        A B C   R(A) := RK(B) / RK(C)\n"
+"OP_POW        A B C   R(A) := RK(B) ^ RK(C)\n"
+"OP_UNM        A B     R(A) := -R(B)\n"
+"OP_NOT        A B     R(A) := not R(B)\n"
+"OP_CONCAT     A B C   R(A) := R(B).. ... ..R(C)\n"
+"OP_JMP        sBx     PC += sBx\n"
+"OP_EQ         A B C   if ((RK(B) == RK(C)) ~= A) then pc++\n"
+"OP_LT         A B C   if ((RK(B) <  RK(C)) ~= A) then pc++\n"
+"OP_LE         A B C   if ((RK(B) <= RK(C)) ~= A) then pc++\n"
+"OP_TEST       A B C   if (R(B) <=> C) then R(A) := R(B) else pc++\n"
+"OP_CALL       A B C   R(A), ... ,R(A+C-2) := R(A)(R(A+1), ... ,R(A+B-1))\n"
+"OP_TAILCALL   A B C   return R(A)(R(A+1), ... ,R(A+B-1))\n"
+"OP_RETURN     A B     return R(A), ... ,R(A+B-2)  (see note)\n"
+"OP_FORLOOP    A sBx   R(A)+=R(A+2); if R(A) <?= R(A+1) then PC+= sBx\n"
+"OP_TFORLOOP   A C     R(A+2), ... ,R(A+2+C) := R(A)(R(A+1), R(A+2));\n"
+"                      if R(A+2) ~= nil then pc++\n"
+"OP_TFORPREP   A sBx   if type(R(A)) == table then R(A+1):=R(A), R(A):=next;\n"
+"                      PC += sBx\n"
+"OP_SETLIST    A Bx    R(A)[Bx-Bx%FPF+i] := R(A+i), 1 <= i <= Bx%FPF+1\n"
+"OP_SETLISTO   A Bx    (see note)\n"
+"OP_CLOSE      A       close all variables in the stack up to (>=) R(A)\n"
+"OP_CLOSURE    A Bx    R(A) := closure(KPROTO[Bx], R(A), ... ,R(A+n))\n"
+"----------------------------------------------------------------------]]\n"
+"\nluaP.opnames = {}  -- opcode names\n"
+"luaP.OpCode = {}   -- lookup name -> number\n"
+"luaP.ROpCode = {}  -- lookup number -> name\n"
+"\nlocal i = 0\n"
+"for v in string.gfind([[\n"
+"MOVE -- 0\n"
+"LOADK\n"
+"LOADBOOL\n"
+"LOADNIL\n"
+"GETUPVAL\n"
+"GETGLOBAL -- 5\n"
+"GETTABLE\n"
+"SETGLOBAL\n"
+"SETUPVAL\n"
+"SETTABLE\n"
+"NEWTABLE -- 10\n"
+"SELF\n"
+"ADD\n"
+"SUB\n"
+"MUL\n"
+"DIV -- 15\n"
+"MOD\n"
+"POW\n"
+"UNM\n"
+"NOT\n"
+"LEN -- 20\n"
+"CONCAT\n"
+"JMP\n"
+"EQ\n"
+"LT\n"
+"LE -- 25\n"
+"TEST\n"
+"TESTSET\n"
+"CALL\n"
+"TAILCALL\n"
+"RETURN -- 30\n"
+"FORLOOP\n"
+"FORPREP\n"
+"TFORLOOP\n"
+"SETLIST\n"
+"CLOSE -- 35\n"
+"CLOSURE\n"
+"VARARG\n"
+"]], \"[%a]+\") do\n"
+"  local n = \"OP_\"..v\n"
+"  luaP.opnames[i] = v\n"
+"  luaP.OpCode[n] = i\n"
+"  luaP.ROpCode[i] = n\n"
+"  i = i + 1\n"
+"end\n"
+"luaP.NUM_OPCODES = i\n"
+"\n--[[\n"
+"===========================================================================\n"
+"  Notes:\n"
+"  (1) In OP_CALL, if (B == 0) then B = top. C is the number of returns - 1,\n"
+"      and can be 0: OP_CALL then sets 'top' to last_result+1, so\n"
+"      next open instruction (OP_CALL, OP_RETURN, OP_SETLIST) may use 'top'.\n"
+"\n  (2) In OP_RETURN, if (B == 0) then return up to 'top'\n"
+"\n  (3) For comparisons, B specifies what conditions the test should accept.\n"
+"\n  (4) All 'skips' (pc++) assume that next instruction is a jump\n"
+"\n  (5) OP_SETLISTO is used when the last item in a table constructor is a\n"
+"      function, so the number of elements set is up to top of stack\n"
+"===========================================================================\n"
+"--]]\n"
+"\n------------------------------------------------------------------------\n"
+"-- masks for instruction properties\n"
+"------------------------------------------------------------------------\n"
+"-- was enum OpModeMask:\n"
+"luaP.OpModeBreg = 2  -- B is a register\n"
+"luaP.OpModeBrk  = 3  -- B is a register/constant\n"
+"luaP.OpModeCrk  = 4  -- C is a register/constant\n"
+"luaP.OpModesetA = 5  -- instruction set register A\n"
+"luaP.OpModeK    = 6  -- Bx is a constant\n"
+"luaP.OpModeT    = 1  -- operator is a test\n"
+"\n------------------------------------------------------------------------\n"
+"-- get opcode mode, e.g. \"iABC\"\n"
+"------------------------------------------------------------------------\n"
+"function luaP:getOpMode(m)\n"
+"   --printv(m)\n"
+"   --printv(self.OpCode[m])\n"
+"   --printv(self.opmodes [self.OpCode[m]+1])\n"
+"   return self.OpMode[tonumber(string.sub(self.opmodes[self.OpCode[m] + 1], 7, 7))]\n"
+"end\n"
+"\n------------------------------------------------------------------------\n"
+"-- test an instruction property flag\n"
+"-- * b is a string, e.g. \"OpModeBreg\"\n"
+"------------------------------------------------------------------------\n"
+"function luaP:testOpMode(m, b)\n"
+"  return (string.sub(self.opmodes[self.OpCode[m] + 1], self[b], self[b]) == \"1\")\n"
+"end\n"
+"\n-- number of list items to accumulate before a SETLIST instruction\n"
+"-- (must be a power of 2)\n"
+"-- * used in lparser, lvm, ldebug, ltests\n"
+"luaP.LFIELDS_PER_FLUSH = 50 --FF updated to match 5.1\n"
+"\n-- luaP_opnames[] is set above, as the luaP.opnames table\n"
+"-- opmode(t,b,bk,ck,sa,k,m) deleted\n"
+"\n--[[--------------------------------------------------------------------\n"
+"  Legend for luaP:opmodes:\n"
+"  1 T  -> T (is a test?)\n"
+"  2 B  -> B is a register\n"
+"  3 b  -> B is an RK register/constant combination\n"
+"  4 C  -> C is an RK register/constant combination\n"
+"  5 A  -> register A is set by the opcode\n"
+"  6 K  -> Bx is a constant\n"
+"  7 m  -> 1 if iABC  layout,\n"
+"          2 if iABx  layout, \n"
+"          3 if iAsBx layout\n"
+"----------------------------------------------------------------------]]\n"
+"\nluaP.opmodes = {\n"
+"-- TBbCAKm      opcode\n"
+"  \"0100101\", -- OP_MOVE      0\n"
+"  \"0000112\", -- OP_LOADK\n"
+"  \"0000101\", -- OP_LOADBOOL\n"
+"  \"0100101\", -- OP_LOADNIL\n"
+"  \"0000101\", -- OP_GETUPVAL\n"
+"  \"0000112\", -- OP_GETGLOBAL 5\n"
+"  \"0101101\", -- OP_GETTABLE\n"
+"  \"0000012\", -- OP_SETGLOBAL\n"
+"  \"0000001\", -- OP_SETUPVAL\n"
+"  \"0011001\", -- OP_SETTABLE\n"
+"  \"0000101\", -- OP_NEWTABLE 10\n"
+"  \"0101101\", -- OP_SELF\n"
+"  \"0011101\", -- OP_ADD\n"
+"  \"0011101\", -- OP_SUB\n"
+"  \"0011101\", -- OP_MUL\n"
+"  \"0011101\", -- OP_DIV      15\n"
+"  \"0011101\", -- OP_MOD\n"
+"  \"0011101\", -- OP_POW\n"
+"  \"0100101\", -- OP_UNM\n"
+"  \"0100101\", -- OP_NOT\n"
+"  \"0100101\", -- OP_LEN      20\n"
+"  \"0101101\", -- OP_CONCAT\n"
+"  \"0000003\", -- OP_JMP\n"
+"  \"1011001\", -- OP_EQ\n"
+"  \"1011001\", -- OP_LT\n"
+"  \"1011001\", -- OP_LE       25\n"
+"  \"1000101\", -- OP_TEST\n"
+"  \"1100101\", -- OP_TESTSET\n"
+"  \"0000001\", -- OP_CALL\n"
+"  \"0000001\", -- OP_TAILCALL\n"
+"  \"0000001\", -- OP_RETURN   30\n"
+"  \"0000003\", -- OP_FORLOOP\n"
+"  \"0000103\", -- OP_FORPREP\n"
+"  \"1000101\", -- OP_TFORLOOP\n"
+"  \"0000001\", -- OP_SETLIST\n"
+"  \"0000001\", -- OP_CLOSE    35\n"
+"  \"0000102\", -- OP_CLOSURE\n"
+"  \"0000101\"  -- OP_VARARG\n"
+"}\n"
+"\nreturn luaP",
true, false);
// End of /metalua/compiler/bytecode/lopcodes.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "misc.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Summary: metalua parser, miscellaneous utility functions.\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Exported API:\n"
+"-- * [mlp.fget()]\n"
+"-- * [mlp.id()]\n"
+"-- * [mlp.opt_id()]\n"
+"-- * [mlp.id_list()]\n"
+"-- * [mlp.string()]\n"
+"-- * [mlp.opt_string()]\n"
+"-- * [mlp.id2string()]\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal gg       = require 'metalua.grammar.generator'\n"
+"\n-- TODO: replace splice-aware versions with naive ones, move etensions in ./meta\n"
+"\nreturn function(M)\n"
+"    local _M = gg.future(M)\n"
+"\n--[[ metaprog-free versions:\n"
+"    function M.id(lx)\n"
+"        if lx:peek().tag~='Id' then gg.parse_error(lx, \"Identifier expected\")\n"
+"        else return lx:next() end\n"
+"    end\n"
+"\n    function M.opt_id(lx)\n"
+"        if lx:peek().tag~='Id' then return lx:next() else return false end\n"
+"    end\n"
+"\n    function M.string(lx)\n"
+"        if lx:peek().tag~='String' then gg.parse_error(lx, \"String expected\")\n"
+"        else return lx:next() end\n"
+"    end\n"
+"\n    function M.opt_string(lx)\n"
+"        if lx:peek().tag~='String' then return lx:next() else return false end\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Converts an identifier into a string. Hopefully one day it'll handle\n"
+"    -- splices gracefully, but that proves quite tricky.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.id2string (id)\n"
+"        if id.tag == \"Id\" then id.tag = \"String\"; return id\n"
+"        else error (\"Identifier expected: \"..table.tostring(id, 'nohash')) end\n"
+"    end\n"
+"--]]\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Try to read an identifier (possibly as a splice), or return [false] if no\n"
+"    -- id is found.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.opt_id (lx)\n"
+"        local a = lx:peek();\n"
+"        if lx:is_keyword (a, \"-{\") then\n"
+"            local v = M.meta.splice(lx)\n"
+"            if v.tag ~= \"Id\" and v.tag ~= \"Splice\" then\n"
+"                gg.parse_error(lx, \"Bad id splice\")\n"
+"            end\n"
+"            return v\n"
+"        elseif a.tag == \"Id\" then return lx:next()\n"
+"        else return false end\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Mandatory reading of an id: causes an error if it can't read one.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.id (lx)\n"
+"        return M.opt_id (lx) or gg.parse_error(lx,\"Identifier expected\")\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Common helper function\n"
+"    --------------------------------------------------------------------------------\n"
+"    M.id_list = gg.list { primary = _M.id, separators = \",\" }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Converts an identifier into a string. Hopefully one day it'll handle\n"
+"    -- splices gracefully, but that proves quite tricky.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.id2string (id)\n"
+"        --print(\"id2string:\", disp.ast(id))\n"
+"        if id.tag == \"Id\" then id.tag = \"String\"; return id\n"
+"        elseif id.tag == \"Splice\" then\n"
+"            error (\"id2string on splice not implemented\")\n"
+"            -- Evaluating id[1] will produce `Id{ xxx },\n"
+"            -- and we want it to produce `String{ xxx }.\n"
+"            -- The following is the plain notation of:\n"
+"            -- +{ `String{ `Index{ `Splice{ -{id[1]} }, `Number 1 } } }\n"
+"            return { tag=\"String\",  { tag=\"Index\", { tag=\"Splice\", id[1] },\n"
+"                                      { tag=\"Number\", 1 } } }\n"
+"        else error (\"Identifier expected: \"..table.tostring(id, 'nohash')) end\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Read a string, possibly spliced, or return an error if it can't\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.string (lx)\n"
+"        local a = lx:peek()\n"
+"        if lx:is_keyword (a, \"-{\") then\n"
+"            local v = M.meta.splice(lx)\n"
+"            if v.tag ~= \"String\" and v.tag ~= \"Splice\" then\n"
+"                gg.parse_error(lx,\"Bad string splice\")\n"
+"            end\n"
+"            return v\n"
+"        elseif a.tag == \"String\" then return lx:next()\n"
+"        else error \"String expected\" end\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Try to read a string, or return false if it can't. No splice allowed.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.opt_string (lx)\n"
+"        return lx:peek().tag == \"String\" and lx:next()\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Chunk reader: block + Eof\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.skip_initial_sharp_comment (lx)\n"
+"        -- Dirty hack: I'm happily fondling lexer's private parts\n"
+"        -- FIXME: redundant with lexer:newstream()\n"
+"        lx :sync()\n"
+"        local i = lx.src:match (\"^#.-\\n"
+"()\", lx.i)\n"
+"        if i then\n"
+"            lx.i = i\n"
+"            lx.column_offset = i\n"
+"            lx.line = lx.line and lx.line + 1 or 1\n"
+"        end\n"
+"    end\n"
+"\n    local function chunk (lx)\n"
+"        if lx:peek().tag == 'Eof' then\n"
+"            return { } -- handle empty files\n"
+"        else\n"
+"            M.skip_initial_sharp_comment (lx)\n"
+"            local chunk = M.block (lx)\n"
+"            if lx:peek().tag ~= \"Eof\" then\n"
+"                gg.parse_error(lx, \"End-of-file expected\")\n"
+"            end\n"
+"            return chunk\n"
+"        end\n"
+"    end\n"
+"\n    -- chunk is wrapped in a sequence so that it has a \"transformer\" field.\n"
+"    M.chunk = gg.sequence { chunk, builder = unpack }\n"
+"\n    return M\n"
+"end",
true, false);
// End of /metalua/compiler/parser/misc.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "ext.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Non-Lua syntax extensions\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal gg        = require 'metalua.grammar.generator'\n"
+"\nreturn function(M)\n"
+"\n    local _M = gg.future(M)\n"
+"\n    ---------------------------------------------------------------------------\n"
+"    -- Algebraic Datatypes\n"
+"    ----------------------------------------------------------------------------\n"
+"    local function adt (lx)\n"
+"        local node = _M.id (lx)\n"
+"        local tagval = node[1]\n"
+"        -- tagkey = `Pair{ `String \"key\", `String{ -{tagval} } }\n"
+"        local tagkey = { tag=\"Pair\", {tag=\"String\", \"tag\"}, {tag=\"String\", tagval} }\n"
+"        if lx:peek().tag == \"String\" or lx:peek().tag == \"Number\" then\n"
+"            -- TODO support boolean litterals\n"
+"            return { tag=\"Table\", tagkey, lx:next() }\n"
+"        elseif lx:is_keyword (lx:peek(), \"{\") then\n"
+"            local x = M.table.table (lx)\n"
+"            table.insert (x, 1, tagkey)\n"
+"            return x\n"
+"        else return { tag=\"Table\", tagkey } end\n"
+"    end\n"
+"\n    M.adt = gg.sequence{ \"`\", adt, builder = unpack }\n"
+"\n    M.expr.primary :add(M.adt)\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- Anonymous lambda\n"
+"    ----------------------------------------------------------------------------\n"
+"    M.lambda_expr = gg.sequence{\n"
+"        \"|\", _M.func_params_content, \"|\", _M.expr,\n"
+"        builder = function (x)\n"
+"            local li = x[2].lineinfo\n"
+"            return { tag=\"Function\", x[1],\n"
+"                     { {tag=\"Return\", x[2], lineinfo=li }, lineinfo=li } }\n"
+"        end }\n"
+"\n    M.expr.primary :add (M.lambda_expr)\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Allows to write \"a `f` b\" instead of \"f(a, b)\". Taken from Haskell.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.expr_in_backquotes (lx) return M.expr(lx, 35) end -- 35=limited precedence\n"
+"    M.expr.infix :add{ name = \"infix function\",\n"
+"        \"`\", _M.expr_in_backquotes, \"`\", prec = 35, assoc=\"left\",\n"
+"        builder = function(a, op, b) return {tag=\"Call\", op[1], a, b} end }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- C-style op+assignments\n"
+"    -- TODO: no protection against side-effects in LHS vars.\n"
+"    --------------------------------------------------------------------------------\n"
+"    local function op_assign(kw, op)\n"
+"        local function rhs(a, b) return { tag=\"Op\", op, a, b } end\n"
+"        local function f(a,b)\n"
+"            if #a ~= #b then gg.parse_error \"assymetric operator+assignment\" end\n"
+"            local right = { }\n"
+"            local r = { tag=\"Set\", a, right }\n"
+"            for i=1, #a do right[i] = { tag=\"Op\", op, a[i], b[i] } end\n"
+"            return r\n"
+"        end\n"
+"        M.lexer :add (kw)\n"
+"        M.assignments[kw] = f\n"
+"    end\n"
+"\n    local ops = { add='+='; sub='-='; mul='*='; div='/=' }\n"
+"    for ast_op_name, keyword in pairs(ops) do op_assign(keyword, ast_op_name) end\n"
+"\n    return M\n"
+"end",
true, false);
// End of /metalua/compiler/parser/ext.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "meta.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2014 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-- Compile-time metaprogramming features: splicing ASTs generated during compilation,\n"
+"-- AST quasi-quoting helpers.\n"
+"\nlocal gg       = require 'metalua.grammar.generator'\n"
+"\nreturn function(M)\n"
+"    local _M = gg.future(M)\n"
+"    M.meta={ }\n"
+"    local _MM = gg.future(M.meta)\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- External splicing: compile an AST into a chunk, load and evaluate\n"
+"    -- that chunk, and replace the chunk by its result (which must also be\n"
+"    -- an AST).\n"
+"    --------------------------------------------------------------------------------\n"
+"\n    -- TODO: that's not part of the parser\n"
+"    function M.meta.eval (ast)\n"
+"        -- TODO: should there be one mlc per splice, or per parser instance?\n"
+"        local mlc = require 'metalua.compiler'.new()\n"
+"        local f = mlc :ast_to_function (ast, '=splice')\n"
+"        local result=f(M) -- splices act on the current parser\n"
+"        return result\n"
+"    end\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- Going from an AST to an AST representing that AST\n"
+"    -- the only hash-part key being lifted is `\"tag\"`.\n"
+"    -- Doesn't lift subtrees protected inside a `Splice{ ... }.\n"
+"    -- e.g. change `Foo{ 123 } into\n"
+"    -- `Table{ `Pair{ `String \"tag\", `String \"foo\" }, `Number 123 }\n"
+"    ----------------------------------------------------------------------------\n"
+"    local function lift (t)\n"
+"        --print(\"QUOTING:\", table.tostring(t, 60,'nohash'))\n"
+"        local cases = { }\n"
+"        function cases.table (t)\n"
+"            local mt = { tag = \"Table\" }\n"
+"            --table.insert (mt, { tag = \"Pair\", quote \"quote\", { tag = \"True\" } })\n"
+"            if t.tag == \"Splice\" then\n"
+"                assert (#t==1, \"Invalid splice\")\n"
+"                local sp = t[1]\n"
+"                return sp\n"
+"            elseif t.tag then\n"
+"                table.insert (mt, { tag=\"Pair\", lift \"tag\", lift(t.tag) })\n"
+"            end\n"
+"            for _, v in ipairs (t) do\n"
+"                table.insert (mt, lift(v))\n"
+"            end\n"
+"            return mt\n"
+"        end\n"
+"        function cases.number  (t) return { tag = \"Number\", t, quote = true } end\n"
+"        function cases.string  (t) return { tag = \"String\", t, quote = true } end\n"
+"        function cases.boolean (t) return { tag = t and \"True\" or \"False\", t, quote = true } end\n"
+"        local f = cases [type(t)]\n"
+"        if f then return f(t) else error (\"Cannot quote an AST containing \"..tostring(t)) end\n"
+"    end\n"
+"    M.meta.lift = lift\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- when this variable is false, code inside [-{...}] is compiled and\n"
+"    -- avaluated immediately. When it's true (supposedly when we're\n"
+"    -- parsing data inside a quasiquote), [-{foo}] is replaced by\n"
+"    -- [`Splice{foo}], which will be unpacked by [quote()].\n"
+"    --------------------------------------------------------------------------------\n"
+"    local in_a_quote = false\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Parse the inside of a \"-{ ... }\"\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.meta.splice_content (lx)\n"
+"        local parser_name = \"expr\"\n"
+"        if lx:is_keyword (lx:peek(2), \":\") then\n"
+"            local a = lx:next()\n"
+"            lx:next() -- skip \":\"\n"
+"            assert (a.tag==\"Id\", \"Invalid splice parser name\")\n"
+"            parser_name = a[1]\n"
+"        end\n"
+"        -- TODO FIXME running a new parser with the old lexer?!\n"
+"        local parser = require 'metalua.compiler.parser'.new()\n"
+"        local ast = parser [parser_name](lx)\n"
+"        if in_a_quote then -- only prevent quotation in this subtree\n"
+"            --printf(\"SPLICE_IN_QUOTE:\\n"
+"%s\", _G.table.tostring(ast, \"nohash\", 60))\n"
+"            return { tag=\"Splice\", ast }\n"
+"        else -- convert in a block, eval, replace with result\n"
+"            if parser_name == \"expr\" then ast = { { tag=\"Return\", ast } }\n"
+"            elseif parser_name == \"stat\"  then ast = { ast }\n"
+"            elseif parser_name ~= \"block\" then\n"
+"                error (\"splice content must be an expr, stat or block\") end\n"
+"            --printf(\"EXEC THIS SPLICE:\\n"
+"%s\", _G.table.tostring(ast, \"nohash\", 60))\n"
+"            return M.meta.eval (ast)\n"
+"        end\n"
+"    end\n"
+"\n    M.meta.splice = gg.sequence{ \"-{\", _MM.splice_content, \"}\", builder=unpack }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Parse the inside of a \"+{ ... }\"\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.meta.quote_content (lx)\n"
+"        local parser\n"
+"        if lx:is_keyword (lx:peek(2), \":\") then -- +{parser: content }\n"
+"            local parser_name = M.id(lx)[1]\n"
+"            parser = M[parser_name]\n"
+"            lx:next() -- skip \":\"\n"
+"        else -- +{ content }\n"
+"            parser = M.expr\n"
+"        end\n"
+"\n        local prev_iq = in_a_quote\n"
+"        in_a_quote = true\n"
+"        --print(\"IN_A_QUOTE\")\n"
+"        local content = parser (lx)\n"
+"        local q_content = M.meta.lift (content)\n"
+"        in_a_quote = prev_iq\n"
+"        return q_content\n"
+"    end\n"
+"\n    return M\n"
+"end",
true, false);
// End of /metalua/compiler/parser/meta.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "common.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n-- Shared common parser table. It will be filled by parser.init(),\n"
+"-- and every other module will be able to call its elements at runtime.\n"
+"--\n"
+"-- If the table was directly created in parser.init, a circular\n"
+"-- dependency would be created: parser.init depends on other modules to fill the table,\n"
+"-- so other modules can't simultaneously depend on it.\n"
+"\nreturn { }",
true, false);
// End of /metalua/compiler/parser/common.lua
Lua5_1.provide_file("/metalua/compiler/parser/annot/", "grammar.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal gg    = require 'metalua.grammar.generator'\n"
+"\nreturn function(M)\n"
+"    local _M = gg.future(M)\n"
+"    M.lexer :add '->'\n"
+"    local A = { }\n"
+"    local _A = gg.future(A)\n"
+"    M.annot = A\n"
+"\n    -- Type identifier: Lua keywords such as `\"nil\"` allowed.\n"
+"    function M.annot.tid(lx)\n"
+"        local w = lx :next()\n"
+"        local t = w.tag\n"
+"        if t=='Keyword' and w[1] :match '^[%a_][%w_]*$' or w.tag=='Id'\n"
+"        then return {tag='TId'; lineinfo=w.lineinfo; w[1]}\n"
+"        else return gg.parse_error (lx, 'tid expected') end\n"
+"    end\n"
+"\n    local field_types = { var='TVar'; const='TConst';\n"
+"                          currently='TCurrently'; field='TField' }\n"
+"\n    -- TODO check lineinfo\n"
+"    function M.annot.tf(lx)\n"
+"        local tk = lx:next()\n"
+"        local w = tk[1]\n"
+"        local tag = field_types[w]\n"
+"        if not tag then error ('Invalid field type '..w)\n"
+"        elseif tag=='TField' then return {tag='TField'} else\n"
+"            local te = M.te(lx)\n"
+"            return {tag=tag; te}\n"
+"        end\n"
+"    end\n"
+"\n    M.annot.tebar_content = gg.list{\n"
+"        name        = 'tebar content',\n"
+"        primary     = _A.te,\n"
+"        separators  = { \",\", \";\" },\n"
+"        terminators = \")\" }\n"
+"\n    M.annot.tebar = gg.multisequence{\n"
+"        name = 'annot.tebar',\n"
+"        --{ '*', builder = 'TDynbar' }, -- maybe not user-available\n"
+"        { '(', _A.tebar_content, ')',\n"
+"          builder = function(x) return x[1] end },\n"
+"        { _A.te }\n"
+"    }\n"
+"\n    M.annot.te = gg.multisequence{\n"
+"        name = 'annot.te',\n"
+"        { _A.tid, builder=function(x) return x[1] end },\n"
+"        { '*', builder = 'TDyn' },\n"
+"        { \"[\",\n"
+"          gg.list{\n"
+"              primary = gg.sequence{\n"
+"                  _M.expr, \"=\", _A.tf,\n"
+"                  builder = 'TPair'\n"
+"              },\n"
+"              separators  = { \",\", \";\" },\n"
+"              terminators = { \"]\", \"|\" } },\n"
+"          gg.onkeyword{ \"|\", _A.tf },\n"
+"          \"]\",\n"
+"          builder = function(x)\n"
+"              local fields, other = unpack(x)\n"
+"              return { tag='TTable', other or {tag='TField'}, fields }\n"
+"          end }, -- \"[ ... ]\"\n"
+"        { '(', _A.tebar_content, ')', '->', '(', _A.tebar_content, ')',\n"
+"          builder = function(x)\n"
+"               local p, r = unpack(x)\n"
+"               return {tag='TFunction', p, r }\n"
+"           end } }\n"
+"\n    M.annot.ts = gg.multisequence{\n"
+"        name = 'annot.ts',\n"
+"        { 'return', _A.tebar_content, builder='TReturn' },\n"
+"        { _A.tid, builder = function(x)\n"
+"              if x[1][1]=='pass' then return {tag='TPass'}\n"
+"              else error \"Bad statement type\" end\n"
+"          end } }\n"
+"\n-- TODO: add parsers for statements:\n"
+"-- #return tebar\n"
+"-- #alias = te\n"
+"-- #ell = tf\n"
+"--[[\n"
+"    M.annot.stat_annot = gg.sequence{\n"
+"        gg.list{ primary=_A.tid, separators='.' },\n"
+"        '=',\n"
+"        XXX??,\n"
+"        builder = 'Annot' }\n"
+"--]]\n"
+"\n    return M.annot\n"
+"end",
true, false);
// End of /metalua/compiler/parser/annot/grammar.lua
Lua5_1.provide_file("/metalua/compiler/parser/annot/", "generator.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nrequire 'checks'\n"
+"local gg = require 'metalua.grammar.generator'\n"
+"local M  = { }\n"
+"\nfunction M.opt(mlc, primary, a_type)\n"
+"    checks('table', 'table|function', 'string')\n"
+"    return gg.sequence{\n"
+"        primary,\n"
+"        gg.onkeyword{ \"#\", function() return assert(mlc.annot[a_type]) end },\n"
+"        builder = function(x)\n"
+"            local t, annot = unpack(x)\n"
+"            return annot and { tag='Annot', t, annot } or t\n"
+"        end }\n"
+"end\n"
+"\n-- split a list of \"foo\" and \"`Annot{foo, annot}\" into a list of \"foo\"\n"
+"-- and a list of \"annot\".\n"
+"-- No annot list is returned if none of the elements were annotated.\n"
+"function M.split(lst)\n"
+"    local x, a, some = { }, { }, false\n"
+"    for i, p in ipairs(lst) do\n"
+"        if p.tag=='Annot' then\n"
+"            some, x[i], a[i] = true, unpack(p)\n"
+"        else x[i] = p end\n"
+"    end\n"
+"    if some then return x, a else return lst end\n"
+"end\n"
+"\nreturn M\n",
true, false);
// End of /metalua/compiler/parser/annot/generator.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "stat.lua",
 "------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Summary: metalua parser, statement/block parser. This is part of the\n"
+"-- definition of module [mlp].\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Exports API:\n"
+"-- * [mlp.stat()]\n"
+"-- * [mlp.block()]\n"
+"-- * [mlp.for_header()]\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\nlocal lexer    = require 'metalua.grammar.lexer'\n"
+"local gg       = require 'metalua.grammar.generator'\n"
+"\nlocal annot = require 'metalua.compiler.parser.annot.generator'\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- List of all keywords that indicate the end of a statement block. Users are\n"
+"-- likely to extend this list when designing extensions.\n"
+"--------------------------------------------------------------------------------\n"
+"\n\n"
+"return function(M)\n"
+"    local _M = gg.future(M)\n"
+"\n    M.block_terminators = { \"else\", \"elseif\", \"end\", \"until\", \")\", \"}\", \"]\" }\n"
+"\n    -- FIXME: this must be handled from within GG!!!\n"
+"    -- FIXME: there's no :add method in the list anyway. Added by gg.list?!\n"
+"    function M.block_terminators :add(x)\n"
+"        if type (x) == \"table\" then for _, y in ipairs(x) do self :add (y) end\n"
+"        else table.insert (self, x) end\n"
+"    end\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- list of statements, possibly followed by semicolons\n"
+"    ----------------------------------------------------------------------------\n"
+"    M.block = gg.list {\n"
+"        name        = \"statements block\",\n"
+"        terminators = M.block_terminators,\n"
+"        primary     = function (lx)\n"
+"            -- FIXME use gg.optkeyword()\n"
+"            local x = M.stat (lx)\n"
+"            if lx:is_keyword (lx:peek(), \";\") then lx:next() end\n"
+"            return x\n"
+"        end }\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- Helper function for \"return <expr_list>\" parsing.\n"
+"    -- Called when parsing return statements.\n"
+"    -- The specific test for initial \";\" is because it's not a block terminator,\n"
+"    -- so without it gg.list would choke on \"return ;\" statements.\n"
+"    -- We don't make a modified copy of block_terminators because this list\n"
+"    -- is sometimes modified at runtime, and the return parser would get out of\n"
+"    -- sync if it was relying on a copy.\n"
+"    ----------------------------------------------------------------------------\n"
+"    local return_expr_list_parser = gg.multisequence{\n"
+"        { \";\" , builder = function() return { } end },\n"
+"        default = gg.list {\n"
+"            _M.expr, separators = \",\", terminators = M.block_terminators } }\n"
+"\n\n"
+"    local for_vars_list = gg.list{\n"
+"        name        = \"for variables list\",\n"
+"        primary     = _M.id,\n"
+"        separators  = \",\",\n"
+"        terminators = \"in\" }\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- for header, between [for] and [do] (exclusive).\n"
+"    -- Return the `Forxxx{...} AST, without the body element (the last one).\n"
+"    ----------------------------------------------------------------------------\n"
+"    function M.for_header (lx)\n"
+"        local vars = M.id_list(lx)\n"
+"        if lx :is_keyword (lx:peek(), \"=\") then\n"
+"            if #vars ~= 1 then\n"
+"                gg.parse_error (lx, \"numeric for only accepts one variable\")\n"
+"            end\n"
+"            lx:next() -- skip \"=\"\n"
+"            local exprs = M.expr_list (lx)\n"
+"            if #exprs < 2 or #exprs > 3 then\n"
+"                gg.parse_error (lx, \"numeric for requires 2 or 3 boundaries\")\n"
+"            end\n"
+"            return { tag=\"Fornum\", vars[1], unpack (exprs) }\n"
+"        else\n"
+"            if not lx :is_keyword (lx :next(), \"in\") then\n"
+"                gg.parse_error (lx, '\"=\" or \"in\" expected in for loop')\n"
+"            end\n"
+"            local exprs = M.expr_list (lx)\n"
+"            return { tag=\"Forin\", vars, exprs }\n"
+"        end\n"
+"    end\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- Function def parser helper: id ( . id ) *\n"
+"    ----------------------------------------------------------------------------\n"
+"    local function fn_builder (list)\n"
+"        local acc = list[1]\n"
+"        local first = acc.lineinfo.first\n"
+"        for i = 2, #list do\n"
+"            local index = M.id2string(list[i])\n"
+"            local li = lexer.new_lineinfo(first, index.lineinfo.last)\n"
+"            acc = { tag=\"Index\", acc, index, lineinfo=li }\n"
+"        end\n"
+"        return acc\n"
+"    end\n"
+"    local func_name = gg.list{ _M.id, separators = \".\", builder = fn_builder }\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- Function def parser helper: ( : id )?\n"
+"    ----------------------------------------------------------------------------\n"
+"    local method_name = gg.onkeyword{ name = \"method invocation\", \":\", _M.id,\n"
+"        transformers = { function(x) return x and x.tag=='Id' and M.id2string(x) end } }\n"
+"\n    ----------------------------------------------------------------------------\n"
+"    -- Function def builder\n"
+"    ----------------------------------------------------------------------------\n"
+"    local function funcdef_builder(x)\n"
+"        local name, method, func = unpack(x)\n"
+"        if method then\n"
+"            name = { tag=\"Index\", name, method,\n"
+"                     lineinfo = {\n"
+"                         first = name.lineinfo.first,\n"
+"                         last  = method.lineinfo.last } }\n"
+"            table.insert (func[1], 1, {tag=\"Id\", \"self\"})\n"
+"        end\n"
+"        local r = { tag=\"Set\", {name}, {func} }\n"
+"        r[1].lineinfo = name.lineinfo\n"
+"        r[2].lineinfo = func.lineinfo\n"
+"        return r\n"
+"    end\n"
+"\n\n"
+"    ----------------------------------------------------------------------------\n"
+"    -- if statement builder\n"
+"    ----------------------------------------------------------------------------\n"
+"    local function if_builder (x)\n"
+"        local cond_block_pairs, else_block, r = x[1], x[2], {tag=\"If\"}\n"
+"        local n_pairs = #cond_block_pairs\n"
+"        for i = 1, n_pairs do\n"
+"            local cond, block = unpack(cond_block_pairs[i])\n"
+"            r[2*i-1], r[2*i] = cond, block\n"
+"        end\n"
+"        if else_block then table.insert(r, #r+1, else_block) end\n"
+"        return r\n"
+"    end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- produce a list of (expr,block) pairs\n"
+"    --------------------------------------------------------------------------------\n"
+"    local elseifs_parser = gg.list {\n"
+"        gg.sequence { _M.expr, \"then\", _M.block , name='elseif parser' },\n"
+"        separators  = \"elseif\",\n"
+"        terminators = { \"else\", \"end\" }\n"
+"    }\n"
+"\n    local annot_expr = gg.sequence {\n"
+"        _M.expr,\n"
+"        gg.onkeyword{ \"#\", gg.future(M, 'annot').tf },\n"
+"        builder = function(x)\n"
+"            local e, a = unpack(x)\n"
+"            if a then return { tag='Annot', e, a }\n"
+"            else return e end\n"
+"        end }\n"
+"\n    local annot_expr_list = gg.list {\n"
+"        primary = annot.opt(M, _M.expr, 'tf'), separators = ',' }\n"
+"\n    ------------------------------------------------------------------------\n"
+"    -- assignments and calls: statements that don't start with a keyword\n"
+"    ------------------------------------------------------------------------\n"
+"    local function assign_or_call_stat_parser (lx)\n"
+"        local e = annot_expr_list (lx)\n"
+"        local a = lx:is_keyword(lx:peek())\n"
+"        local op = a and M.assignments[a]\n"
+"        -- TODO: refactor annotations\n"
+"        if op then\n"
+"            --FIXME: check that [e] is a LHS\n"
+"            lx :next()\n"
+"            local annots\n"
+"            e, annots = annot.split(e)\n"
+"            local v = M.expr_list (lx)\n"
+"            if type(op)==\"string\" then return { tag=op, e, v, annots }\n"
+"            else return op (e, v) end\n"
+"        else\n"
+"            assert (#e > 0)\n"
+"            if #e > 1 then\n"
+"                gg.parse_error (lx,\n"
+"                    \"comma is not a valid statement separator; statement can be \"..\n"
+"                    \"separated by semicolons, or not separated at all\")\n"
+"            elseif e[1].tag ~= \"Call\" and e[1].tag ~= \"Invoke\" then\n"
+"                local typename\n"
+"                if e[1].tag == 'Id' then\n"
+"                    typename = '(\"'..e[1][1]..'\") is an identifier'\n"
+"                elseif e[1].tag == 'Op' then\n"
+"                    typename = \"is an arithmetic operation\"\n"
+"                else typename = \"is of type '\"..(e[1].tag or \"<list>\")..\"'\" end\n"
+"                gg.parse_error (lx,\n"
+"                     \"This expression %s; \"..\n"
+"                     \"a statement was expected, and only function and method call \"..\n"
+"                     \"expressions can be used as statements\", typename);\n"
+"            end\n"
+"            return e[1]\n"
+"        end\n"
+"    end\n"
+"\n    M.local_stat_parser = gg.multisequence{\n"
+"        -- local function <name> <func_val>\n"
+"        { \"function\", _M.id, _M.func_val, builder =\n"
+"          function(x)\n"
+"              local vars = { x[1], lineinfo = x[1].lineinfo }\n"
+"              local vals = { x[2], lineinfo = x[2].lineinfo }\n"
+"              return { tag=\"Localrec\", vars, vals }\n"
+"          end },\n"
+"        -- local <id_list> ( = <expr_list> )?\n"
+"        default = gg.sequence{\n"
+"            gg.list{\n"
+"                primary = annot.opt(M, _M.id, 'tf'),\n"
+"                separators = ',' },\n"
+"            gg.onkeyword{ \"=\", _M.expr_list },\n"
+"            builder = function(x)\n"
+"                 local annotated_left, right = unpack(x)\n"
+"                 local left, annotations = annot.split(annotated_left)\n"
+"                 return {tag=\"Local\", left, right or { }, annotations }\n"
+"             end } }\n"
+"\n    ------------------------------------------------------------------------\n"
+"    -- statement\n"
+"    ------------------------------------------------------------------------\n"
+"    M.stat = gg.multisequence {\n"
+"        name = \"statement\",\n"
+"        { \"do\", _M.block, \"end\", builder =\n"
+"          function (x) return { tag=\"Do\", unpack (x[1]) } end },\n"
+"        { \"for\", _M.for_header, \"do\", _M.block, \"end\", builder =\n"
+"          function (x) x[1][#x[1]+1] = x[2]; return x[1] end },\n"
+"        { \"function\", func_name, method_name, _M.func_val, builder=funcdef_builder },\n"
+"        { \"while\", _M.expr, \"do\", _M.block, \"end\", builder = \"While\" },\n"
+"        { \"repeat\", _M.block, \"until\", _M.expr, builder = \"Repeat\" },\n"
+"        { \"local\", _M.local_stat_parser, builder = unpack },\n"
+"        { \"return\", return_expr_list_parser, builder =\n"
+"          function(x) x[1].tag='Return'; return x[1] end },\n"
+"        { \"break\", builder = function() return { tag=\"Break\" } end },\n"
+"        { \"-{\", gg.future(M, 'meta').splice_content, \"}\", builder = unpack },\n"
+"        { \"if\", gg.nonempty(elseifs_parser), gg.onkeyword{ \"else\", M.block }, \"end\",\n"
+"          builder = if_builder },\n"
+"        default = assign_or_call_stat_parser }\n"
+"\n    M.assignments = {\n"
+"        [\"=\"] = \"Set\"\n"
+"    }\n"
+"\n    function M.assignments:add(k, v) self[k] = v end\n"
+"\n    return M\n"
+"end",
true, false);
// End of /metalua/compiler/parser/stat.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "expr.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Exported API:\n"
+"-- * [mlp.expr()]\n"
+"-- * [mlp.expr_list()]\n"
+"-- * [mlp.func_val()]\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\nlocal pp    = require 'metalua.pprint'\n"
+"local gg    = require 'metalua.grammar.generator'\n"
+"local annot = require 'metalua.compiler.parser.annot.generator'\n"
+"\nreturn function(M)\n"
+"    local _M = gg.future(M)\n"
+"    local _table = gg.future(M, 'table')\n"
+"    local _meta  = gg.future(M, 'meta') -- TODO move to ext?\n"
+"    local _annot = gg.future(M, 'annot') -- TODO move to annot\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Non-empty expression list. Actually, this isn't used here, but that's\n"
+"    -- handy to give to users.\n"
+"    --------------------------------------------------------------------------------\n"
+"    M.expr_list = gg.list{ primary=_M.expr, separators=\",\" }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Helpers for function applications / method applications\n"
+"    --------------------------------------------------------------------------------\n"
+"    M.func_args_content = gg.list{\n"
+"        name        = \"function arguments\",\n"
+"        primary     = _M.expr,\n"
+"        separators  = \",\",\n"
+"        terminators = \")\" }\n"
+"\n    -- Used to parse methods\n"
+"    M.method_args = gg.multisequence{\n"
+"        name = \"function argument(s)\",\n"
+"        { \"{\",  _table.content, \"}\" },\n"
+"        { \"(\",  _M.func_args_content, \")\", builder = unpack },\n"
+"        { \"+{\", _meta.quote_content, \"}\" },\n"
+"        -- TODO lineinfo?\n"
+"        function(lx) local r = M.opt_string(lx); return r and {r} or { } end }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- [func_val] parses a function, from opening parameters parenthese to\n"
+"    -- \"end\" keyword included. Used for anonymous functions as well as\n"
+"    -- function declaration statements (both local and global).\n"
+"    --\n"
+"    -- It's wrapped in a [_func_val] eta expansion, so that when expr\n"
+"    -- parser uses the latter, they will notice updates of [func_val]\n"
+"    -- definitions.\n"
+"    --------------------------------------------------------------------------------\n"
+"    M.func_params_content = gg.list{\n"
+"        name=\"function parameters\",\n"
+"        gg.multisequence{ { \"...\", builder = \"Dots\" }, annot.opt(M, _M.id, 'te') },\n"
+"        separators  = \",\", terminators = {\")\", \"|\"} }\n"
+"\n    -- TODO move to annot\n"
+"    M.func_val = gg.sequence{\n"
+"        name = \"function body\",\n"
+"        \"(\", _M.func_params_content, \")\", _M.block, \"end\",\n"
+"        builder = function(x)\n"
+"             local params, body = unpack(x)\n"
+"             local annots, some = { }, false\n"
+"             for i, p in ipairs(params) do\n"
+"                 if p.tag=='Annot' then\n"
+"                     params[i], annots[i], some = p[1], p[2], true\n"
+"                 else annots[i] = false end\n"
+"             end\n"
+"             if some then return { tag='Function', params, body, annots }\n"
+"             else  return { tag='Function', params, body } end\n"
+"         end }\n"
+"\n    local func_val = function(lx) return M.func_val(lx) end\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- Default parser for primary expressions\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.id_or_literal (lx)\n"
+"        local a = lx:next()\n"
+"        if a.tag~=\"Id\" and a.tag~=\"String\" and a.tag~=\"Number\" then\n"
+"            local msg\n"
+"            if a.tag=='Eof' then\n"
+"                msg = \"End of file reached when an expression was expected\"\n"
+"            elseif a.tag=='Keyword' then\n"
+"                msg = \"An expression was expected, and `\"..a[1]..\n"
+"                    \"' can't start an expression\"\n"
+"            else\n"
+"                msg = \"Unexpected expr token \" .. pp.tostring (a)\n"
+"            end\n"
+"            gg.parse_error (lx, msg)\n"
+"        end\n"
+"        return a\n"
+"    end\n"
+"\n\n"
+"    --------------------------------------------------------------------------------\n"
+"    -- Builder generator for operators. Wouldn't be worth it if \"|x|\" notation\n"
+"    -- were allowed, but then lua 5.1 wouldn't compile it\n"
+"    --------------------------------------------------------------------------------\n"
+"\n    -- opf1 = |op| |_,a| `Op{ op, a }\n"
+"    local function opf1 (op) return\n"
+"        function (_,a) return { tag=\"Op\", op, a } end end\n"
+"\n    -- opf2 = |op| |a,_,b| `Op{ op, a, b }\n"
+"    local function opf2 (op) return\n"
+"        function (a,_,b) return { tag=\"Op\", op, a, b } end end\n"
+"\n    -- opf2r = |op| |a,_,b| `Op{ op, b, a } -- (args reversed)\n"
+"    local function opf2r (op) return\n"
+"        function (a,_,b) return { tag=\"Op\", op, b, a } end end\n"
+"\n    local function op_ne(a, _, b)\n"
+"        -- This version allows to remove the \"ne\" operator from the AST definition.\n"
+"        -- However, it doesn't always produce the exact same bytecode as Lua 5.1.\n"
+"        return { tag=\"Op\", \"not\",\n"
+"                 { tag=\"Op\", \"eq\", a, b, lineinfo= {\n"
+"                       first = a.lineinfo.first, last = b.lineinfo.last } } }\n"
+"    end\n"
+"\n\n"
+"    --------------------------------------------------------------------------------\n"
+"    --\n"
+"    -- complete expression\n"
+"    --\n"
+"    --------------------------------------------------------------------------------\n"
+"\n    -- FIXME: set line number. In [expr] transformers probably\n"
+"    M.expr = gg.expr {\n"
+"        name = \"expression\",\n"
+"        primary = gg.multisequence{\n"
+"            name = \"expr primary\",\n"
+"            { \"(\", _M.expr, \")\",               builder = \"Paren\" },\n"
+"            { \"function\", _M.func_val,         builder = unpack },\n"
+"            { \"-{\", _meta.splice_content, \"}\", builder = unpack },\n"
+"            { \"+{\", _meta.quote_content, \"}\",  builder = unpack },\n"
+"            { \"nil\",                           builder = \"Nil\" },\n"
+"            { \"true\",                          builder = \"True\" },\n"
+"            { \"false\",                         builder = \"False\" },\n"
+"            { \"...\",                           builder = \"Dots\" },\n"
+"            { \"{\", _table.content, \"}\",        builder = unpack },\n"
+"            _M.id_or_literal },\n"
+"\n        infix = {\n"
+"            name = \"expr infix op\",\n"
+"            { \"+\",  prec = 60, builder = opf2 \"add\"  },\n"
+"            { \"-\",  prec = 60, builder = opf2 \"sub\"  },\n"
+"            { \"*\",  prec = 70, builder = opf2 \"mul\"  },\n"
+"            { \"/\",  prec = 70, builder = opf2 \"div\"  },\n"
+"            { \"%\",  prec = 70, builder = opf2 \"mod\"  },\n"
+"            { \"^\",  prec = 90, builder = opf2 \"pow\",    assoc = \"right\" },\n"
+"            { \"..\", prec = 40, builder = opf2 \"concat\", assoc = \"right\" },\n"
+"            { \"==\", prec = 30, builder = opf2 \"eq\"  },\n"
+"            { \"~=\", prec = 30, builder = op_ne  },\n"
+"            { \"<\",  prec = 30, builder = opf2 \"lt\"  },\n"
+"            { \"<=\", prec = 30, builder = opf2 \"le\"  },\n"
+"            { \">\",  prec = 30, builder = opf2r \"lt\"  },\n"
+"            { \">=\", prec = 30, builder = opf2r \"le\"  },\n"
+"            { \"and\",prec = 20, builder = opf2 \"and\" },\n"
+"            { \"or\", prec = 10, builder = opf2 \"or\"  } },\n"
+"\n        prefix = {\n"
+"            name = \"expr prefix op\",\n"
+"            { \"not\", prec = 80, builder = opf1 \"not\" },\n"
+"            { \"#\",   prec = 80, builder = opf1 \"len\" },\n"
+"            { \"-\",   prec = 80, builder = opf1 \"unm\" } },\n"
+"\n        suffix = {\n"
+"            name = \"expr suffix op\",\n"
+"            { \"[\", _M.expr, \"]\", builder = function (tab, idx)\n"
+"              return {tag=\"Index\", tab, idx[1]} end},\n"
+"            { \".\", _M.id, builder = function (tab, field)\n"
+"              return {tag=\"Index\", tab, _M.id2string(field[1])} end },\n"
+"            { \"(\", _M.func_args_content, \")\", builder = function(f, args)\n"
+"              return {tag=\"Call\", f, unpack(args[1])} end },\n"
+"            { \"{\", _table.content, \"}\", builder = function (f, arg)\n"
+"              return {tag=\"Call\", f, arg[1]} end},\n"
+"            { \":\", _M.id, _M.method_args, builder = function (obj, post)\n"
+"              local m_name, args = unpack(post)\n"
+"              return {tag=\"Invoke\", obj, _M.id2string(m_name), unpack(args)} end},\n"
+"            { \"+{\", _meta.quote_content, \"}\", builder = function (f, arg)\n"
+"              return {tag=\"Call\", f,  arg[1] } end },\n"
+"            default = { name=\"opt_string_arg\", parse = _M.opt_string, builder = function(f, arg)\n"
+"              return {tag=\"Call\", f, arg } end } } }\n"
+"    return M\n"
+"end",
true, false);
// End of /metalua/compiler/parser/expr.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "table.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Exported API:\n"
+"-- * [M.table_bracket_field()]\n"
+"-- * [M.table_field()]\n"
+"-- * [M.table_content()]\n"
+"-- * [M.table()]\n"
+"--\n"
+"-- KNOWN BUG: doesn't handle final \";\" or \",\" before final \"}\"\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal gg  = require 'metalua.grammar.generator'\n"
+"\nreturn function(M)\n"
+"\n    M.table = { }\n"
+"    local _table = gg.future(M.table)\n"
+"    local _expr  = gg.future(M).expr\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- `[key] = value` table field definition\n"
+"    --------------------------------------------------------------------------------\n"
+"    M.table.bracket_pair = gg.sequence{ \"[\", _expr, \"]\", \"=\", _expr, builder = \"Pair\" }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- table element parser: list value, `id = value` pair or `[value] = value` pair.\n"
+"    --------------------------------------------------------------------------------\n"
+"    function M.table.element (lx)\n"
+"        if lx :is_keyword (lx :peek(), \"[\") then return M.table.bracket_pair(lx) end\n"
+"        local e = M.expr (lx)\n"
+"        if not lx :is_keyword (lx :peek(), \"=\") then return e end\n"
+"        lx :next(); -- skip the \"=\"\n"
+"        local key = M.id2string(e) -- will fail on non-identifiers\n"
+"        local val = M.expr(lx)\n"
+"        local r = { tag=\"Pair\", key, val }\n"
+"        r.lineinfo = { first = key.lineinfo.first, last = val.lineinfo.last }\n"
+"        return r\n"
+"    end\n"
+"\n    -----------------------------------------------------------------------------\n"
+"    -- table constructor, without enclosing braces; returns a full table object\n"
+"    -----------------------------------------------------------------------------\n"
+"    M.table.content  = gg.list {\n"
+"        -- eta expansion to allow patching the element definition\n"
+"        primary     =  _table.element,\n"
+"        separators  = { \",\", \";\" },\n"
+"        terminators = \"}\",\n"
+"        builder     = \"Table\" }\n"
+"\n    --------------------------------------------------------------------------------\n"
+"    -- complete table constructor including [{...}]\n"
+"    --------------------------------------------------------------------------------\n"
+"    -- TODO beware, stat and expr use only table.content, this can't be patched.\n"
+"    M.table.table = gg.sequence{ \"{\", _table.content, \"}\", builder = unpack }\n"
+"\n    return M\n"
+"end",
true, false);
// End of /metalua/compiler/parser/table.lua
Lua5_1.provide_file("/metalua/compiler/parser/", "lexer.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2014 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n----------------------------------------------------------------------\n"
+"-- Generate a new lua-specific lexer, derived from the generic lexer.\n"
+"----------------------------------------------------------------------\n"
+"\nlocal generic_lexer = require 'metalua.grammar.lexer'\n"
+"\nreturn function()\n"
+"    local lexer = generic_lexer.lexer :clone()\n"
+"\n    local keywords = {\n"
+"        \"and\", \"break\", \"do\", \"else\", \"elseif\",\n"
+"        \"end\", \"false\", \"for\", \"function\",\n"
+"        \"goto\", -- Lua5.2\n"
+"        \"if\",\n"
+"        \"in\", \"local\", \"nil\", \"not\", \"or\", \"repeat\",\n"
+"        \"return\", \"then\", \"true\", \"until\", \"while\",\n"
+"        \"...\", \"..\", \"==\", \">=\", \"<=\", \"~=\",\n"
+"        \"::\", -- Lua5,2\n"
+"        \"+{\", \"-{\" } -- Metalua\n"
+"\n    for _, w in ipairs(keywords) do lexer :add (w) end\n"
+"\n    return lexer\n"
+"end",
true, false);
// End of /metalua/compiler/parser/lexer.lua
Lua5_1.provide_file("/metalua/compiler/", "parser.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n-- Export all public APIs from sub-modules, squashed into a flat spacename\n"
+"\nlocal MT = { __type='metalua.compiler.parser' }\n"
+"\nlocal MODULE_REL_NAMES = { \"annot.grammar\", \"expr\", \"meta\", \"misc\",\n"
+"                           \"stat\", \"table\", \"ext\" }\n"
+"\nlocal function new()\n"
+"    local M = {\n"
+"        lexer = require \"metalua.compiler.parser.lexer\" ();\n"
+"        extensions = { } }\n"
+"    for _, rel_name in ipairs(MODULE_REL_NAMES) do\n"
+"        local abs_name = \"metalua.compiler.parser.\"..rel_name\n"
+"        local extender = require (abs_name)\n"
+"        if not M.extensions[abs_name] then\n"
+"            if type (extender) == 'function' then extender(M) end\n"
+"            M.extensions[abs_name] = extender\n"
+"        end\n"
+"    end\n"
+"    return setmetatable(M, MT)\n"
+"end\n"
+"\nreturn { new = new }\n",
true, false);
// End of /metalua/compiler/parser.lua
Lua5_1.provide_file("/metalua/compiler/", "bytecode.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal compile = require 'metalua.compiler.bytecode.compile'\n"
+"local ldump   = require 'metalua.compiler.bytecode.ldump'\n"
+"\nlocal M = { }\n"
+"\nM.ast_to_proto      = compile.ast_to_proto\n"
+"M.proto_to_bytecode = ldump.dump_string\n"
+"M.proto_to_file     = ldump.dump_file\n"
+"\nreturn M",
true, false);
// End of /metalua/compiler/bytecode.lua
Lua5_1.provide_file("/metalua/compiler/", "ast_to_src.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-{ extension ('match', ...) }\n"
+"\nlocal M = { }\n"
+"M.__index = M\n"
+"\nlocal pp=require 'metalua.pprint'\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Instanciate a new AST->source synthetizer\n"
+"--------------------------------------------------------------------------------\n"
+"function M.new ()\n"
+"   local self = {\n"
+"      _acc           = { },  -- Accumulates pieces of source as strings\n"
+"      current_indent = 0,    -- Current level of line indentation\n"
+"      indent_step    = \"   \" -- Indentation symbol, normally spaces or '\\t'\n"
+"   }\n"
+"   return setmetatable (self, M)\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Run a synthetizer on the `ast' arg and return the source as a string.\n"
+"-- Can also be used as a static method `M.run (ast)'; in this case,\n"
+"-- a temporary Metizer is instanciated on the fly.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:run (ast)\n"
+"   if not ast then\n"
+"      self, ast = M.new(), self\n"
+"   end\n"
+"   self._acc = { }\n"
+"   self:node (ast)\n"
+"   return table.concat (self._acc)\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Accumulate a piece of source file in the synthetizer.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:acc (x)\n"
+"   if x then table.insert (self._acc, x) end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Accumulate an indented newline.\n"
+"-- Jumps an extra line if indentation is 0, so that\n"
+"-- toplevel definitions are separated by an extra empty line.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:nl ()\n"
+"   if self.current_indent == 0 then self:acc \"\\n"
+"\"  end\n"
+"   self:acc (\"\\n"
+"\" .. self.indent_step:rep (self.current_indent))\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Increase indentation and accumulate a new line.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:nlindent ()\n"
+"   self.current_indent = self.current_indent + 1\n"
+"   self:nl ()\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Decrease indentation and accumulate a new line.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:nldedent ()\n"
+"   self.current_indent = self.current_indent - 1\n"
+"   self:acc (\"\\n"
+"\" .. self.indent_step:rep (self.current_indent))\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Keywords, which are illegal as identifiers.\n"
+"--------------------------------------------------------------------------------\n"
+"local keywords_list = {\n"
+"   \"and\",    \"break\",   \"do\",    \"else\",   \"elseif\",\n"
+"   \"end\",    \"false\",   \"for\",   \"function\", \"if\",\n"
+"   \"in\",     \"local\",   \"nil\",   \"not\",    \"or\",\n"
+"   \"repeat\", \"return\",  \"then\",  \"true\",   \"until\",\n"
+"   \"while\" }\n"
+"local keywords = { }\n"
+"for _, kw in pairs(keywords_list) do keywords[kw]=true end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Return true iff string `id' is a legal identifier name.\n"
+"--------------------------------------------------------------------------------\n"
+"local function is_ident (id)\n"
+"    return string['match'](id, \"^[%a_][%w_]*$\") and not keywords[id]\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Return true iff ast represents a legal function name for\n"
+"-- syntax sugar ``function foo.bar.gnat() ... end'':\n"
+"-- a series of nested string indexes, with an identifier as\n"
+"-- the innermost node.\n"
+"--------------------------------------------------------------------------------\n"
+"local function is_idx_stack (ast)\n"
+"   match ast with\n"
+"   | `Id{ _ }                     -> return true\n"
+"   | `Index{ left, `String{ _ } } -> return is_idx_stack (left)\n"
+"   | _                            -> return false\n"
+"   end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Operator precedences, in increasing order.\n"
+"-- This is not directly used, it's used to generate op_prec below.\n"
+"--------------------------------------------------------------------------------\n"
+"local op_preprec = {\n"
+"   { \"or\", \"and\" },\n"
+"   { \"lt\", \"le\", \"eq\", \"ne\" },\n"
+"   { \"concat\" },\n"
+"   { \"add\", \"sub\" },\n"
+"   { \"mul\", \"div\", \"mod\" },\n"
+"   { \"unary\", \"not\", \"len\" },\n"
+"   { \"pow\" },\n"
+"   { \"index\" } }\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- operator --> precedence table, generated from op_preprec.\n"
+"--------------------------------------------------------------------------------\n"
+"local op_prec = { }\n"
+"\nfor prec, ops in ipairs (op_preprec) do\n"
+"   for _, op in ipairs (ops) do\n"
+"      op_prec[op] = prec\n"
+"   end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- operator --> source representation.\n"
+"--------------------------------------------------------------------------------\n"
+"local op_symbol = {\n"
+"   add    = \" + \",   sub     = \" - \",   mul     = \" * \",\n"
+"   div    = \" / \",   mod     = \" % \",   pow     = \" ^ \",\n"
+"   concat = \" .. \",  eq      = \" == \",  ne      = \" ~= \",\n"
+"   lt     = \" < \",   le      = \" <= \",  [\"and\"] = \" and \",\n"
+"   [\"or\"] = \" or \",  [\"not\"] = \"not \",  len     = \"# \" }\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Accumulate the source representation of AST `node' in\n"
+"-- the synthetizer. Most of the work is done by delegating to\n"
+"-- the method having the name of the AST tag.\n"
+"-- If something can't be converted to normal sources, it's\n"
+"-- instead dumped as a `-{ ... }' splice in the source accumulator.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:node (node)\n"
+"   assert (self~=M and self._acc)\n"
+"   if node==nil then self:acc'<<error>>'; return end\n"
+"   if not node.tag then -- tagless block.\n"
+"      self:list (node, self.nl)\n"
+"   else\n"
+"      local f = M[node.tag]\n"
+"      if type (f) == \"function\" then -- Delegate to tag method.\n"
+"         f (self, node, unpack (node))\n"
+"      elseif type (f) == \"string\" then -- tag string.\n"
+"         self:acc (f)\n"
+"      else -- No appropriate method, fall back to splice dumping.\n"
+"           -- This cannot happen in a plain Lua AST.\n"
+"         self:acc \" -{ \"\n"
+"         self:acc (pp.tostring (node, {metalua_tag=1, hide_hash=1}), 80)\n"
+"         self:acc \" }\"\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"-- Convert every node in the AST list `list' passed as 1st arg.\n"
+"-- `sep' is an optional separator to be accumulated between each list element,\n"
+"-- it can be a string or a synth method.\n"
+"-- `start' is an optional number (default == 1), indicating which is the\n"
+"-- first element of list to be converted, so that we can skip the begining\n"
+"-- of a list.\n"
+"--------------------------------------------------------------------------------\n"
+"function M:list (list, sep, start)\n"
+"   for i = start or 1, # list do\n"
+"      self:node (list[i])\n"
+"      if list[i + 1] then\n"
+"         if not sep then\n"
+"         elseif type (sep) == \"function\" then sep (self)\n"
+"         elseif type (sep) == \"string\"   then self:acc (sep)\n"
+"         else   error \"Invalid list separator\" end\n"
+"      end\n"
+"   end\n"
+"end\n"
+"\n--------------------------------------------------------------------------------\n"
+"--\n"
+"-- Tag methods.\n"
+"-- ------------\n"
+"--\n"
+"-- Specific AST node dumping methods, associated to their node kinds\n"
+"-- by their name, which is the corresponding AST tag.\n"
+"-- synth:node() is in charge of delegating a node's treatment to the\n"
+"-- appropriate tag method.\n"
+"--\n"
+"-- Such tag methods are called with the AST node as 1st arg.\n"
+"-- As a convenience, the n node's children are passed as args #2 ... n+1.\n"
+"--\n"
+"-- There are several things that could be refactored into common subroutines\n"
+"-- here: statement blocks dumping, function dumping...\n"
+"-- However, given their small size and linear execution\n"
+"-- (they basically perform series of :acc(), :node(), :list(),\n"
+"-- :nl(), :nlindent() and :nldedent() calls), it seems more readable\n"
+"-- to avoid multiplication of such tiny functions.\n"
+"--\n"
+"-- To make sense out of these, you need to know metalua's AST syntax, as\n"
+"-- found in the reference manual or in metalua/doc/ast.txt.\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\nfunction M:Do (node)\n"
+"   self:acc      \"do\"\n"
+"   self:nlindent ()\n"
+"   self:list     (node, self.nl)\n"
+"   self:nldedent ()\n"
+"   self:acc      \"end\"\n"
+"end\n"
+"\nfunction M:Set (node)\n"
+"   match node with\n"
+"   | `Set{ { `Index{ lhs, `String{ method } } },\n"
+"           { `Function{ { `Id \"self\", ... } == params, body } } }\n"
+"         if is_idx_stack (lhs) and is_ident (method) ->\n"
+"      -- ``function foo:bar(...) ... end'' --\n"
+"      self:acc      \"function \"\n"
+"      self:node     (lhs)\n"
+"      self:acc      \":\"\n"
+"      self:acc      (method)\n"
+"      self:acc      \" (\"\n"
+"      self:list     (params, \", \", 2)\n"
+"      self:acc      \")\"\n"
+"      self:nlindent ()\n"
+"      self:list     (body, self.nl)\n"
+"      self:nldedent ()\n"
+"      self:acc      \"end\"\n"
+"\n   | `Set{ { lhs }, { `Function{ params, body } } } if is_idx_stack (lhs) ->\n"
+"      -- ``function foo(...) ... end'' --\n"
+"      self:acc      \"function \"\n"
+"      self:node     (lhs)\n"
+"      self:acc      \" (\"\n"
+"      self:list     (params, \", \")\n"
+"      self:acc      \")\"\n"
+"      self:nlindent ()\n"
+"      self:list    (body, self.nl)\n"
+"      self:nldedent ()\n"
+"      self:acc      \"end\"\n"
+"\n   | `Set{ { `Id{ lhs1name } == lhs1, ... } == lhs, rhs }\n"
+"         if not is_ident (lhs1name) ->\n"
+"      -- ``foo, ... = ...'' when foo is *not* a valid identifier.\n"
+"      -- In that case, the spliced 1st variable must get parentheses,\n"
+"      -- to be distinguished from a statement splice.\n"
+"      -- This cannot happen in a plain Lua AST.\n"
+"      self:acc      \"(\"\n"
+"      self:node     (lhs1)\n"
+"      self:acc      \")\"\n"
+"      if lhs[2] then -- more than one lhs variable\n"
+"         self:acc   \", \"\n"
+"         self:list  (lhs, \", \", 2)\n"
+"      end\n"
+"      self:acc      \" = \"\n"
+"      self:list     (rhs, \", \")\n"
+"\n   | `Set{ lhs, rhs } ->\n"
+"      -- ``... = ...'', no syntax sugar --\n"
+"      self:list  (lhs, \", \")\n"
+"      self:acc   \" = \"\n"
+"      self:list  (rhs, \", \")\n"
+"   | `Set{ lhs, rhs, annot } ->\n"
+"      -- ``... = ...'', no syntax sugar, annotation --\n"
+"      local n = #lhs\n"
+"      for i=1,n do\n"
+"          local ell, a = lhs[i], annot[i]\n"
+"          self:node (ell)\n"
+"          if a then\n"
+"              self:acc ' #'\n"
+"              self:node(a)\n"
+"          end\n"
+"          if i~=n then self:acc ', ' end\n"
+"      end\n"
+"      self:acc   \" = \"\n"
+"      self:list  (rhs, \", \")\n"
+"   end\n"
+"end\n"
+"\nfunction M:While (node, cond, body)\n"
+"   self:acc      \"while \"\n"
+"   self:node     (cond)\n"
+"   self:acc      \" do\"\n"
+"   self:nlindent ()\n"
+"   self:list     (body, self.nl)\n"
+"   self:nldedent ()\n"
+"   self:acc      \"end\"\n"
+"end\n"
+"\nfunction M:Repeat (node, body, cond)\n"
+"   self:acc      \"repeat\"\n"
+"   self:nlindent ()\n"
+"   self:list     (body, self.nl)\n"
+"   self:nldedent ()\n"
+"   self:acc      \"until \"\n"
+"   self:node     (cond)\n"
+"end\n"
+"\nfunction M:If (node)\n"
+"   for i = 1, #node-1, 2 do\n"
+"      -- for each ``if/then'' and ``elseif/then'' pair --\n"
+"      local cond, body = node[i], node[i+1]\n"
+"      self:acc      (i==1 and \"if \" or \"elseif \")\n"
+"      self:node     (cond)\n"
+"      self:acc      \" then\"\n"
+"      self:nlindent ()\n"
+"      self:list     (body, self.nl)\n"
+"      self:nldedent ()\n"
+"   end\n"
+"   -- odd number of children --> last one is an `else' clause --\n"
+"   if #node%2 == 1 then\n"
+"      self:acc      \"else\"\n"
+"      self:nlindent ()\n"
+"      self:list     (node[#node], self.nl)\n"
+"      self:nldedent ()\n"
+"   end\n"
+"   self:acc \"end\"\n"
+"end\n"
+"\nfunction M:Fornum (node, var, first, last)\n"
+"   local body = node[#node]\n"
+"   self:acc      \"for \"\n"
+"   self:node     (var)\n"
+"   self:acc      \" = \"\n"
+"   self:node     (first)\n"
+"   self:acc      \", \"\n"
+"   self:node     (last)\n"
+"   if #node==5 then -- 5 children --> child #4 is a step increment.\n"
+"      self:acc   \", \"\n"
+"      self:node  (node[4])\n"
+"   end\n"
+"   self:acc      \" do\"\n"
+"   self:nlindent ()\n"
+"   self:list     (body, self.nl)\n"
+"   self:nldedent ()\n"
+"   self:acc      \"end\"\n"
+"end\n"
+"\nfunction M:Forin (node, vars, generators, body)\n"
+"   self:acc      \"for \"\n"
+"   self:list     (vars, \", \")\n"
+"   self:acc      \" in \"\n"
+"   self:list     (generators, \", \")\n"
+"   self:acc      \" do\"\n"
+"   self:nlindent ()\n"
+"   self:list     (body, self.nl)\n"
+"   self:nldedent ()\n"
+"   self:acc      \"end\"\n"
+"end\n"
+"\nfunction M:Local (node, lhs, rhs, annots)\n"
+"    if next (lhs) then\n"
+"        self:acc     \"local \"\n"
+"        if annots then\n"
+"            local n = #lhs\n"
+"            for i=1, n do\n"
+"                self:node (lhs)\n"
+"                local a = annots[i]\n"
+"                if a then\n"
+"                    self:acc ' #'\n"
+"                    self:node (a)\n"
+"                end\n"
+"                if i~=n then self:acc ', ' end\n"
+"            end\n"
+"        else\n"
+"            self:list    (lhs, \", \")\n"
+"        end\n"
+"        if rhs[1] then\n"
+"            self:acc  \" = \"\n"
+"            self:list (rhs, \", \")\n"
+"        end\n"
+"    else -- Can't create a local statement with 0 variables in plain Lua\n"
+"        self:acc (table.tostring (node, 'nohash', 80))\n"
+"    end\n"
+"end\n"
+"\nfunction M:Localrec (node, lhs, rhs)\n"
+"   match node with\n"
+"   | `Localrec{ { `Id{name} }, { `Function{ params, body } } }\n"
+"         if is_ident (name) ->\n"
+"      -- ``local function name() ... end'' --\n"
+"      self:acc      \"local function \"\n"
+"      self:acc      (name)\n"
+"      self:acc      \" (\"\n"
+"      self:list     (params, \", \")\n"
+"      self:acc      \")\"\n"
+"      self:nlindent ()\n"
+"      self:list     (body, self.nl)\n"
+"      self:nldedent ()\n"
+"      self:acc      \"end\"\n"
+"\n   | _ ->\n"
+"      -- Other localrec are unprintable ==> splice them --\n"
+"          -- This cannot happen in a plain Lua AST. --\n"
+"      self:acc \"-{ \"\n"
+"      self:acc (table.tostring (node, 'nohash', 80))\n"
+"      self:acc \" }\"\n"
+"   end\n"
+"end\n"
+"\nfunction M:Call (node, f)\n"
+"   -- single string or table literal arg ==> no need for parentheses. --\n"
+"   local parens\n"
+"   match node with\n"
+"   | `Call{ _, `String{_} }\n"
+"   | `Call{ _, `Table{...}} -> parens = false\n"
+"   | _ -> parens = true\n"
+"   end\n"
+"   self:node (f)\n"
+"   self:acc  (parens and \" (\" or  \" \")\n"
+"   self:list (node, \", \", 2) -- skip `f'.\n"
+"   self:acc  (parens and \")\")\n"
+"end\n"
+"\nfunction M:Invoke (node, f, method)\n"
+"   -- single string or table literal arg ==> no need for parentheses. --\n"
+"   local parens\n"
+"   match node with\n"
+"   | `Invoke{ _, _, `String{_} }\n"
+"   | `Invoke{ _, _, `Table{...}} -> parens = false\n"
+"   | _ -> parens = true\n"
+"   end\n"
+"   self:node   (f)\n"
+"   self:acc    \":\"\n"
+"   self:acc    (method[1])\n"
+"   self:acc    (parens and \" (\" or  \" \")\n"
+"   self:list   (node, \", \", 3) -- Skip args #1 and #2, object and method name.\n"
+"   self:acc    (parens and \")\")\n"
+"end\n"
+"\nfunction M:Return (node)\n"
+"   self:acc  \"return \"\n"
+"   self:list (node, \", \")\n"
+"end\n"
+"\nM.Break = \"break\"\n"
+"M.Nil   = \"nil\"\n"
+"M.False = \"false\"\n"
+"M.True  = \"true\"\n"
+"M.Dots  = \"...\"\n"
+"\nfunction M:Number (node, n)\n"
+"   self:acc (tostring (n))\n"
+"end\n"
+"\nfunction M:String (node, str)\n"
+"   -- format \"%q\" prints '\\n"
+"' in an umpractical way IMO,\n"
+"   -- so this is fixed with the :gsub( ) call.\n"
+"   self:acc (string.format (\"%q\", str):gsub (\"\\\\\\n"
+"\", \"\\\\n"
+"\"))\n"
+"end\n"
+"\nfunction M:Function (node, params, body, annots)\n"
+"    self:acc      \"function (\"\n"
+"    if annots then\n"
+"        local n = #params\n"
+"        for i=1,n do\n"
+"            local p, a = params[i], annots[i]\n"
+"            self:node(p)\n"
+"            if annots then\n"
+"                self:acc \" #\"\n"
+"                self:node(a)\n"
+"            end\n"
+"            if i~=n then self:acc ', ' end\n"
+"        end\n"
+"    else\n"
+"        self:list (params, \", \")\n"
+"    end\n"
+"    self:acc      \")\"\n"
+"    self:nlindent ()\n"
+"    self:list     (body, self.nl)\n"
+"    self:nldedent ()\n"
+"    self:acc      \"end\"\n"
+"end\n"
+"\nfunction M:Table (node)\n"
+"   if not node[1] then self:acc \"{ }\" else\n"
+"      self:acc \"{\"\n"
+"      if #node > 1 then self:nlindent () else self:acc \" \" end\n"
+"      for i, elem in ipairs (node) do\n"
+"         match elem with\n"
+"         | `Pair{ `String{ key }, value } if is_ident (key) ->\n"
+"            -- ``key = value''. --\n"
+"            self:acc  (key)\n"
+"            self:acc  \" = \"\n"
+"            self:node (value)\n"
+"\n         | `Pair{ key, value } ->\n"
+"            -- ``[key] = value''. --\n"
+"            self:acc  \"[\"\n"
+"            self:node (key)\n"
+"            self:acc  \"] = \"\n"
+"            self:node (value)\n"
+"\n         | _ ->\n"
+"            -- ``value''. --\n"
+"            self:node (elem)\n"
+"         end\n"
+"         if node [i+1] then\n"
+"            self:acc \",\"\n"
+"            self:nl  ()\n"
+"         end\n"
+"      end\n"
+"      if #node > 1 then self:nldedent () else self:acc \" \" end\n"
+"      self:acc       \"}\"\n"
+"   end\n"
+"end\n"
+"\nfunction M:Op (node, op, a, b)\n"
+"   -- Transform ``not (a == b)'' into ``a ~= b''. --\n"
+"   match node with\n"
+"   | `Op{ \"not\", `Op{ \"eq\", _a, _b } }\n"
+"   | `Op{ \"not\", `Paren{ `Op{ \"eq\", _a, _b } } } ->\n"
+"      op, a, b = \"ne\", _a, _b\n"
+"   | _ ->\n"
+"   end\n"
+"\n   if b then -- binary operator.\n"
+"      local left_paren, right_paren\n"
+"      match a with\n"
+"      | `Op{ op_a, ...} if op_prec[op] >= op_prec[op_a] -> left_paren = true\n"
+"      | _ -> left_paren = false\n"
+"      end\n"
+"\n      match b with -- FIXME: might not work with right assoc operators ^ and ..\n"
+"      | `Op{ op_b, ...} if op_prec[op] >= op_prec[op_b] -> right_paren = true\n"
+"      | _ -> right_paren = false\n"
+"      end\n"
+"\n      self:acc  (left_paren and \"(\")\n"
+"      self:node (a)\n"
+"      self:acc  (left_paren and \")\")\n"
+"\n      self:acc  (op_symbol [op])\n"
+"\n      self:acc  (right_paren and \"(\")\n"
+"      self:node (b)\n"
+"      self:acc  (right_paren and \")\")\n"
+"\n   else -- unary operator.\n"
+"      local paren\n"
+"      match a with\n"
+"      | `Op{ op_a, ... } if op_prec[op] >= op_prec[op_a] -> paren = true\n"
+"      | _ -> paren = false\n"
+"      end\n"
+"      self:acc  (op_symbol[op])\n"
+"      self:acc  (paren and \"(\")\n"
+"      self:node (a)\n"
+"      self:acc  (paren and \")\")\n"
+"   end\n"
+"end\n"
+"\nfunction M:Paren (node, content)\n"
+"   self:acc  \"(\"\n"
+"   self:node (content)\n"
+"   self:acc  \")\"\n"
+"end\n"
+"\nfunction M:Index (node, table, key)\n"
+"   local paren_table\n"
+"   -- Check precedence, see if parens are needed around the table --\n"
+"   match table with\n"
+"   | `Op{ op, ... } if op_prec[op] < op_prec.index -> paren_table = true\n"
+"   | _ -> paren_table = false\n"
+"   end\n"
+"\n   self:acc  (paren_table and \"(\")\n"
+"   self:node (table)\n"
+"   self:acc  (paren_table and \")\")\n"
+"\n   match key with\n"
+"   | `String{ field } if is_ident (field) ->\n"
+"      -- ``table.key''. --\n"
+"      self:acc \".\"\n"
+"      self:acc (field)\n"
+"   | _ ->\n"
+"      -- ``table [key]''. --\n"
+"      self:acc   \"[\"\n"
+"      self:node (key)\n"
+"      self:acc   \"]\"\n"
+"   end\n"
+"end\n"
+"\nfunction M:Id (node, name)\n"
+"   if is_ident (name) then\n"
+"      self:acc (name)\n"
+"   else -- Unprintable identifier, fall back to splice representation.\n"
+"        -- This cannot happen in a plain Lua AST.\n"
+"      self:acc    \"-{`Id \"\n"
+"      self:String (node, name)\n"
+"      self:acc    \"}\"\n"
+"   end\n"
+"end\n"
+"\n\n"
+"M.TDyn    = '*'\n"
+"M.TDynbar = '**'\n"
+"M.TPass   = 'pass'\n"
+"M.TField  = 'field'\n"
+"M.TIdbar  = M.TId\n"
+"M.TReturn = M.Return\n"
+"\n\n"
+"function M:TId (node, name) self:acc(name) end\n"
+"\n\n"
+"function M:TCatbar(node, te, tebar)\n"
+"    self:acc'('\n"
+"    self:node(te)\n"
+"    self:acc'|'\n"
+"    self:tebar(tebar)\n"
+"    self:acc')'\n"
+"end\n"
+"\nfunction M:TFunction(node, p, r)\n"
+"    self:tebar(p)\n"
+"    self:acc '->'\n"
+"    self:tebar(r)\n"
+"end\n"
+"\nfunction M:TTable (node, default, pairs)\n"
+"    self:acc '['\n"
+"    self:list (pairs, ', ')\n"
+"    if default.tag~='TField' then\n"
+"        self:acc '|'\n"
+"        self:node (default)\n"
+"    end\n"
+"    self:acc ']'\n"
+"end\n"
+"\nfunction M:TPair (node, k, v)\n"
+"    self:node (k)\n"
+"    self:acc '='\n"
+"    self:node (v)\n"
+"end\n"
+"\nfunction M:TIdbar (node, name)\n"
+"    self :acc (name)\n"
+"end\n"
+"\nfunction M:TCatbar (node, a, b)\n"
+"    self:node(a)\n"
+"    self:acc ' ++ '\n"
+"    self:node(b)\n"
+"end\n"
+"\nfunction M:tebar(node)\n"
+"    if node.tag then self:node(node) else\n"
+"        self:acc '('\n"
+"        self:list(node, ', ')\n"
+"        self:acc ')'\n"
+"    end\n"
+"end\n"
+"\nfunction M:TUnkbar(node, name)\n"
+"    self:acc '~~'\n"
+"    self:acc (name)\n"
+"end\n"
+"\nfunction M:TUnk(node, name)\n"
+"    self:acc '~'\n"
+"    self:acc (name)\n"
+"end\n"
+"\nfor name, tag in pairs{ const='TConst', var='TVar', currently='TCurrently', just='TJust' } do\n"
+"    M[tag] = function(self, node, te)\n"
+"        self:acc (name..' ')\n"
+"        self:node(te)\n"
+"    end\n"
+"end\n"
+"\nreturn (|x| M.run(x))\n",
true, false);
// End of /metalua/compiler/ast_to_src.mlua
Lua5_1.provide_file("/metalua/compiler/", "globals.lua",
 "--------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"--------------------------------------------------------------------------------\n"
+"\n--*-lua-*-----------------------------------------------------------------------\n"
+"-- Override Lua's default compilation functions, so that they support Metalua\n"
+"-- rather than only plain Lua\n"
+"--------------------------------------------------------------------------------\n"
+"\nlocal mlc = require 'metalua.compiler'\n"
+"\nlocal M = { }\n"
+"\n-- Original versions\n"
+"local original_lua_versions = {\n"
+"    load       = load,\n"
+"    loadfile   = loadfile,\n"
+"    loadstring = loadstring,\n"
+"    dofile     = dofile }\n"
+"\nlocal lua_loadstring = loadstring\n"
+"local lua_loadfile = loadfile\n"
+"\nfunction M.loadstring(str, name)\n"
+"   if type(str) ~= 'string' then error 'string expected' end\n"
+"   if str:match '^\\027LuaQ' then return lua_loadstring(str) end\n"
+"   local n = str:match '^#![^\\n"
+"]*\\n"
+"()'\n"
+"   if n then str=str:sub(n, -1) end\n"
+"   -- FIXME: handle erroneous returns (return nil + error msg)\n"
+"   return mlc.new():src_to_function(str, name)\n"
+"end\n"
+"\nfunction M.loadfile(filename)\n"
+"   local f, err_msg = io.open(filename, 'rb')\n"
+"   if not f then return nil, err_msg end\n"
+"   local success, src = pcall( f.read, f, '*a')\n"
+"   pcall(f.close, f)\n"
+"   if success then return M.loadstring (src, '@'..filename)\n"
+"   else return nil, src end\n"
+"end\n"
+"\nfunction M.load(f, name)\n"
+"   local acc = { }\n"
+"   while true do\n"
+"      local x = f()\n"
+"      if not x then break end\n"
+"      assert(type(x)=='string', \"function passed to load() must return strings\")\n"
+"      table.insert(acc, x)\n"
+"   end\n"
+"   return M.loadstring(table.concat(acc))\n"
+"end\n"
+"\nfunction M.dostring(src)\n"
+"   local f, msg = M.loadstring(src)\n"
+"   if not f then error(msg) end\n"
+"   return f()\n"
+"end\n"
+"\nfunction M.dofile(name)\n"
+"   local f, msg = M.loadfile(name)\n"
+"   if not f then error(msg) end\n"
+"   return f()\n"
+"end\n"
+"\n-- Export replacement functions as globals\n"
+"for name, f in pairs(M) do _G[name] = f end\n"
+"\n-- To be done *after* exportation\n"
+"M.lua = original_lua_versions\n"
+"\nreturn M",
true, false);
// End of /metalua/compiler/globals.lua
Lua5_1.provide_file("/metalua/", "treequery.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\nlocal walk = require 'metalua.treequery.walk'\n"
+"\nlocal M = { }\n"
+"-- support for old-style modules\n"
+"treequery = M\n"
+"\n-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"--\n"
+"-- multimap helper mmap: associate a key to a set of values\n"
+"--\n"
+"-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"\nlocal function mmap_add (mmap, node, x)\n"
+"    if node==nil then return false end\n"
+"    local set = mmap[node]\n"
+"    if set then set[x] = true\n"
+"    else mmap[node] = {[x]=true} end\n"
+"end\n"
+"\n-- currently unused, I throw the whole set away\n"
+"local function mmap_remove (mmap, node, x)\n"
+"    local set = mmap[node]\n"
+"    if not set then return false\n"
+"    elseif not set[x] then return false\n"
+"    elseif next(set) then set[x]=nil\n"
+"    else mmap[node] = nil end\n"
+"    return true\n"
+"end\n"
+"\n-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"--\n"
+"-- TreeQuery object.\n"
+"--\n"
+"-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"\nlocal ACTIVE_SCOPE = setmetatable({ }, {__mode=\"k\"})\n"
+"\n-- treequery metatable\n"
+"local Q = { }; Q.__index = Q\n"
+"\n--- treequery constructor\n"
+"--  the resultingg object will allow to filter ans operate on the AST\n"
+"--  @param root the AST to visit\n"
+"--  @return a treequery visitor instance\n"
+"function M.treequery(root)\n"
+"    return setmetatable({\n"
+"        root = root,\n"
+"        unsatisfied = 0,\n"
+"        predicates  = { },\n"
+"        until_up    = { },\n"
+"        from_up     = { },\n"
+"        up_f        = false,\n"
+"        down_f      = false,\n"
+"        filters     = { },\n"
+"    }, Q)\n"
+"end\n"
+"\n-- helper to share the implementations of positional filters\n"
+"local function add_pos_filter(self, position, inverted, inclusive, f, ...)\n"
+"    if type(f)=='string' then f = M.has_tag(f, ...) end\n"
+"    if not inverted then self.unsatisfied += 1 end\n"
+"    local x = {\n"
+"        pred      = f,\n"
+"        position  = position,\n"
+"        satisfied = false,\n"
+"        inverted  = inverted  or false,\n"
+"        inclusive = inclusive or false }\n"
+"    table.insert(self.predicates, x)\n"
+"    return self\n"
+"end\n"
+"\nfunction Q :if_unknown(f)\n"
+"    self.unknown_handler = f or (||nil)\n"
+"    return self\n"
+"end\n"
+"\n-- TODO: offer an API for inclusive pos_filters\n"
+"\n--- select nodes which are after one which satisfies predicate f\n"
+"Q.after     = |self, f, ...| add_pos_filter(self, 'after', false, false, f, ...)\n"
+"--- select nodes which are not after one which satisfies predicate f\n"
+"Q.not_after = |self, f, ...| add_pos_filter(self, 'after', true,  false, f, ...)\n"
+"--- select nodes which are under one which satisfies predicate f\n"
+"Q.under     = |self, f, ...| add_pos_filter(self, 'under', false, false, f, ...)\n"
+"--- select nodes which are not under one which satisfies predicate f\n"
+"Q.not_under = |self, f, ...| add_pos_filter(self, 'under', true,  false, f, ...)\n"
+"\n--- select nodes which satisfy predicate f\n"
+"function Q :filter(f, ...)\n"
+"    if type(f)=='string' then f = M.has_tag(f, ...) end\n"
+"    table.insert(self.filters, f);\n"
+"    return self\n"
+"end\n"
+"\n--- select nodes which satisfy predicate f\n"
+"function Q :filter_not(f, ...)\n"
+"    if type(f)=='string' then f = M.has_tag(f, ...) end\n"
+"    table.insert(self.filters, |...| not f(...))\n"
+"    return self\n"
+"end\n"
+"\n-- private helper: apply filters and execute up/down callbacks when applicable\n"
+"function Q :execute()\n"
+"    local cfg = { }\n"
+"    -- TODO: optimize away not_under & not_after by pruning the tree\n"
+"    function cfg.down(...)\n"
+"        --printf (\"[down]\\t%s\\t%s\", self.unsatisfied, table.tostring((...)))\n"
+"        ACTIVE_SCOPE[...] = cfg.scope\n"
+"        local satisfied = self.unsatisfied==0\n"
+"        for _, x in ipairs(self.predicates) do\n"
+"            if not x.satisfied and x.pred(...) then\n"
+"                x.satisfied = true\n"
+"                local node, parent = ...\n"
+"                local inc = x.inverted and 1 or -1\n"
+"                if x.position=='under' then\n"
+"                    -- satisfied from after we get down this node...\n"
+"                    self.unsatisfied += inc\n"
+"                    -- ...until before we get up this node\n"
+"                    mmap_add(self.until_up, node, x)\n"
+"                elseif x.position=='after' then\n"
+"                    -- satisfied from after we get up this node...\n"
+"                    mmap_add(self.from_up, node, x)\n"
+"                    -- ...until before we get up this node's parent\n"
+"                    mmap_add(self.until_up, parent, x)\n"
+"                elseif x.position=='under_or_after' then\n"
+"                    -- satisfied from after we get down this node...\n"
+"                    self.satisfied += inc\n"
+"                    -- ...until before we get up this node's parent...\n"
+"                    mmap_add(self.until_up, parent, x)\n"
+"                else\n"
+"                    error \"position not understood\"\n"
+"                end -- position\n"
+"                if x.inclusive then satisfied = self.unsatisfied==0 end\n"
+"            end -- predicate passed\n"
+"        end -- for predicates\n"
+"\n        if satisfied then\n"
+"            for _, f in ipairs(self.filters) do\n"
+"                if not f(...) then satisfied=false; break end\n"
+"            end\n"
+"            if satisfied and self.down_f then self.down_f(...) end\n"
+"        end\n"
+"    end\n"
+"\n    function cfg.up(...)\n"
+"        --printf (\"[up]\\t%s\", table.tostring((...)))\n"
+"\n        -- Remove predicates which are due before we go up this node\n"
+"        local preds = self.until_up[...]\n"
+"        if preds then\n"
+"            for x, _ in pairs(preds) do\n"
+"                local inc = x.inverted and -1 or 1\n"
+"                self.unsatisfied += inc\n"
+"                x.satisfied = false\n"
+"            end\n"
+"            self.until_up[...] = nil\n"
+"        end\n"
+"\n        -- Execute the up callback\n"
+"        -- TODO: cache the filter passing result from the down callback\n"
+"        -- TODO: skip if there's no callback\n"
+"        local satisfied = self.unsatisfied==0\n"
+"        if satisfied then\n"
+"            for _, f in ipairs(self.filters) do\n"
+"                if not f(self, ...) then satisfied=false; break end\n"
+"            end\n"
+"            if satisfied and self.up_f then self.up_f(...) end\n"
+"        end\n"
+"\n        -- Set predicate which are due after we go up this node\n"
+"        local preds = self.from_up[...]\n"
+"        if preds then\n"
+"            for p, _ in pairs(preds) do\n"
+"                local inc = p.inverted and 1 or -1\n"
+"                self.unsatisfied += inc\n"
+"            end\n"
+"            self.from_up[...] = nil\n"
+"        end\n"
+"        ACTIVE_SCOPE[...] = nil\n"
+"    end\n"
+"\n    function cfg.binder(id_node, ...)\n"
+"        --printf(\" >>> Binder called on %s, %s\", table.tostring(id_node),\n"
+"        --      table.tostring{...}:sub(2,-2))\n"
+"        cfg.down(id_node, ...)\n"
+"        cfg.up(id_node, ...)\n"
+"        --printf(\"down/up on binder done\")\n"
+"    end\n"
+"\n    cfg.unknown = self.unknown_handler\n"
+"\n    --function cfg.occurrence (binder, occ)\n"
+"    --   if binder then OCC2BIND[occ] = binder[1] end\n"
+"       --printf(\" >>> %s is an occurrence of %s\", occ[1], table.tostring(binder and binder[2]))\n"
+"    --end\n"
+"\n    --function cfg.binder(...) cfg.down(...); cfg.up(...) end\n"
+"    return walk.guess(cfg, self.root)\n"
+"end\n"
+"\n--- Execute a function on each selected node\n"
+"--  @down: function executed when we go down a node, i.e. before its children\n"
+"--         have been examined.\n"
+"--  @up: function executed when we go up a node, i.e. after its children\n"
+"--       have been examined.\n"
+"function Q :foreach(down, up)\n"
+"    if not up and not down then\n"
+"        error \"iterator missing\"\n"
+"    end\n"
+"    self.up_f = up\n"
+"    self.down_f = down\n"
+"    return self :execute()\n"
+"end\n"
+"\n--- Return the list of nodes selected by a given treequery.\n"
+"function Q :list()\n"
+"    local acc = { }\n"
+"    self :foreach(|x| table.insert(acc, x))\n"
+"    return acc\n"
+"end\n"
+"\n--- Return the first matching element\n"
+"--  TODO:  dirty hack, to implement properly with a 'break' return.\n"
+"--  Also, it won't behave correctly if a predicate causes an error,\n"
+"--  or if coroutines are involved.\n"
+"function Q :first()\n"
+"   local result = { }\n"
+"   local function f(...) result = {...}; error() end\n"
+"   pcall(|| self :foreach(f))\n"
+"   return unpack(result)\n"
+"end\n"
+"\n--- Pretty printer for queries\n"
+"function Q :__tostring() return \"<treequery>\" end\n"
+"\n-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"--\n"
+"-- Predicates.\n"
+"--\n"
+"-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"\n--- Return a predicate which is true if the tested node's tag is among the\n"
+"--  one listed as arguments\n"
+"-- @param ... a sequence of tag names\n"
+"function M.has_tag(...)\n"
+"    local args = {...}\n"
+"    if #args==1 then\n"
+"        local tag = ...\n"
+"        return (|node| node.tag==tag)\n"
+"        --return function(self, node) printf(\"node %s has_tag %s?\", table.tostring(node), tag); return node.tag==tag end\n"
+"    else\n"
+"        local tags = { }\n"
+"        for _, tag in ipairs(args) do tags[tag]=true end\n"
+"        return function(node)\n"
+"            local node_tag = node.tag\n"
+"            return node_tag and tags[node_tag]\n"
+"        end\n"
+"    end\n"
+"end\n"
+"\n--- Predicate to test whether a node represents an expression.\n"
+"M.is_expr = M.has_tag('Nil', 'Dots', 'True', 'False', 'Number','String',\n"
+"                  'Function', 'Table', 'Op', 'Paren', 'Call', 'Invoke',\n"
+"                  'Id', 'Index')\n"
+"\n-- helper for is_stat\n"
+"local STAT_TAGS = { Do=1, Set=1, While=1, Repeat=1, If=1, Fornum=1,\n"
+"                    Forin=1, Local=1, Localrec=1, Return=1, Break=1 }\n"
+"\n--- Predicate to test whether a node represents a statement.\n"
+"--  It is context-aware, i.e. it recognizes `Call and `Invoke nodes\n"
+"--  used in a statement context as such.\n"
+"function M.is_stat(node, parent)\n"
+"    local tag = node.tag\n"
+"    if not tag then return false\n"
+"    elseif STAT_TAGS[tag] then return true\n"
+"    elseif tag=='Call' or tag=='Invoke' then return parent.tag==nil\n"
+"    else return false end\n"
+"end\n"
+"\n--- Predicate to test whether a node represents a statements block.\n"
+"function M.is_block(node) return node.tag==nil end\n"
+"\n-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"--\n"
+"-- Variables and scopes.\n"
+"--\n"
+"-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"\nlocal BINDER_PARENT_TAG = {\n"
+"   Local=true, Localrec=true, Forin=true, Function=true }\n"
+"\n--- Test whether a node is a binder. This is local predicate, although it\n"
+"--  might need to inspect the parent node.\n"
+"function M.is_binder(node, parent)\n"
+"   --printf('is_binder(%s, %s)', table.tostring(node), table.tostring(parent))\n"
+"   if node.tag ~= 'Id' or not parent then return false end\n"
+"   if parent.tag=='Fornum' then  return parent[1]==node end\n"
+"   if not BINDER_PARENT_TAG[parent.tag] then return false end\n"
+"   for _, binder in ipairs(parent[1]) do\n"
+"       if binder==node then return true end\n"
+"   end\n"
+"   return false\n"
+"end\n"
+"\n--- Retrieve the binder associated to an occurrence within root.\n"
+"--  @param occurrence an Id node representing an occurrence in `root`.\n"
+"--  @param root the tree in which `node` and its binder occur.\n"
+"--  @return the binder node, and its ancestors up to root if found.\n"
+"--  @return nil if node is global (or not an occurrence) in `root`.\n"
+"function M.binder(occurrence, root)\n"
+"    local cfg, id_name, result = { }, occurrence[1], { }\n"
+"    function cfg.occurrence(id)\n"
+"        if id == occurrence then result = cfg.scope :get(id_name) end\n"
+"        -- TODO: break the walker\n"
+"    end\n"
+"    walk.guess(cfg, root)\n"
+"    return unpack(result)\n"
+"end\n"
+"\n--- Predicate to filter occurrences of a given binder.\n"
+"--  Warning: it relies on internal scope book-keeping,\n"
+"--  and for this reason, it only works as query method argument.\n"
+"--  It won't work outside of a query.\n"
+"--  @param binder the binder whose occurrences must be kept by predicate\n"
+"--  @return a predicate\n"
+"\n-- function M.is_occurrence_of(binder)\n"
+"--     return function(node, ...)\n"
+"--         if node.tag ~= 'Id' then return nil end\n"
+"--         if M.is_binder(node, ...) then return nil end\n"
+"--         local scope = ACTIVE_SCOPE[node]\n"
+"--         if not scope then return nil end\n"
+"--         local result = scope :get (node[1]) or { }\n"
+"--         if result[1] ~= binder then return nil end\n"
+"--         return unpack(result)\n"
+"--     end\n"
+"-- end\n"
+"\nfunction M.is_occurrence_of(binder)\n"
+"    return function(node, ...)\n"
+"        local b = M.get_binder(node)\n"
+"        return b and b==binder\n"
+"    end\n"
+"end\n"
+"\nfunction M.get_binder(occurrence, ...)\n"
+"    if occurrence.tag ~= 'Id' then return nil end\n"
+"    if M.is_binder(occurrence, ...) then return nil end\n"
+"    local scope = ACTIVE_SCOPE[occurrence]\n"
+"    local binder_hierarchy = scope :get(occurrence[1])\n"
+"    return unpack (binder_hierarchy or { })\n"
+"end\n"
+"\n--- Transform a predicate on a node into a predicate on this node's\n"
+"--  parent. For instance if p tests whether a node has property P,\n"
+"--  then parent(p) tests whether this node's parent has property P.\n"
+"--  The ancestor level is precised with n, with 1 being the node itself,\n"
+"--  2 its parent, 3 its grand-parent etc.\n"
+"--  @param[optional] n the parent to examine, default=2\n"
+"--  @param pred the predicate to transform\n"
+"--  @return a predicate\n"
+"function M.parent(n, pred, ...)\n"
+"    if type(n)~='number' then n, pred = 2, n end\n"
+"    if type(pred)=='string' then pred = M.has_tag(pred, ...) end\n"
+"    return function(self, ...)\n"
+"        return select(n, ...) and pred(self, select(n, ...))\n"
+"    end\n"
+"end\n"
+"\n--- Transform a predicate on a node into a predicate on this node's\n"
+"--  n-th child.\n"
+"--  @param n the child's index number\n"
+"--  @param pred the predicate to transform\n"
+"--  @return a predicate\n"
+"function M.child(n, pred)\n"
+"    return function(node, ...)\n"
+"        local child = node[n]\n"
+"        return child and pred(child, node, ...)\n"
+"    end\n"
+"end\n"
+"\n--- Predicate to test the position of a node in its parent.\n"
+"--  The predicate succeeds if the node is the n-th child of its parent,\n"
+"--  and a <= n <= b.\n"
+"--  nth(a) is equivalent to nth(a, a).\n"
+"--  Negative indices are admitted, and count from the last child,\n"
+"--  as done for instance by string.sub().\n"
+"--\n"
+"--  TODO: This is wrong, this tests the table relationship rather than the\n"
+"--  AST node relationship.\n"
+"--  Must build a getindex helper, based on pattern matching, then build\n"
+"--  the predicate around it.\n"
+"--\n"
+"--  @param a lower bound\n"
+"--  @param a upper bound\n"
+"--  @return a predicate\n"
+"function M.is_nth(a, b)\n"
+"    b = b or a\n"
+"    return function(self, node, parent)\n"
+"        if not parent then return false end\n"
+"        local nchildren = #parent\n"
+"        local a = a<=0 and nchildren+a+1 or a\n"
+"        if a>nchildren then return false end\n"
+"        local b = b<=0 and nchildren+b+1 or b>nchildren and nchildren or b\n"
+"        for i=a,b do if parent[i]==node then return true end end\n"
+"        return false\n"
+"    end\n"
+"end\n"
+"\n\n"
+"-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"--\n"
+"-- Comments parsing.\n"
+"--\n"
+"-- -----------------------------------------------------------------------------\n"
+"-- -----------------------------------------------------------------------------\n"
+"\nlocal comment_extractor = |which_side| function (node)\n"
+"    local x = node.lineinfo\n"
+"    x = x and x[which_side]\n"
+"    x = x and x.comments\n"
+"    if not x then return nil end\n"
+"    local lines = { }\n"
+"    for _, record in ipairs(x) do\n"
+"        table.insert(lines, record[1])\n"
+"    end\n"
+"    return table.concat(lines, '\\n"
+"')\n"
+"end\n"
+"\nM.comment_prefix = comment_extractor 'first'\n"
+"M.comment_suffix = comment_extractor 'last'\n"
+"\n\n"
+"--- Shortcut for the query constructor\n"
+"function M :__call(...) return self.treequery(...) end\n"
+"setmetatable(M, M)\n"
+"\nreturn M\n",
true, false);
// End of /metalua/treequery.mlua
Lua5_1.provide_file("/metalua/extension/", "xmatch.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\nrequire 'metalua.extension.match'\n"
+"\nmodule ('spmatch', package.seeall)\n"
+"\nrequire 'metalua.walk.id'\n"
+"\n----------------------------------------------------------------------\n"
+"-- Back-end for statements\n"
+"-- \"match function ...\" and \"local match function...\".\n"
+"-- Tag must be either \"Localrec\" or \"Set\".\n"
+"----------------------------------------------------------------------\n"
+"named_match_function_builder = |tag| function (x)\n"
+"   local func_name, _, cases = unpack(x)\n"
+"   local arity = #cases[1][1][1]\n"
+"   if arity==0 then\n"
+"      error \"There must be at least 1 case in match function\"\n"
+"   end\n"
+"   local args = { }\n"
+"   for i=1, arity do args[i] = mlp.gensym(\"arg.\"..i) end\n"
+"   local body = match_builder{args, cases}\n"
+"   return { tag=tag, {func_name}, { `Function{ args, {body} } } }\n"
+"end\n"
+"\n-- Get rid of the former parser, it will be blended in a multiseq:\n"
+"mlp.stat:del 'match'\n"
+"\n----------------------------------------------------------------------\n"
+"-- \"match function\", \"match ... with\"\n"
+"----------------------------------------------------------------------\n"
+"mlp.stat:add{ 'match',\n"
+"   gg.multisequence{\n"
+"\n      ----------------------------------------------------------------\n"
+"      -- Shortcut for declaration of functions containing only a match:\n"
+"      -- \"function f($1) match $1 with $2 end end\" can be written:\n"
+"      -- \"match function f $2 end\"\n"
+"      ----------------------------------------------------------------\n"
+"      { 'function', mlp.expr, gg.optkeyword '|',\n"
+"         match_cases_list_parser, 'end',\n"
+"         builder = named_match_function_builder 'Set' },\n"
+"\n      ----------------------------------------------------------------\n"
+"      -- Reintroduce the original match statement:\n"
+"      ----------------------------------------------------------------\n"
+"      default = gg.sequence{\n"
+"         mlp.expr_list, 'with', gg.optkeyword '|',\n"
+"         match_cases_list_parser, 'end',\n"
+"         builder = |x| match_builder{ x[1], x[3] } } } }\n"
+"\n----------------------------------------------------------------------\n"
+"-- Shortcut: \"local match function f $cases end\" translates to:\n"
+"-- \"local function f($args) match $args with $cases end end\"\n"
+"----------------------------------------------------------------------\n"
+"mlp.stat:get'local'[2]:add{\n"
+"   'match', 'function', mlp.expr, gg.optkeyword '|',\n"
+"   match_cases_list_parser, 'end',\n"
+"   builder = named_match_function_builder 'Localrec' }\n"
+"\n----------------------------------------------------------------------\n"
+"-- \"match...with\" expressions and \"match function...\"\n"
+"----------------------------------------------------------------------\n"
+"mlp.expr:add{ 'match', builder = |x| x[1], gg.multisequence{\n"
+"\n      ----------------------------------------------------------------\n"
+"      -- Anonymous match functions:\n"
+"      -- \"function ($1) match $1 with $2 end end\" can be written:\n"
+"      -- \"match function $2 end\"\n"
+"      ----------------------------------------------------------------\n"
+"      { 'function', gg.optkeyword '|',\n"
+"         match_cases_list_parser,\n"
+"         'end',\n"
+"         builder = function(x)\n"
+"            local _, cases = unpack(x)\n"
+"            local v        = mlp.gensym()\n"
+"            local body     = match_builder{v, cases}\n"
+"            return `Function{ {v}, {body} }\n"
+"         end },\n"
+"\n      ----------------------------------------------------------------\n"
+"      -- match expressions: you can put a match where an expression\n"
+"      -- is expected. The case bodies are then expected to be\n"
+"      -- expressions, not blocks.\n"
+"      ----------------------------------------------------------------\n"
+"      default = gg.sequence{\n"
+"         mlp.expr_list, 'with', gg.optkeyword '|',\n"
+"         gg.list{  name = \"match cases list\",\n"
+"            gg.sequence{ name = \"match expr case\",\n"
+"               gg.list{ name  = \"match expr case patterns list\",\n"
+"                  primary     = mlp.expr_list,\n"
+"                  separators  = \"|\",\n"
+"                  terminators = { \"->\", \"if\" } },\n"
+"               gg.onkeyword{ \"if\", mlp.expr, consume = true },\n"
+"               \"->\",\n"
+"               mlp.expr }, -- Notice: expression, not block!\n"
+"            separators  = \"|\" },\n"
+"         -- Notice: no \"end\" keyword!\n"
+"         builder = function (x)\n"
+"            local tested_term_seq, _, cases = unpack(x)\n"
+"            local v = mlp.gensym 'match_expr'\n"
+"            -- Replace expressions with blocks\n"
+"            for _, case in ipairs (cases) do\n"
+"               local body = case[3]\n"
+"               case[3] = { `Set{ {v}, {body} } }\n"
+"            end\n"
+"            local m = match_builder { tested_term_seq, cases }\n"
+"            return `Stat{ { `Local{{v}}; m }, v }\n"
+"         end } } }\n"
+"\nfunction bind (x)\n"
+"   local patterns, values = unpack(x)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Generate pattern code: \"bind vars = vals\" translates to:\n"
+"   -- do\n"
+"   --   pattern matching code, goto 'fail' on mismatch\n"
+"   --   goto 'success'\n"
+"   --   label 'fail': error \"...\"\n"
+"   --   label success\n"
+"   -- end\n"
+"   -- vars is the set of variables used by the pattern\n"
+"   -------------------------------------------------------------------\n"
+"   local code, vars do\n"
+"      local match_cfg = {\n"
+"         on_failure = mlp.gensym 'mismatch' [1],\n"
+"         locals = { },\n"
+"         code = { } }\n"
+"      pattern_seq_builder(patterns, values, match_cfg)\n"
+"      local on_success = mlp.gensym 'on_success' [1]\n"
+"      code = {\n"
+"         match_cfg.code;\n"
+"         `Goto{ on_success };\n"
+"         `Label{ match_cfg.on_failure };\n"
+"         +{error \"bind error\"};\n"
+"         `Label{ on_success } }\n"
+"      vars = match_cfg.locals\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- variables that actually appear in the pattern:\n"
+"   -------------------------------------------------------------------\n"
+"   local vars_in_pattern do\n"
+"      vars_in_pattern = { }\n"
+"      local walk_cfg = { id = { } }\n"
+"      function walk_cfg.id.free(v) vars_in_pattern[v[1]]=true end\n"
+"      walk_id.expr_list(walk_cfg, patterns)\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- temp variables that are generated for destructuring,\n"
+"   -- but aren't explicitly typed by the user. These must be made\n"
+"   -- local.\n"
+"   -------------------------------------------------------------------\n"
+"   local vars_not_in_pattern do\n"
+"      vars_not_in_pattern = { }\n"
+"      for k, _ in pairs(vars) do\n"
+"         if not vars_in_pattern[k] then\n"
+"            vars_not_in_pattern[k] = true\n"
+"         end\n"
+"      end\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Declare the temp variables as local to the statement.\n"
+"   -------------------------------------------------------------------\n"
+"   if next(vars_not_in_pattern) then\n"
+"      local loc = { }\n"
+"      for k, _ in pairs(vars_not_in_pattern) do\n"
+"         table.insert (loc, `Id{k})\n"
+"      end\n"
+"      table.insert (code, 1, `Local{ loc, { } })\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Transform the set of pattern variable names into a list of `Id{}\n"
+"   -------------------------------------------------------------------\n"
+"   local decl_list do\n"
+"      decl_list = { }\n"
+"      for k, _ in pairs(vars_in_pattern) do\n"
+"         table.insert (decl_list, `Id{k})\n"
+"      end\n"
+"   end\n"
+"\n   return code, decl_list\n"
+"end\n"
+"\nfunction local_bind(x)\n"
+"   local code, vars = bind (x)\n"
+"   return { `Local{ vars, { } }; code }\n"
+"end\n"
+"\nfunction non_local_bind(x)\n"
+"   local code, _ = bind (x)\n"
+"   code.tag = 'Do'\n"
+"   return code\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Syntax front-end\n"
+"----------------------------------------------------------------------\n"
+"mlp.lexer:add 'bind'\n"
+"\n----------------------------------------------------------------------\n"
+"-- bind patterns = vars\n"
+"----------------------------------------------------------------------\n"
+"mlp.stat:add{ 'bind', mlp.expr_list, '=', mlp.expr_list,\n"
+"   builder = non_local_bind }\n"
+"\n----------------------------------------------------------------------\n"
+"-- local bind patterns = vars\n"
+"-- Some monkey-patching of \"local ...\" must take place\n"
+"----------------------------------------------------------------------\n"
+"mlp.stat:get'local'[2]:add{ 'bind', mlp.expr_list, '=', mlp.expr_list,\n"
+"   builder = local_bind }\n",
true, false);
// End of /metalua/extension/xmatch.mlua
Lua5_1.provide_file("/metalua/extension/", "comprehension.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"--\n"
+"-- This extension implements list comprehensions, similar to Haskell and\n"
+"-- Python syntax, to easily describe lists.\n"
+"--\n"
+"-- * x[a ... b] is the list { x[a], x[a+1], ..., x[b] }\n"
+"-- * { f()..., b } contains all the elements returned by f(), then b\n"
+"--   (allows to expand list fields other than the last one)\n"
+"-- * list comprehensions a la python, with \"for\" and \"if\" suffixes:\n"
+"--   {i+10*j for i=1,3 for j=1,3 if i~=j} is { 21, 31, 12, 32, 13, 23 }\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-{ extension (\"match\", ...) }\n"
+"\nlocal SUPPORT_IMPROVED_LOOPS   = true\n"
+"local SUPPORT_IMPROVED_INDEXES = false -- depends on deprecated table.isub\n"
+"local SUPPORT_CONTINUE         = true\n"
+"local SUPPORT_COMP_LISTS       = true\n"
+"\nassert (SUPPORT_IMPROVED_LOOPS or not SUPPORT_CONTINUE,\n"
+"        \"Can't support 'continue' without improved loop headers\")\n"
+"\nlocal gg  = require 'metalua.grammar.generator'\n"
+"local Q   = require 'metalua.treequery'\n"
+"\nlocal function dots_list_suffix_builder (x) return `DotsSuffix{ x } end\n"
+"\nlocal function for_list_suffix_builder (list_element, suffix)\n"
+"    local new_header = suffix[1]\n"
+"    match list_element with\n"
+"    | `Comp{ _, acc } -> table.insert (acc, new_header); return list_element\n"
+"    |  _ -> return `Comp{ list_element, { new_header } }\n"
+"    end\n"
+"end\n"
+"\nlocal function if_list_suffix_builder (list_element, suffix)\n"
+"    local new_header = `If{ suffix[1] }\n"
+"    match list_element with\n"
+"    | `Comp{ _, acc } -> table.insert (acc, new_header); return list_element\n"
+"    |  _ -> return `Comp{ list_element, { new_header } }\n"
+"    end\n"
+"end\n"
+"\n-- Builds a statement from a table element, which adds this element to\n"
+"-- a table `t`, potentially thanks to an alias `tinsert` to\n"
+"-- `table.insert`.\n"
+"-- @param core the part around which the loops are built.\n"
+"--   either `DotsSuffix{expr}, `Pair{ expr } or a plain expression\n"
+"-- @param list comprehension suffixes, in the order in which they appear\n"
+"--   either `Forin{ ... } or `Fornum{ ...} or `If{ ... }. In each case,\n"
+"--   it misses a last child node as its body.\n"
+"-- @param t a variable containing the table to fill\n"
+"-- @param tinsert a variable containing `table.insert`.\n"
+"--\n"
+"-- @return fill a statement which fills empty table `t` with the denoted element\n"
+"local function comp_list_builder(core, list, t, tinsert)\n"
+"    local filler\n"
+"    -- 1 - Build the loop's core: if it has suffix \"...\", every elements of the\n"
+"    --     multi-return must be inserted, hence the extra [for] loop.\n"
+"    match core with\n"
+"    | `DotsSuffix{ element } ->\n"
+"        local x = gg.gensym()\n"
+"        filler = +{stat: for _, -{x} in pairs{ -{element} } do (-{tinsert})(-{t}, -{x}) end }\n"
+"    | `Pair{ key, value } ->\n"
+"        --filler = +{ -{t}[-{key}] = -{value} }\n"
+"        filler = `Set{ { `Index{ t, key } }, { value } }\n"
+"    |  _ -> filler = +{ (-{tinsert})(-{t}, -{core}) }\n"
+"    end\n"
+"\n    -- 2 - Stack the `if` and `for` control structures, from outside to inside.\n"
+"    --     This is done in a destructive way for the elements of [list].\n"
+"    for i = #list, 1, -1 do\n"
+"        table.insert (list[i], {filler})\n"
+"        filler = list[i]\n"
+"    end\n"
+"\n    return filler\n"
+"end\n"
+"\nlocal function table_content_builder (list)\n"
+"    local special = false -- Does the table need a special builder?\n"
+"    for _, element in ipairs(list) do\n"
+"        local etag = element.tag\n"
+"        if etag=='Comp' or etag=='DotsSuffix' then special=true; break end\n"
+"    end\n"
+"    if not special then list.tag='Table'; return list end\n"
+"\n    local t, tinsert = gg.gensym 'table', gg.gensym 'table_insert'\n"
+"    local filler_block = { +{stat: local -{t}, -{tinsert} = { }, table.insert } }\n"
+"    for _, element in ipairs(list) do\n"
+"        local filler\n"
+"        match element with\n"
+"        | `Comp{ core, comp } -> filler = comp_list_builder(core, comp, t, tinsert)\n"
+"        | _ -> filler = comp_list_builder(element, { }, t, tinsert)\n"
+"        end\n"
+"        table.insert(filler_block, filler)\n"
+"    end\n"
+"    return `Stat{ filler_block, t }\n"
+"end\n"
+"\n\n"
+"--------------------------------------------------------------------------------\n"
+"-- Back-end for improved index operator.\n"
+"local function index_builder(a, suffix)\n"
+"   match suffix[1] with\n"
+"   -- Single index, no range: keep the native semantics\n"
+"   | { { e, false } } -> return `Index{ a, e }\n"
+"   -- Either a range, or multiple indexes, or both\n"
+"   | ranges ->\n"
+"      local r = `Call{ +{table.isub}, a }\n"
+"      local function acc (x,y) table.insert (r,x); table.insert (r,y) end\n"
+"      for _, seq in ipairs (ranges) do\n"
+"         match seq with\n"
+"         | { e, false } -> acc(e,e)\n"
+"         | { e, f }     -> acc(e,f)\n"
+"         end\n"
+"      end\n"
+"      return r\n"
+"   end\n"
+"end\n"
+"\n-------------------------------------------------------------------\n"
+"-- Find continue statements in a loop body, change them into goto\n"
+"-- end-of-body.\n"
+"local function transform_continue_statements(body)\n"
+"   local continue_statements = Q(body)\n"
+"       :if_unknown() -- tolerate unknown 'Continue' statements\n"
+"       :not_under ('Forin', 'Fornum', 'While', 'Repeat')\n"
+"       :filter ('Continue')\n"
+"       :list()\n"
+"   if next(continue_statements) then\n"
+"       local continue_label = gg.gensym 'continue' [1]\n"
+"       table.insert(body, `Label{ continue_label })\n"
+"       for _, statement in ipairs(continue_statements) do\n"
+"           statement.tag = 'Goto'\n"
+"           statement[1] = continue_label\n"
+"       end\n"
+"       return true\n"
+"   else return false end\n"
+"end\n"
+"\n-------------------------------------------------------------------------------\n"
+"-- Back-end for loops with a multi-element header\n"
+"local function loop_builder(x)\n"
+"   local first, elements, body = unpack(x)\n"
+"\n   -- Change continue statements into gotos.\n"
+"   if SUPPORT_CONTINUE then transform_continue_statements(body) end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- If it's a regular loop, don't bloat the code\n"
+"   if not next(elements) then\n"
+"      table.insert(first, body)\n"
+"      return first\n"
+"   end\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- There's no reason to treat the first element in a special way\n"
+"   table.insert(elements, 1, first)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Change breaks into gotos that escape all loops at once.\n"
+"   local exit_label = nil\n"
+"   local function break_to_goto(break_node)\n"
+"       if not exit_label then exit_label = gg.gensym 'break' [1] end\n"
+"       break_node = break_node or { }\n"
+"       break_node.tag = 'Goto'\n"
+"       break_node[1] = exit_label\n"
+"       return break_node\n"
+"   end\n"
+"   Q(body)\n"
+"       :not_under('Function', 'Forin', 'Fornum', 'While', 'Repeat')\n"
+"       :filter('Break')\n"
+"       :foreach (break_to_goto)\n"
+"\n   -------------------------------------------------------------------\n"
+"   -- Compile all headers elements, from last to first.\n"
+"   -- invariant: `body` is a block (not a statement)\n"
+"   local result = body\n"
+"   for i = #elements, 1, -1 do\n"
+"      local e = elements[i]\n"
+"      match e with\n"
+"      | `If{ cond }    ->\n"
+"         result = { `If{ cond, result } }\n"
+"      | `Until{ cond } ->\n"
+"         result = +{block: if -{cond} then -{break_to_goto()} else -{result} end }\n"
+"      | `While{ cond } ->\n"
+"         if i==1 then result = { `While{ cond, result } } -- top-level while\n"
+"         else result = +{block: if -{cond} then -{result} else -{break_to_goto()} end } end\n"
+"      | `Forin{ ... } | `Fornum{ ... } ->\n"
+"         table.insert (e, result); result={e}\n"
+"      | _-> require'metalua.pprint'.printf(\"Bad loop header element %s\", e)\n"
+"      end\n"
+"   end\n"
+"\n\n"
+"   -------------------------------------------------------------------\n"
+"   -- If some breaks had to be changed into gotos, insert the label\n"
+"   if exit_label then result = { result, `Label{ exit_label } } end\n"
+"\n   return result\n"
+"end\n"
+"\n\n"
+"--------------------------------------------------------------------------------\n"
+"-- Improved \"[...]\" index operator:\n"
+"--  * support for multi-indexes (\"foo[bar, gnat]\")\n"
+"--  * support for ranges (\"foo[bar ... gnat]\")\n"
+"--------------------------------------------------------------------------------\n"
+"local function extend(M)\n"
+"\n    local _M = gg.future(M)\n"
+"\n    if SUPPORT_COMP_LISTS then\n"
+"        -- support for \"for\" / \"if\" comprehension suffixes in literal tables\n"
+"        local original_table_element = M.table.element\n"
+"        M.table.element = gg.expr{ name=\"table cell\",\n"
+"                                   primary = original_table_element,\n"
+"                                   suffix  = { name=\"table cell suffix\",\n"
+"                                               { \"...\",                builder = dots_list_suffix_builder },\n"
+"                                               { \"for\", _M.for_header, builder = for_list_suffix_builder  },\n"
+"                                               { \"if\",  _M.expr,       builder = if_list_suffix_builder   } } }\n"
+"        M.table.content.builder = table_content_builder\n"
+"    end\n"
+"\n    if SUPPORT_IMPROVED_INDEXES then\n"
+"        -- Support for ranges and multiple indices in bracket suffixes\n"
+"        M.expr.suffix:del '['\n"
+"        M.expr.suffix:add{ name=\"table index/range\",\n"
+"                           \"[\", gg.list{\n"
+"                               gg.sequence { _M.expr, gg.onkeyword{ \"...\", _M.expr } } ,\n"
+"                               separators = { \",\", \";\" } },\n"
+"                           \"]\", builder = index_builder }\n"
+"    end\n"
+"\n    if SUPPORT_IMPROVED_LOOPS then\n"
+"        local original_for_header = M.for_header\n"
+"        M.stat :del  'for'\n"
+"        M.stat :del  'while'\n"
+"\n        M.loop_suffix = gg.multisequence{\n"
+"            { 'while',  _M.expr, builder = |x| `Until{ `Op{ 'not', x[1] } } },\n"
+"            { 'until',  _M.expr, builder = |x| `Until{ x[1] } },\n"
+"            { 'if',     _M.expr, builder = |x| `If{ x[1] } },\n"
+"            { 'for',    original_for_header, builder = |x| x[1] } }\n"
+"\n        M.loop_suffix_list = gg.list{ _M.loop_suffix, terminators='do' }\n"
+"\n        M.stat :add{\n"
+"            'for', original_for_header, _M.loop_suffix_list, 'do', _M.block, 'end',\n"
+"            builder = loop_builder }\n"
+"\n        M.stat :add{\n"
+"            'while', _M.expr, _M.loop_suffix_list, 'do', _M.block, 'end',\n"
+"            builder = |x| loop_builder{ `While{x[1]}, x[2], x[3] } }\n"
+"    end\n"
+"\n    if SUPPORT_CONTINUE then\n"
+"        M.lexer :add 'continue'\n"
+"        M.stat :add{ 'continue', builder='Continue' }\n"
+"    end\n"
+"end\n"
+"\nreturn extend\n",
true, false);
// End of /metalua/extension/comprehension.mlua
Lua5_1.provide_file("/metalua/extension/", "match.mlua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-------------------------------------------------------------------------------\n"
+"--\n"
+"-- Glossary:\n"
+"--\n"
+"-- * term_seq: the tested stuff, a sequence of terms\n"
+"-- * pattern_element: might match one term of a term seq. Represented\n"
+"--   as expression ASTs.\n"
+"-- * pattern_seq: might match a term_seq\n"
+"-- * pattern_group: several pattern seqs, one of them might match\n"
+"--                  the term seq.\n"
+"-- * case: pattern_group * guard option * block\n"
+"-- * match_statement: tested term_seq * case list\n"
+"--\n"
+"-- Hence a complete match statement is a:\n"
+"--\n"
+"-- { list(expr),  list{ list(list(expr)), expr or false, block } }\n"
+"--\n"
+"-- Implementation hints\n"
+"-- ====================\n"
+"--\n"
+"-- The implementation is made as modular as possible, so that parts\n"
+"-- can be reused in other extensions. The priviledged way to share\n"
+"-- contextual information across functions is through the 'cfg' table\n"
+"-- argument. Its fields include:\n"
+"--\n"
+"-- * code: code generated from pattern. A pattern_(element|seq|group)\n"
+"--   is compiled as a sequence of instructions which will jump to\n"
+"--   label [cfg.on_failure] if the tested term doesn't match.\n"
+"--\n"
+"-- * on_failure: name of the label where the code will jump if the\n"
+"--   pattern doesn't match\n"
+"--\n"
+"-- * locals: names of local variables used by the pattern. This\n"
+"--   includes bound variables, and temporary variables used to\n"
+"--   destructure tables. Names are stored as keys of the table,\n"
+"--   values are meaningless.\n"
+"--\n"
+"-- * after_success: label where the code must jump after a pattern\n"
+"--   succeeded to capture a term, and the guard suceeded if there is\n"
+"--   any, and the conditional block has run.\n"
+"--\n"
+"-- * ntmp: number of temporary variables used to destructurate table\n"
+"--   in the current case.\n"
+"--\n"
+"-- Code generation is performed by acc_xxx() functions, which accumulate\n"
+"-- code in cfg.code:\n"
+"--\n"
+"-- * acc_test(test, cfg) will generate a jump to cfg.on_failure\n"
+"--   *when the test returns TRUE*\n"
+"--\n"
+"-- * acc_stat accumulates a statement\n"
+"--\n"
+"-- * acc_assign accumulate an assignment statement, and makes sure that\n"
+"--   the LHS variable the registered as local in cfg.locals.\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-- TODO: hygiene wrt type()\n"
+"-- TODO: cfg.ntmp isn't reset as often as it could. I'm not even sure\n"
+"--       the corresponding locals are declared.\n"
+"\n\n"
+"local gg  = require 'metalua.grammar.generator'\n"
+"local pp  = require 'metalua.pprint'\n"
+"\n----------------------------------------------------------------------\n"
+"-- This would have been best done through library 'metalua.walk',\n"
+"-- but walk depends on match, so we have to break the dependency.\n"
+"-- It replaces all instances of `...' in `ast' with `term', unless\n"
+"-- it appears in a function.\n"
+"----------------------------------------------------------------------\n"
+"local function replace_dots (ast, term)\n"
+"    local function rec (node)\n"
+"        for i, child in ipairs(node) do\n"
+"            if type(child)~=\"table\" then -- pass\n"
+"            elseif child.tag=='Dots' then\n"
+"                if term=='ambiguous' then\n"
+"                    error (\"You can't use `...' on the right of a match case when it appears \"..\n"
+"                           \"more than once on the left\")\n"
+"                else node[i] = term end\n"
+"            elseif child.tag=='Function' then return nil\n"
+"            else rec(child) end\n"
+"        end\n"
+"    end\n"
+"    return rec(ast)\n"
+"end\n"
+"\nlocal tmpvar_base = gg.gensym 'submatch.' [1]\n"
+"\nlocal function next_tmpvar(cfg)\n"
+"   assert (cfg.ntmp, \"No cfg.ntmp imbrication level in the match compiler\")\n"
+"   cfg.ntmp = cfg.ntmp+1\n"
+"   return `Id{ tmpvar_base .. cfg.ntmp }\n"
+"end\n"
+"\n-- Code accumulators\n"
+"local acc_stat = |x,cfg| table.insert (cfg.code, x)\n"
+"local acc_test = |x,cfg| acc_stat(+{stat: if -{x} then -{`Goto{cfg.on_failure}} end}, cfg)\n"
+"-- lhs :: `Id{ string }\n"
+"-- rhs :: expr\n"
+"local function acc_assign (lhs, rhs, cfg)\n"
+"   assert(lhs.tag=='Id')\n"
+"   cfg.locals[lhs[1]] = true\n"
+"   acc_stat (`Set{ {lhs}, {rhs} }, cfg)\n"
+"end\n"
+"\nlocal literal_tags = { String=1, Number=1, True=1, False=1, Nil=1 }\n"
+"\n-- pattern :: `Id{ string }\n"
+"-- term    :: expr\n"
+"local function id_pattern_element_builder (pattern, term, cfg)\n"
+"   assert (pattern.tag == \"Id\")\n"
+"   if pattern[1] == \"_\" then\n"
+"      -- \"_\" is used as a dummy var ==> no assignment, no == checking\n"
+"      cfg.locals._ = true\n"
+"   elseif cfg.locals[pattern[1]] then\n"
+"      -- This var is already bound ==> test for equality\n"
+"      acc_test (+{ -{term} ~= -{pattern} }, cfg)\n"
+"   else\n"
+"      -- Free var ==> bind it, and remember it for latter linearity checking\n"
+"      acc_assign (pattern, term, cfg)\n"
+"      cfg.locals[pattern[1]] = true\n"
+"   end\n"
+"end\n"
+"\n-- mutually recursive with table_pattern_element_builder\n"
+"local pattern_element_builder\n"
+"\n-- pattern :: pattern and `Table{ }\n"
+"-- term    :: expr\n"
+"local function table_pattern_element_builder (pattern, term, cfg)\n"
+"   local seen_dots, len = false, 0\n"
+"   acc_test (+{ type( -{term} ) ~= \"table\" }, cfg)\n"
+"   for i = 1, #pattern do\n"
+"      local key, sub_pattern\n"
+"      if pattern[i].tag==\"Pair\" then -- Explicit key/value pair\n"
+"         key, sub_pattern = unpack (pattern[i])\n"
+"         assert (literal_tags[key.tag], \"Invalid key\")\n"
+"      else -- Implicit key\n"
+"         len, key, sub_pattern = len+1, `Number{ len+1 }, pattern[i]\n"
+"      end\n"
+"\n      -- '...' can only appear in final position\n"
+"      -- Could be fixed actually...\n"
+"      assert (not seen_dots, \"Wrongly placed `...' \")\n"
+"\n      if sub_pattern.tag == \"Id\" then\n"
+"         -- Optimization: save a useless [ v(n+1)=v(n).key ]\n"
+"         id_pattern_element_builder (sub_pattern, `Index{ term, key }, cfg)\n"
+"         if sub_pattern[1] ~= \"_\" then\n"
+"            acc_test (+{ -{sub_pattern} == nil }, cfg)\n"
+"         end\n"
+"      elseif sub_pattern.tag == \"Dots\" then\n"
+"         -- Remember where the capture is, and thatt arity checking shouldn't occur\n"
+"         seen_dots = true\n"
+"      else\n"
+"         -- Business as usual:\n"
+"         local v2 = next_tmpvar(cfg)\n"
+"         acc_assign (v2, `Index{ term, key }, cfg)\n"
+"         pattern_element_builder (sub_pattern, v2, cfg)\n"
+"         -- TODO: restore ntmp?\n"
+"      end\n"
+"   end\n"
+"   if seen_dots then -- remember how to retrieve `...'\n"
+"      -- FIXME: check, but there might be cases where the variable -{term}\n"
+"      -- will be overridden in contrieved tables.\n"
+"      -- ==> save it now, and clean the setting statement if unused\n"
+"      if cfg.dots_replacement then cfg.dots_replacement = 'ambiguous'\n"
+"      else cfg.dots_replacement = +{ select (-{`Number{len}}, unpack(-{term})) } end\n"
+"   else -- Check arity\n"
+"      acc_test (+{ #-{term} ~= -{`Number{len}} }, cfg)\n"
+"   end\n"
+"end\n"
+"\n-- mutually recursive with pattern_element_builder\n"
+"local eq_pattern_element_builder, regexp_pattern_element_builder\n"
+"\n-- Concatenate code in [cfg.code], that will jump to label\n"
+"-- [cfg.on_failure] if [pattern] doesn't match [term]. [pattern]\n"
+"-- should be an identifier, or at least cheap to compute and\n"
+"-- side-effects free.\n"
+"--\n"
+"-- pattern :: pattern_element\n"
+"-- term    :: expr\n"
+"function pattern_element_builder (pattern, term, cfg)\n"
+"   if literal_tags[pattern.tag] then\n"
+"      acc_test (+{ -{term} ~= -{pattern} }, cfg)\n"
+"   elseif \"Id\" == pattern.tag then\n"
+"      id_pattern_element_builder (pattern, term, cfg)\n"
+"   elseif \"Op\" == pattern.tag and \"div\" == pattern[1] then\n"
+"      regexp_pattern_element_builder (pattern, term, cfg)\n"
+"   elseif \"Op\" == pattern.tag and \"eq\" == pattern[1] then\n"
+"      eq_pattern_element_builder (pattern, term, cfg)\n"
+"   elseif \"Table\" == pattern.tag then\n"
+"      table_pattern_element_builder (pattern, term, cfg)\n"
+"   else\n"
+"      error (\"Invalid pattern at \"..\n"
+"             tostring(pattern.lineinfo)..\n"
+"             \": \"..pp.tostring(pattern, {hide_hash=true}))\n"
+"   end\n"
+"end\n"
+"\nfunction eq_pattern_element_builder (pattern, term, cfg)\n"
+"   local _, pat1, pat2 = unpack (pattern)\n"
+"   local ntmp_save = cfg.ntmp\n"
+"   pattern_element_builder (pat1, term, cfg)\n"
+"   cfg.ntmp = ntmp_save\n"
+"   pattern_element_builder (pat2, term, cfg)\n"
+"end\n"
+"\n-- pattern :: `Op{ 'div', string, list{`Id string} or `Id{ string }}\n"
+"-- term    :: expr\n"
+"local function regexp_pattern_element_builder (pattern, term, cfg)\n"
+"   local op, regexp, sub_pattern = unpack(pattern)\n"
+"\n   -- Sanity checks --\n"
+"   assert (op=='div', \"Don't know what to do with that op in a pattern\")\n"
+"   assert (regexp.tag==\"String\",\n"
+"           \"Left hand side operand for '/' in a pattern must be \"..\n"
+"           \"a literal string representing a regular expression\")\n"
+"   if sub_pattern.tag==\"Table\" then\n"
+"      for _, x in ipairs(sub_pattern) do\n"
+"\t assert (x.tag==\"Id\" or x.tag=='Dots',\n"
+"\t\t \"Right hand side operand for '/' in a pattern must be \"..\n"
+"\t\t \"a list of identifiers\")\n"
+"      end\n"
+"   else\n"
+"      assert (sub_pattern.tag==\"Id\",\n"
+"\t      \"Right hand side operand for '/' in a pattern must be \"..\n"
+"              \"an identifier or a list of identifiers\")\n"
+"   end\n"
+"\n   -- Regexp patterns can only match strings\n"
+"   acc_test (+{ type(-{term}) ~= 'string' }, cfg)\n"
+"   -- put all captures in a list\n"
+"   local capt_list  = +{ { string.strmatch(-{term}, -{regexp}) } }\n"
+"   -- save them in a var_n for recursive decomposition\n"
+"   local v2 = next_tmpvar(cfg)\n"
+"   acc_stat (+{stat: local -{v2} = -{capt_list} }, cfg)\n"
+"   -- was capture successful?\n"
+"   acc_test (+{ not next (-{v2}) }, cfg)\n"
+"   pattern_element_builder (sub_pattern, v2, cfg)\n"
+"end\n"
+"\n\n"
+"-- Jumps to [cfg.on_faliure] if pattern_seq doesn't match\n"
+"-- term_seq.\n"
+"local function pattern_seq_builder (pattern_seq, term_seq, cfg)\n"
+"   if #pattern_seq ~= #term_seq then error (\"Bad seq arity\") end\n"
+"   cfg.locals = { } -- reset bound variables between alternatives\n"
+"   for i=1, #pattern_seq do\n"
+"      cfg.ntmp = 1 -- reset the tmp var generator\n"
+"      pattern_element_builder(pattern_seq[i], term_seq[i], cfg)\n"
+"   end\n"
+"end\n"
+"\n--------------------------------------------------\n"
+"-- for each case i:\n"
+"--   pattern_seq_builder_i:\n"
+"--    * on failure, go to on_failure_i\n"
+"--    * on success, go to on_success\n"
+"--   label on_success:\n"
+"--   block\n"
+"--   goto after_success\n"
+"--   label on_failure_i\n"
+"--------------------------------------------------\n"
+"local function case_builder (case, term_seq, cfg)\n"
+"   local patterns_group, guard, block = unpack(case)\n"
+"   local on_success = gg.gensym 'on_success' [1]\n"
+"   for i = 1, #patterns_group do\n"
+"      local pattern_seq = patterns_group[i]\n"
+"      cfg.on_failure = gg.gensym 'match_fail' [1]\n"
+"      cfg.dots_replacement = false\n"
+"      pattern_seq_builder (pattern_seq, term_seq, cfg)\n"
+"      if i<#patterns_group then\n"
+"         acc_stat (`Goto{on_success}, cfg)\n"
+"         acc_stat (`Label{cfg.on_failure}, cfg)\n"
+"      end\n"
+"   end\n"
+"   acc_stat (`Label{on_success}, cfg)\n"
+"   if guard then acc_test (+{not -{guard}}, cfg) end\n"
+"   if cfg.dots_replacement then\n"
+"      replace_dots (block, cfg.dots_replacement)\n"
+"   end\n"
+"   block.tag = 'Do'\n"
+"   acc_stat (block, cfg)\n"
+"   acc_stat (`Goto{cfg.after_success}, cfg)\n"
+"   acc_stat (`Label{cfg.on_failure}, cfg)\n"
+"end\n"
+"\nlocal function match_builder (x)\n"
+"   local term_seq, cases = unpack(x)\n"
+"   local cfg = {\n"
+"      code          = `Do{ },\n"
+"      after_success = gg.gensym \"_after_success\" }\n"
+"\n\n"
+"   -- Some sharing issues occur when modifying term_seq,\n"
+"   -- so it's replaced by a copy new_term_seq.\n"
+"   -- TODO: clean that up, and re-suppress the useless copies\n"
+"   -- (cf. remarks about capture bug below).\n"
+"   local new_term_seq = { }\n"
+"\n   local match_locals\n"
+"\n   -- Make sure that all tested terms are variables or literals\n"
+"   for i=1, #term_seq do\n"
+"      local t = term_seq[i]\n"
+"      -- Capture problem: the following would compile wrongly:\n"
+"      --    `match x with x -> end'\n"
+"      -- Temporary workaround: suppress the condition, so that\n"
+"      -- all external variables are copied into unique names.\n"
+"      --if t.tag ~= 'Id' and not literal_tags[t.tag] then\n"
+"         local v = gg.gensym 'v'\n"
+"         if not match_locals then match_locals = `Local{ {v}, {t} } else\n"
+"            table.insert(match_locals[1], v)\n"
+"            table.insert(match_locals[2], t)\n"
+"         end\n"
+"         new_term_seq[i] = v\n"
+"      --end\n"
+"   end\n"
+"   term_seq = new_term_seq\n"
+"\n   if match_locals then acc_stat(match_locals, cfg) end\n"
+"\n   for i=1, #cases do\n"
+"      local case_cfg = {\n"
+"         after_success    = cfg.after_success,\n"
+"         code             = `Do{ }\n"
+"         -- locals    = { } -- unnecessary, done by pattern_seq_builder\n"
+"      }\n"
+"      case_builder (cases[i], term_seq, case_cfg)\n"
+"      if next (case_cfg.locals) then\n"
+"         local case_locals = { }\n"
+"         table.insert (case_cfg.code, 1, `Local{ case_locals, { } })\n"
+"         for v, _ in pairs (case_cfg.locals) do\n"
+"            table.insert (case_locals, `Id{ v })\n"
+"         end\n"
+"      end\n"
+"      acc_stat(case_cfg.code, cfg)\n"
+"  end\n"
+"  local li = `String{tostring(cases.lineinfo)}\n"
+"  acc_stat(+{error('mismatch at '..-{li})}, cfg)\n"
+"  acc_stat(`Label{cfg.after_success}, cfg)\n"
+"  return cfg.code\n"
+"end\n"
+"\n----------------------------------------------------------------------\n"
+"-- Syntactical front-end\n"
+"----------------------------------------------------------------------\n"
+"\nlocal function extend(M)\n"
+"\n    local _M = gg.future(M)\n"
+"\n    checks('metalua.compiler.parser')\n"
+"    M.lexer:add{ \"match\", \"with\", \"->\" }\n"
+"    M.block.terminators:add \"|\"\n"
+"\n    local match_cases_list_parser = gg.list{ name = \"match cases list\",\n"
+"        gg.sequence{ name = \"match case\",\n"
+"                     gg.list{ name  = \"match case patterns list\",\n"
+"                              primary     = _M.expr_list,\n"
+"                              separators  = \"|\",\n"
+"                              terminators = { \"->\", \"if\" } },\n"
+"                     gg.onkeyword{ \"if\", _M.expr, consume = true },\n"
+"                     \"->\",\n"
+"                     _M.block },\n"
+"        separators  = \"|\",\n"
+"        terminators = \"end\" }\n"
+"\n    M.stat:add{ name = \"match statement\",\n"
+"                  \"match\",\n"
+"                  _M.expr_list,\n"
+"                  \"with\", gg.optkeyword \"|\",\n"
+"                  match_cases_list_parser,\n"
+"                  \"end\",\n"
+"                  builder = |x| match_builder{ x[1], x[3] } }\n"
+"end\n"
+"\nreturn extend",
true, false);
// End of /metalua/extension/match.mlua
Lua5_1.provide_file("/", "test.lua",
 "local sdf;\n"
+"function mwoeir()\n"
+"if true then\n"
+"   local a=1;\n"
+"end\n"
+"end",
true, false);
// End of /test.lua
Lua5_1.provide_file("/", "metalua.lua",
 "-------------------------------------------------------------------------------\n"
+"-- Copyright (c) 2006-2013 Fabien Fleutot and others.\n"
+"--\n"
+"-- All rights reserved.\n"
+"--\n"
+"-- This program and the accompanying materials are made available\n"
+"-- under the terms of the Eclipse Public License v1.0 which\n"
+"-- accompanies this distribution, and is available at\n"
+"-- http://www.eclipse.org/legal/epl-v10.html\n"
+"--\n"
+"-- This program and the accompanying materials are also made available\n"
+"-- under the terms of the MIT public license which accompanies this\n"
+"-- distribution, and is available at http://www.lua.org/license.html\n"
+"--\n"
+"-- Contributors:\n"
+"--     Fabien Fleutot - API and implementation\n"
+"--\n"
+"-------------------------------------------------------------------------------\n"
+"\n-- Survive lack of checks\n"
+"if not pcall(require, 'checks') then function package.preload.checks() function checks() end end end\n"
+"\n-- Main file for the metalua executable\n"
+"require 'metalua.loader' -- load *.mlue files\n"
+"require 'metalua.compiler.globals' -- metalua-aware loadstring, dofile etc.\n"
+"\nlocal alt_getopt = require 'alt_getopt'\n"
+"local pp  = require 'metalua.pprint'\n"
+"local mlc = require 'metalua.compiler'\n"
+"\nlocal M = { }\n"
+"\nlocal AST_COMPILE_ERROR_NUMBER        = -1\n"
+"local RUNTIME_ERROR_NUMBER            = -3\n"
+"\nlocal alt_getopt_options = \"f:l:e:o:xivaASbs\"\n"
+"\nlocal long_opts = {\n"
+"    file='f',\n"
+"    library='l',\n"
+"    literal='e',\n"
+"    output='o',\n"
+"    run='x',\n"
+"    interactive='i',\n"
+"    verbose='v',\n"
+"    ['print-ast']='a',\n"
+"    ['print-ast-lineinfo']='A',\n"
+"    ['print-src']='S',\n"
+"    ['meta-bugs']='b',\n"
+"    ['sharp-bang']='s',\n"
+"}\n"
+"\nlocal chunk_options = {\n"
+"    library=1,\n"
+"    file=1,\n"
+"    literal=1\n"
+"}\n"
+"\nlocal usage=[[\n"
+"\nCompile and/or execute metalua programs. Parameters passed to the\n"
+"compiler should be prefixed with an option flag, hinting what must be\n"
+"done with them: take tham as file names to compile, as library names\n"
+"to load, as parameters passed to the running program... When option\n"
+"flags are absent, metalua tries to adopt a \"Do What I Mean\" approach:\n"
+"\n- if no code (no library, no literal expression and no file) is\n"
+"  specified, the first flag-less parameter is taken as a file name to\n"
+"  load.\n"
+"\n- if no code and no parameter is passed, an interactive loop is\n"
+"  started.\n"
+"\n- if a target file is specified with --output, the program is not\n"
+"  executed by default, unless a --run flag forces it to. Conversely,\n"
+"  if no --output target is specified, the code is run unless ++run\n"
+"  forbids it.\n"
+"]]\n"
+"\nfunction M.cmdline_parser(...)\n"
+"    local argv = {...}\n"
+"    local opts, optind, optarg =\n"
+"        alt_getopt.get_ordered_opts({...}, alt_getopt_options, long_opts)\n"
+"    --pp.printf(\"argv=%s; opts=%s, ending at %i, with optarg=%s\",\n"
+"    --          argv, opts, optind, optarg)\n"
+"    local s2l = { } -- short to long option names conversion table\n"
+"    for long, short in pairs(long_opts) do s2l[short]=long end\n"
+"    local cfg = { chunks = { } }\n"
+"    for i, short in pairs(opts) do\n"
+"        local long = s2l[short]\n"
+"        if chunk_options[long] then table.insert(cfg.chunks, { tag=long, optarg[i] })\n"
+"        else cfg[long] = optarg[i] or true end\n"
+"    end\n"
+"    cfg.params = { select(optind, ...) }\n"
+"    return cfg\n"
+"end\n"
+"\nfunction M.main (...)\n"
+"\n    local cfg = M.cmdline_parser(...)\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Print messages if in verbose mode\n"
+"    -------------------------------------------------------------------\n"
+"    local function verb_print (fmt, ...)\n"
+"        if cfg.verbose then\n"
+"            return pp.printf (\"[ \"..fmt..\" ]\", ...)\n"
+"        end\n"
+"    end\n"
+"\n    if cfg.verbose then\n"
+"        verb_print(\"raw options: %s\", cfg)\n"
+"    end\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- If there's no chunk but there are params, interpret the first\n"
+"    -- param as a file name.\n"
+"    if not next(cfg.chunks) and next(cfg.params) then\n"
+"        local the_file = table.remove(cfg.params, 1)\n"
+"        verb_print(\"Param %q considered as a source file\", the_file)\n"
+"        cfg.file={ the_file }\n"
+"    end\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- If nothing to do, run REPL loop\n"
+"    if not next(cfg.chunks) and not cfg.interactive then\n"
+"        verb_print \"Nothing to compile nor run, force interactive loop\"\n"
+"        cfg.interactive=true\n"
+"    end\n"
+"\n\n"
+"    -------------------------------------------------------------------\n"
+"    -- Run if asked to, or if no --output has been given\n"
+"    -- if cfg.run==false it's been *forced* to false, don't override.\n"
+"    if not cfg.run and not cfg.output then\n"
+"        verb_print(\"No output file specified; I'll run the program\")\n"
+"        cfg.run = true\n"
+"    end\n"
+"\n    local code = { }\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Get ASTs from sources\n"
+"\n    local last_file_idx\n"
+"    for i, x in ipairs(cfg.chunks) do\n"
+"        local compiler = mlc.new()\n"
+"        local tag, val = x.tag, x[1]\n"
+"        verb_print(\"Compiling %s\", x)\n"
+"        local st, ast\n"
+"        if tag=='library' then\n"
+"            ast = { tag='Call',\n"
+"                {tag='Id', \"require\" },\n"
+"                {tag='String', val } }\n"
+"        elseif tag=='literal' then ast = compiler :src_to_ast(val)\n"
+"        elseif tag=='file' then\n"
+"            ast = compiler :srcfile_to_ast(val)\n"
+"            -- Isolate each file in a separate fenv\n"
+"            ast = { tag='Call',\n"
+"                { tag='Function', { { tag='Dots'} }, ast },\n"
+"                { tag='Dots' } }\n"
+"            ast.source  = '@'..val\n"
+"            code.source = '@'..val\n"
+"            last_file_idx = i\n"
+"        else\n"
+"            error (\"Bad option \"..tag)\n"
+"        end\n"
+"        local valid = true -- TODO: check AST's correctness\n"
+"        if not valid then\n"
+"            pp.printf (\"Cannot compile %s:\\n"
+"%s\", x, ast or \"no msg\")\n"
+"            os.exit (AST_COMPILE_ERROR_NUMBER)\n"
+"        end\n"
+"        ast.origin = x\n"
+"        table.insert(code, ast)\n"
+"    end\n"
+"    -- The last file returns the whole chunk's result\n"
+"    if last_file_idx then\n"
+"        -- transform  +{ (function(...) -{ast} end)(...) }\n"
+"        -- into   +{ return (function(...) -{ast} end)(...) }\n"
+"        local prv_ast = code[last_file_idx]\n"
+"        local new_ast = { tag='Return', prv_ast }\n"
+"        code[last_file_idx] = new_ast\n"
+"    end\n"
+"\n    -- Further uses of compiler won't involve AST transformations:\n"
+"    -- they can share the same instance.\n"
+"    -- TODO: reuse last instance if possible.\n"
+"    local compiler = mlc.new()\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- AST printing\n"
+"    if cfg['print-ast'] or cfg['print-ast-lineinfo'] then\n"
+"        verb_print \"Resulting AST:\"\n"
+"        for _, x in ipairs(code) do\n"
+"            pp.printf(\"--- AST From %s: ---\", x.source)\n"
+"            if x.origin and x.origin.tag=='File' then x=x[1][1][2][1] end\n"
+"            local pp_cfg = cfg['print-ast-lineinfo']\n"
+"                and { line_max=1, fix_indent=1, metalua_tag=1 }\n"
+"                or  { line_max=1, metalua_tag=1, hide_hash=1  }\n"
+"            pp.print(x, 80, pp_cfg)\n"
+"        end\n"
+"    end\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Source printing\n"
+"    if cfg['print-src'] then\n"
+"        verb_print \"Resulting sources:\"\n"
+"        for _, x in ipairs(code) do\n"
+"            printf(\"--- Source From %s: ---\", table.tostring(x.source, 'nohash'))\n"
+"            if x.origin and x.origin.tag=='File' then x=x[1][1][2] end\n"
+"            print (compiler :ast2string (x))\n"
+"        end\n"
+"    end\n"
+"\n    -- TODO: canonize/check AST\n"
+"\n    local bytecode = compiler :ast_to_bytecode (code)\n"
+"    code = nil\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Insert #!... command\n"
+"    if cfg.sharpbang then\n"
+"        local shbang = cfg.sharpbang\n"
+"        verb_print (\"Adding sharp-bang directive %q\", shbang)\n"
+"        if not shbang :match'^#!' then shbang = '#!' .. shbang end\n"
+"        if not shbang :match'\\n"
+"$' then shbang = shbang .. '\\n"
+"' end\n"
+"        bytecode = shbang .. bytecode\n"
+"    end\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Save to file\n"
+"    if cfg.output then\n"
+"        -- FIXME: handle '-'\n"
+"        verb_print (\"Saving to file %q\", cfg.output)\n"
+"        local file, err_msg = io.open(cfg.output, 'wb')\n"
+"        if not file then error(\"can't open output file: \"..err_msg) end\n"
+"        file:write(bytecode)\n"
+"        file:close()\n"
+"        if cfg.sharpbang and os.getenv \"OS\" ~= \"Windows_NT\" then\n"
+"            pcall(os.execute, 'chmod a+x \"'..cfg.output..'\"')\n"
+"        end\n"
+"    end\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Run compiled code\n"
+"    if cfg.run then\n"
+"        verb_print \"Running\"\n"
+"        local f = compiler :bytecode_to_function (bytecode)\n"
+"        bytecode = nil\n"
+"        -- FIXME: isolate execution in a ring\n"
+"        -- FIXME: check for failures\n"
+"        local function print_traceback (errmsg)\n"
+"            return errmsg .. '\\n"
+"' .. debug.traceback ('',2) .. '\\n"
+"'\n"
+"        end\n"
+"        local function g() return f(unpack (cfg.params)) end\n"
+"        local st, msg = xpcall(g, print_traceback)\n"
+"        if not st then\n"
+"            io.stderr:write(msg)\n"
+"            os.exit(RUNTIME_ERROR_NUMBER)\n"
+"        end\n"
+"    end\n"
+"\n    -------------------------------------------------------------------\n"
+"    -- Run REPL loop\n"
+"    if cfg.interactive then\n"
+"        verb_print \"Starting REPL loop\"\n"
+"        require 'metalua.repl' .run()\n"
+"    end\n"
+"\n    verb_print \"Done\"\n"
+"\nend\n"
+"\nreturn M.main(...)\n",
true, false);
// End of /metalua.lua
})(Lua5_1);
